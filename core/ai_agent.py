from typing import List, Dict, Any, Optional
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.agents import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.schema import HumanMessage, SystemMessage
from langchain.tools import BaseTool
from core.langchain_tools import tool_registry, MCPTool
from core.mcp import get_all_mcp_tools
from core.tool_manager import tool_manager, ToolCategory
from core.conversation_history import ConversationHistory
import logging
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)

class AIAgent:
    """AI ì—ì´ì „íŠ¸ - ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ë¥¼ ê²°ì •í•˜ê³  ì‹¤í–‰"""
    
    def __init__(self, api_key: str, model_name: str = "gpt-3.5-turbo"):
        self.api_key = api_key
        self.model_name = model_name
        self.llm = self._create_llm()
        self.tools: List[MCPTool] = []
        self.agent_executor: Optional[AgentExecutor] = None
        self.conversation_history = ConversationHistory()
        
        # MCP ë„êµ¬ ë¡œë“œ ë° ë“±ë¡
        self._load_mcp_tools()
        # ê¸°ì¡´ íˆìŠ¤í† ë¦¬ ë¡œë“œ
        self.conversation_history.load_from_file()
    
    def _create_llm(self):
        """LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        if self.model_name.startswith('gemini'):
            return ChatGoogleGenerativeAI(
                model=self.model_name,
                google_api_key=self.api_key,
                temperature=0.1
            )
        else:
            return ChatOpenAI(
                model=self.model_name,
                openai_api_key=self.api_key,
                temperature=0.1
            )
    
    def _load_mcp_tools(self):
        """MCP ë„êµ¬ ë¡œë“œ ë° LangChain ë„êµ¬ë¡œ ë“±ë¡"""
        try:
            all_mcp_tools = get_all_mcp_tools()
            if all_mcp_tools:
                # ëª¨ë“  ë„êµ¬ ë“±ë¡
                self.tools = tool_registry.register_mcp_tools(all_mcp_tools)
                tool_manager.register_tools(all_mcp_tools)
                logger.info(f"AI ì—ì´ì „íŠ¸ì— {len(self.tools)}ê°œ ë„êµ¬ ë¡œë“œë¨")
            else:
                logger.warning("ì‚¬ìš© ê°€ëŠ¥í•œ MCP ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤")
        except Exception as e:
            logger.error(f"MCP ë„êµ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _should_use_tools(self, user_input: str) -> bool:
        """AIê°€ ì»´í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ ê²°ì •"""
        try:
            # ë„êµ¬ ëª©ë¡ ìš”ì²­ì€ í•­ìƒ ë„êµ¬ ì‚¬ìš©
            if any(keyword in user_input.lower() for keyword in ['ë„êµ¬', 'íˆ´', 'tool', 'ê¸°ëŠ¥', 'ëª©ë¡', 'ë¦¬ìŠ¤íŠ¸']):
                return True
            
            # ë„êµ¬ ì„¤ëª… ìˆ˜ì§‘ (ê°„ë‹¨í•˜ê²Œ)
            tool_names = [tool.name for tool in self.tools[:5]]  # ì²« 5ê°œë§Œ
            tools_summary = ", ".join(tool_names) if tool_names else "ì—†ìŒ"
            
            decision_prompt = f"""ì‚¬ìš©ì: "{user_input}"

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {tools_summary}

ì´ ìš”ì²­ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ì‘ì—…ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.
ì˜ˆ: ë°ì´í„° ê²€ìƒ‰, ì›¹ ì¡°íšŒ, ì—¬í–‰ ìƒí’ˆ ì°¾ê¸° ë“±ì€ ë„êµ¬ í•„ìš”.
ì˜ˆ: ì¼ë°˜ ëŒ€í™”, ì„¤ëª… ìš”ì²­, ì˜ê²¬ ë¬¸ì˜ ë“±ì€ ë„êµ¬ ë¶ˆí•„ìš”.

YES ë˜ëŠ” NOë¡œë§Œ ë‹µí•˜ì„¸ìš”."""
            
            messages = [
                SystemMessage(content="ë„êµ¬ ì‚¬ìš© íŒë‹¨ ì „ë¬¸ê°€"),
                HumanMessage(content=decision_prompt)
            ]
            
            response = self.llm.invoke(messages)
            decision = response.content.strip().upper()
            
            result = decision == "YES"
            logger.info(f"ë„êµ¬ ì‚¬ìš© íŒë‹¨: {decision} -> {result} (ì…ë ¥: {user_input[:30]}...)")
            return result
            
        except Exception as e:
            logger.error(f"ë„êµ¬ ì‚¬ìš© íŒë‹¨ ì˜¤ë¥˜: {e}")
            return False
    
    def _create_agent_executor(self) -> AgentExecutor:
        """ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸° ìƒì„±"""
        if not self.tools:
            return None
        
        # OpenAI ë„êµ¬ ì—ì´ì „íŠ¸ ìƒì„± (GPT ëª¨ë¸ìš©)
        if not self.model_name.startswith('gemini'):
            from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
            
            system_message = """ë‹¹ì‹ ì€ ë‹¤ì–‘í•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ì‚¬ìš©í•˜ì„¸ìš”.
ë„êµ¬ ì‚¬ìš© ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”."""
            
            prompt = ChatPromptTemplate.from_messages([
                ("system", system_message),
                ("human", "{input}"),
                MessagesPlaceholder(variable_name="agent_scratchpad"),
            ])
            
            agent = create_openai_tools_agent(self.llm, self.tools, prompt)
            return AgentExecutor(agent=agent, tools=self.tools, verbose=True, max_iterations=2, handle_parsing_errors=True)
        
        # ReAct ì—ì´ì „íŠ¸ ìƒì„± (Gemini ë“± ë‹¤ë¥¸ ëª¨ë¸ìš©)
        else:
            react_prompt = PromptTemplate.from_template("""
ë‹¹ì‹ ì€ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:
{tools}

ë„êµ¬ ì´ë¦„ë“¤: {tool_names}

ë‹¤ìŒ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¥´ì„¸ìš”:

Question: {input}
Thought: ì´ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í• ì§€ ìƒê°í•´ë³´ê² ìŠµë‹ˆë‹¤.
Action: ë„êµ¬ì´ë¦„
Action Input: ë„êµ¬ì— ì „ë‹¬í•  ì…ë ¥ê°’
Observation: ë„êµ¬ ì‹¤í–‰ ê²°ê³¼
Thought: ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.
Final Answer: ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ë‹µë³€

{agent_scratchpad}
""")
            
            agent = create_react_agent(self.llm, self.tools, react_prompt)
            return AgentExecutor(
                agent=agent, 
                tools=self.tools, 
                verbose=False,
                max_iterations=2,
                handle_parsing_errors=True,
                early_stopping_method="force",
                return_intermediate_steps=False
            )
    
    def chat_with_tools(self, user_input: str) -> str:
        """ë„êµ¬ë¥¼ ì‚¬ìš©í•œ ì±„íŒ…"""
        try:
            # í† í° ì œí•œ ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì œí•œ
            if "context_length_exceeded" in str(getattr(self, '_last_error', '')):
                logger.warning("í† í° ì œí•œ ì˜¤ë¥˜ë¡œ ì¸í•´ ì¼ë°˜ ì±„íŒ…ìœ¼ë¡œ ëŒ€ì²´")
                return self.simple_chat(user_input)
            
            # Gemini ëª¨ë¸ì€ ì§ì ‘ ë„êµ¬ í˜¸ì¶œ ë°©ì‹ ì‚¬ìš©
            if self.model_name.startswith('gemini'):
                return self._gemini_tool_chat(user_input)
            
            # GPT ëª¨ë¸ì€ ê¸°ì¡´ ì—ì´ì „íŠ¸ ë°©ì‹ ì‚¬ìš©
            if not self.agent_executor:
                self.agent_executor = self._create_agent_executor()
            
            if not self.agent_executor:
                return "ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            result = self.agent_executor.invoke({"input": user_input})
            output = result.get("output", "")
            
            if "Agent stopped" in output or not output.strip():
                logger.warning("ì—ì´ì „íŠ¸ ì¤‘ë‹¨ë¡œ ì¸í•´ ì¼ë°˜ ì±„íŒ…ìœ¼ë¡œ ëŒ€ì²´")
                return self.simple_chat(user_input)
            
            return output
            
        except Exception as e:
            error_msg = str(e)
            self._last_error = error_msg
            logger.error(f"ë„êµ¬ ì‚¬ìš© ì±„íŒ… ì˜¤ë¥˜: {e}")
            
            # í† í° ì œí•œ ì˜¤ë¥˜ ì²˜ë¦¬
            if "context_length_exceeded" in error_msg or "maximum context length" in error_msg:
                logger.warning("í† í° ì œí•œ ì˜¤ë¥˜ ë°œìƒ, ì¼ë°˜ ì±„íŒ…ìœ¼ë¡œ ëŒ€ì²´")
                return self.simple_chat(user_input)
            
            return self.simple_chat(user_input)
    
    def simple_chat(self, user_input: str) -> str:
        """ì¼ë°˜ ì±„íŒ… (ë„êµ¬ ì‚¬ìš© ì—†ìŒ)"""
        try:
            # ê°€ë…ì„± ì¢‹ì€ ì‘ë‹µì„ ìœ„í•œ ì‹œìŠ¤í…œ ë©”ì‹œì§€
            system_content = """ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì¹œê·¼í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

**ì‘ë‹µ í˜•ì‹ ê°€ì´ë“œë¼ì¸:**
- ê¸´ ë¬¸ì¥ì€ ì ì ˆíˆ ì¤„ë°”ê¿ˆí•˜ì—¬ ê°€ë…ì„± í–¥ìƒ
- ì¤‘ìš”í•œ ì •ë³´ëŠ” **êµµì€ ê¸€ì”¨**ë‚˜ â€¢ ë¶ˆë¦¿ í¬ì¸íŠ¸ ì‚¬ìš©
- ì—¬ëŸ¬ í•­ëª©ì´ ìˆì„ ë•ŒëŠ” ë²ˆí˜¸ë‚˜ êµ¬ë¶„ìë¡œ ì •ë¦¬
- í•œ ì¤„ì— ë„ˆë¬´ ë§ì€ ë‚´ìš©ì„ ë‹´ì§€ ë§ê³  ë‹¨ë½ìœ¼ë¡œ êµ¬ë¶„
- í•µì‹¬ ë‚´ìš©ì„ ë¨¼ì € ì œì‹œí•˜ê³  ì„¸ë¶€ì‚¬í•­ì€ ë’¤ì— ë°°ì¹˜"""
            
            messages = [
                SystemMessage(content=system_content),
                HumanMessage(content=user_input)
            ]
            
            response = self.llm.invoke(messages)
            return response.content
            
        except Exception as e:
            logger.error(f"ì¼ë°˜ ì±„íŒ… ì˜¤ë¥˜: {e}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
    
    def simple_chat_with_history(self, user_input: str, conversation_history: List[Dict]) -> str:
        """ëŒ€í™” ê¸°ë¡ì„ í¬í•¨í•œ ì¼ë°˜ ì±„íŒ…"""
        try:
            messages = self._convert_history_to_messages(conversation_history)
            # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            messages.append(HumanMessage(content=user_input))
            response = self.llm.invoke(messages)
            return response.content
        except Exception as e:
            logger.error(f"ëŒ€í™” ê¸°ë¡ ì±„íŒ… ì˜¤ë¥˜: {e}")
            return self.simple_chat(user_input)
    
    def process_message(self, user_input: str) -> tuple[str, bool]:
        """ë©”ì‹œì§€ ì²˜ë¦¬ - AIê°€ ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ ê²°ì •"""
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.conversation_history.add_message("user", user_input)
        
        if not self.tools:
            response = self.simple_chat_with_history(user_input, self.conversation_history.get_recent_messages(10))
            self.conversation_history.add_message("assistant", response)
            self.conversation_history.save_to_file()
            return response, False
        
        # AIê°€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ ê²°ì •
        use_tools = self._should_use_tools(user_input)
        
        if use_tools:
            response = self.chat_with_tools(user_input)
            self.conversation_history.add_message("assistant", response)
            self.conversation_history.save_to_file()
            return response, True
        else:
            response = self.simple_chat_with_history(user_input, self.conversation_history.get_recent_messages(10))
            self.conversation_history.add_message("assistant", response)
            self.conversation_history.save_to_file()
            return response, False
    
    def process_message_with_history(self, user_input: str, conversation_history: List[Dict]) -> tuple[str, bool]:
        """ëŒ€í™” ê¸°ë¡ì„ í¬í•¨í•œ ë©”ì‹œì§€ ì²˜ë¦¬"""
        if not self.tools:
            response = self.simple_chat_with_history(user_input, conversation_history)
            return response, False
        
        use_tools = self._should_use_tools(user_input)
        
        if use_tools:
            response = self.chat_with_tools(user_input)
            return response, True
        else:
            response = self.simple_chat_with_history(user_input, conversation_history)
            return response, False
    
    def _convert_history_to_messages(self, conversation_history: List[Dict]):
        """ëŒ€í™” ê¸°ë¡ì„ LangChain ë©”ì‹œì§€ë¡œ ë³€í™˜ - í† í° ì œí•œ ê³ ë ¤"""
        messages = []
        
        # ê°„ë‹¨í•œ ì‹œìŠ¤í…œ ë©”ì‹œì§€
        messages.append(SystemMessage(content="AI ì–´ì‹œìŠ¤í„´íŠ¸"))
        
        # í† í° ì œí•œì„ ìœ„í•´ ìµœê·¼ 2ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©
        recent_history = conversation_history[-2:] if len(conversation_history) > 2 else conversation_history
        
        for msg in recent_history:
            role = msg.get('role', '')
            content = msg.get('content', '')[:100]  # ë‚´ìš©ë„ 100ìë¡œ ì œí•œ
            if role == 'user':
                messages.append(HumanMessage(content=content))
            elif role == 'assistant':
                from langchain.schema import AIMessage
                messages.append(AIMessage(content=content))
        
        return messages
    
    def _gemini_tool_chat(self, user_input: str) -> str:
        """ê²Œë¯¸ë‹ˆ ëª¨ë¸ìš© AI ê¸°ë°˜ ë„êµ¬ ì„ íƒ ë° ì‹¤í–‰"""
        try:
            # ë„êµ¬ ëª©ë¡ ìš”ì²­ ì²˜ë¦¬
            if any(keyword in user_input.lower() for keyword in ['ë„êµ¬', 'íˆ´', 'tool', 'ê¸°ëŠ¥', 'ëª©ë¡', 'ë¦¬ìŠ¤íŠ¸']):
                return self._show_tool_list()
            
            # 1ë‹¨ê³„: AIê°€ ì‚¬ìš©í•  ë„êµ¬ì™€ íŒŒë¼ë¯¸í„° ê²°ì •
            tool_decision = self._ai_select_tool(user_input)
            if tool_decision:
                tool_decision['original_query'] = user_input  # ì²­í¬ ì²˜ë¦¬ìš©
            
            if not tool_decision or tool_decision.get('tool') == 'none':
                return self.simple_chat(user_input)
            
            # 2ë‹¨ê³„: ì„ íƒëœ ë„êµ¬ ì‹¤í–‰
            tool_result = self._execute_selected_tool(tool_decision)
            
            # 3ë‹¨ê³„: ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µ ìƒì„±
            return self._generate_final_response(user_input, tool_result)
            
        except Exception as e:
            logger.error(f"ê²Œë¯¸ë‹ˆ ë„êµ¬ ì±„íŒ… ì˜¤ë¥˜: {e}")
            return self.simple_chat(user_input)
    
    def _get_realistic_date_range(self, user_input: str) -> tuple[str, str]:
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ í˜„ì‹¤ì ì¸ ë‚ ì§œ ë²”ìœ„ ìƒì„±"""
        now = datetime.now()
        
        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì—°ë„/ì›” ì¶”ì¶œ
        import re
        year_match = re.search(r'(20\d{2})', user_input)
        month_match = re.search(r'(\d{1,2})ì›”', user_input)
        
        if year_match and month_match:
            year = int(year_match.group(1))
            month = int(month_match.group(1))
            
            # ë„ˆë¬´ ë¨¼ ë¯¸ë˜ëŠ” í˜„ì¬ë¡œë¶€í„° 3ê°œì›” í›„ë¡œ ì¡°ì •
            target_date = datetime(year, month, 1)
            max_future = now + timedelta(days=90)  # 3ê°œì›”
            
            if target_date > max_future:
                target_date = max_future.replace(day=1)
        else:
            # ë‚ ì§œ ì—†ìœ¼ë©´ ë‹¤ìŒ ë‹¬
            target_date = (now + timedelta(days=30)).replace(day=1)
        
        # ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ ìƒì„±
        start_date = target_date.strftime('%Y%m%d')
        end_date = (target_date + timedelta(days=30)).strftime('%Y%m%d')
        
        return start_date, end_date
    
    def _get_area_code(self, user_input: str) -> str:
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì§€ì—­ ì½”ë“œ ì¶”ì¶œ"""
        user_lower = user_input.lower()
        
        # ì§€ì—­ë³„ ì½”ë“œ ë§¤í•‘
        area_mapping = {
            'ë™ë‚¨ì•„': 'A0',
            'ì•„ì‹œì•„': 'A0', 
            'íƒœêµ­': 'A0',
            'ë² íŠ¸ë‚¨': 'A0',
            'ì‹±ê°€í¬ë¥´': 'A0',
            'ì¸ë„ë„¤ì‹œì•„': 'A0',
            'ìœ ëŸ½': 'E0',
            'ì˜êµ­': 'E0',
            'í”„ë‘ìŠ¤': 'E0',
            'ë…ì¼': 'E0',
            'ì´íƒˆë¦¬ì•„': 'E0',
            'ìŠ¤í˜ì¸': 'E0',
            'ì¼ë³¸': 'J0',
            'ì¤‘êµ­': 'C0',
            'ë¯¸êµ­': 'U0',
            'ìºë‚˜ë‹¤': 'U0'
        }
        
        for region, code in area_mapping.items():
            if region in user_lower:
                return code
        
        # ê¸°ë³¸ê°’: ë™ë‚¨ì•„
        return 'A0'
    
    def _ai_select_tool(self, user_input: str):
        """ê²Œë¯¸ë‹ˆ AIê°€ ì‚¬ìš©í•  ë„êµ¬ì™€ íŒŒë¼ë¯¸í„° ê²°ì • - í† í° ì œí•œ ê³ ë ¤"""
        try:
            if not self.tools:
                logger.warning("ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # ë„êµ¬ ì„¤ëª… ìˆ˜ì§‘
            tools_info = []
            for tool in self.tools:
                desc = getattr(tool, 'description', tool.name)
                tools_info.append(f"- {tool.name}: {desc}")
            
            tools_list = "\n".join(tools_info)
            
            # ì—¬í–‰ ìƒí’ˆ ê²€ìƒ‰ì¸ ê²½ìš° í˜„ì‹¤ì ì¸ ë‚ ì§œì™€ ì§€ì—­ ì½”ë“œ ì œì•ˆ
            realistic_dates = ""
            if any(keyword in user_input for keyword in ['ì—¬í–‰', 'ìƒí’ˆ', 'íŒ¨í‚¤ì§€']):
                start_date, end_date = self._get_realistic_date_range(user_input)
                area_code = self._get_area_code(user_input)
                realistic_dates = f"\n\n**ì¶”ì²œ íŒŒë¼ë¯¸í„°:**\n- startDate: {start_date}\n- endDate: {end_date}\n- productAreaCode: {area_code}"
            
            selection_prompt = f"""ì‚¬ìš©ì ìš”ì²­: "{user_input}"

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:
{tools_list}{realistic_dates}

ì‚¬ìš©ì ìš”ì²­ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€ ê²°ì •í•˜ê³ , í•„ìš”í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”:
- ë„êµ¬ê°€ í•„ìš”í•œ ê²½ìš°: TOOL: ë„êµ¬ì´ë¦„ | PARAMS: {{"key": "value"}}
- ë„êµ¬ê°€ í•„ìš”ì—†ëŠ” ê²½ìš°: TOOL: none"""
            
            # ê°„ë‹¨í•œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©
            messages = [
                SystemMessage(content="ë„êµ¬ ì„ íƒ ì „ë¬¸ê°€"),
                HumanMessage(content=selection_prompt)
            ]
            
            response = self.llm.invoke(messages)
            return self._parse_tool_decision(response.content)
            
        except Exception as e:
            logger.error(f"AI ë„êµ¬ ì„ íƒ ì˜¤ë¥˜: {e}")
            return None
    
    def _parse_tool_decision(self, response: str):
        """ë„êµ¬ ì„ íƒ ì‘ë‹µ íŒŒì‹±"""
        try:
            import re
            import json
            
            logger.info(f"íŒŒì‹±í•  ì‘ë‹µ: {response}")
            
            # "TOOL: toolname | PARAMS: {...}" í˜•ì‹ íŒŒì‹±
            match = re.search(r'TOOL:\s*([^|\n]+)(?:\s*\|\s*PARAMS:\s*([^\n]+))?', response, re.IGNORECASE)
            if not match:
                logger.warning(f"ë„êµ¬ í˜•ì‹ ë§¤ì¹­ ì‹¤íŒ¨: {response}")
                return None
            
            tool_name = match.group(1).strip()
            params_str = match.group(2).strip() if match.group(2) else '{}'
            
            logger.info(f"íŒŒì‹±ëœ ë„êµ¬ëª…: '{tool_name}', íŒŒë¼ë¯¸í„°: '{params_str}'")
            
            if tool_name.lower() == 'none':
                return {'tool': 'none'}
            
            try:
                params = json.loads(params_str)
            except json.JSONDecodeError as je:
                logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {params_str}, ì˜¤ë¥˜: {je}")
                params = {}
            
            return {
                'tool': tool_name,
                'params': params
            }
            
        except Exception as e:
            logger.error(f"ë„êµ¬ ê²°ì • íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None
    
    def _split_large_response(self, response_text: str, max_chunk_size: int = 3000) -> List[str]:
        """í° ì‘ë‹µì„ ì²­í¬ë¡œ ë¶„í• """
        if len(response_text) <= max_chunk_size:
            return [response_text]
        
        chunks = []
        current_pos = 0
        
        while current_pos < len(response_text):
            # JSON êµ¬ì¡°ë¥¼ ê³ ë ¤í•œ ë¶„í•  ì§€ì  ì°¾ê¸°
            end_pos = min(current_pos + max_chunk_size, len(response_text))
            
            # JSON ê°ì²´ë‚˜ ë°°ì—´ ëì—ì„œ ë¶„í• 
            if end_pos < len(response_text):
                # ë’¤ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ }, ] ì°¾ê¸°
                for i in range(end_pos, current_pos, -1):
                    if response_text[i] in ['}', ']', ',']:
                        end_pos = i + 1
                        break
            
            chunk = response_text[current_pos:end_pos]
            chunks.append(chunk)
            current_pos = end_pos
        
        return chunks
    
    def _process_chunked_response(self, large_response: str, user_query: str) -> str:
        """ëŒ€ìš©ëŸ‰ ì‘ë‹µì„ ì „ì²´ ë¶„ì„í•˜ì—¬ ê²°ê³¼ë§Œ ë³´ì—¬ì£¼ê¸°"""
        logger.info(f"ëŒ€ìš©ëŸ‰ ì‘ë‹µ ë¶„ì„ ì‹œì‘: {len(large_response)}ì")
        
        # ì „ì²´ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ë¶„ì„
        analysis_prompt = f"""ì‚¬ìš©ì ì§ˆì˜: {user_query}

ë°ì´í„°:
{large_response}

ìœ„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”. ì²­í¬ ë²ˆí˜¸ë‚˜ ë¶„ì„ ì§„í–‰ ìƒí™©ì€ ì–¸ê¸‰í•˜ì§€ ë§ê³  ê²°ê³¼ë§Œ ë³´ì—¬ì£¼ì„¸ìš”."""
        
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¶„ì„ ê³¼ì •ì€ ì–¸ê¸‰í•˜ì§€ ë§ê³  ê²°ê³¼ë§Œ ë³´ì—¬ì£¼ì„¸ìš”."),
            HumanMessage(content=analysis_prompt)
        ]
        
        analysis_response = self.llm.invoke(messages)
        return analysis_response.content
    
    def _execute_selected_tool(self, tool_decision):
        """ì„ íƒëœ ë„êµ¬ ì‹¤í–‰"""
        try:
            tool_name = tool_decision['tool']
            params = tool_decision.get('params', {})
            
            # ë„êµ¬ ìŠ¤í‚¤ë§ˆì— ë”°ë¼ íŒŒë¼ë¯¸í„° ìë™ ë³€í™˜
            selected_tool = None
            for tool in self.tools:
                if tool.name.lower() == tool_name.lower():
                    selected_tool = tool
                    break
            
            if selected_tool and hasattr(selected_tool, 'args_schema') and selected_tool.args_schema:
                try:
                    schema = selected_tool.args_schema.schema()
                    if 'properties' in schema:
                        for param_name, param_value in params.items():
                            if param_name in schema['properties']:
                                param_schema = schema['properties'][param_name]
                                if param_schema.get('type') == 'array' and isinstance(param_value, str):
                                    params[param_name] = [param_value]
                except:
                    pass
            
            logger.info(f"ë„êµ¬ ì°¾ê¸°: '{tool_name}'")
            
            # ë„êµ¬ ì°¾ê¸° (ë” ìœ ì—°í•œ ë§¤ì¹­)
            selected_tool = None
            for tool in self.tools:
                tool_name_lower = tool_name.lower()
                actual_name_lower = tool.name.lower()
                
                # ì •í™•í•œ ì´ë¦„ ë§¤ì¹­ ë˜ëŠ” ë¶€ë¶„ ë§¤ì¹­
                if (tool_name_lower == actual_name_lower or 
                    tool_name_lower in actual_name_lower or 
                    actual_name_lower in tool_name_lower or
                    tool_name_lower.replace('_', '-') == actual_name_lower.replace('_', '-')):
                    selected_tool = tool
                    logger.info(f"ë„êµ¬ ë§¤ì¹­ ì„±ê³µ: '{tool_name}' -> '{tool.name}'")
                    break
            
            if not selected_tool:
                available_tools = [t.name for t in self.tools]
                logger.error(f"ë„êµ¬ '{tool_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {available_tools}")
                return f"ë„êµ¬ '{tool_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {available_tools}"
            
            # ê²€ìƒ‰ ë„êµ¬ì˜ ê²½ìš° ë” ë§ì€ ê²°ê³¼ ìš”ì²­
            if 'search' in selected_tool.name.lower():
                if 'limit' not in params and 'maxResults' not in params:
                    params['maxResults'] = 10  # ê¸°ë³¸ 10ê°œ ê²°ê³¼
                if 'includeHtml' not in params:
                    params['includeHtml'] = False
            
            # ë„êµ¬ ì‹¤í–‰ (GPT ìŠ¤íƒ€ì¼ ë¡œê¹…)
            print(f"\n> Invoking: `{selected_tool.name}` with `{params}`\n")
            
            result = selected_tool.invoke(params)
            
            # ê²°ê³¼ ì¶œë ¥
            print(result)
            print("\n")
            
            # ê²°ê³¼ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° ëŒ€ì•ˆ ì œì‹œ
            if isinstance(result, str) and ('"resultCount": 0' in result or '"saleProductItemResponseList": []' in result):
                logger.warning(f"ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ: {selected_tool.name}")
                return f"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë‚ ì§œë‚˜ ì§€ì—­ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.\n\nì›ë³¸ ê²°ê³¼: {result}"
            
            logger.info(f"ë„êµ¬ ì‹¤í–‰ ê²°ê³¼: {str(result)[:200]}...")
            
            # ëŒ€ìš©ëŸ‰ ì‘ë‹µ ì²˜ë¦¬
            if isinstance(result, str) and len(result) > 5000:
                logger.info(f"ëŒ€ìš©ëŸ‰ ì‘ë‹µ ê°ì§€: {len(result)}ì")
                original_query = tool_decision.get('original_query', '') if isinstance(tool_decision, dict) else ''
                return self._process_chunked_response(result, original_query)
            
            return result
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            
            # íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜ ì²˜ë¦¬
            if 'timeout' in error_msg.lower() or 'MCP ì‘ë‹µ íƒ€ì„ì•„ì›ƒ' in error_msg:
                return f"ë„êµ¬ í˜¸ì¶œ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            
            return f"ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
    
    def _show_tool_list(self) -> str:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ì„ ë™ì ìœ¼ë¡œ ìƒì„±í•˜ì—¬ ë°˜í™˜"""
        if not self.tools:
            return "í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # ì„œë²„ë³„ë¡œ ë„êµ¬ ë¶„ë¥˜
        tools_by_server = {}
        for tool in self.tools:
            server_name = getattr(tool, 'server_name', 'Unknown')
            if server_name not in tools_by_server:
                tools_by_server[server_name] = []
            tools_by_server[server_name].append(tool)
        
        # ë„êµ¬ ëª©ë¡ ìƒì„±
        result = ["ğŸ”§ **ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡**\n"]
        
        for server_name, server_tools in tools_by_server.items():
            result.append(f"ğŸ“¦ **{server_name}** ({len(server_tools)}ê°œ ë„êµ¬):")
            for tool in server_tools:
                desc = getattr(tool, 'description', tool.name)
                # ì „ì²´ ì„¤ëª… í‘œì‹œ
                result.append(f"  â€¢ {tool.name}: {desc}")
            result.append("")  # ë¹ˆ ì¤„ ì¶”ê°€
        
        result.append(f"ì´ {len(self.tools)}ê°œì˜ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return "\n".join(result)
    
    def _format_response(self, text: str) -> str:
        """ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ê°€ë…ì„± ì¢‹ê²Œ í¬ë§·íŒ…"""
        if not text or len(text) < 50:
            return text
        
        import re
        
        # 1. ë¬¸ì¥ ëì— ì¤„ë°”ê¿ˆ ì¶”ê°€
        formatted = text.replace('ë‹¤. ', 'ë‹¤.\n\n')
        formatted = formatted.replace('ìŠµë‹ˆë‹¤. ', 'ìŠµë‹ˆë‹¤.\n\n')
        
        # 2. ì—°ì†ëœ ì •ë³´ë¥¼ ë¶ˆë¦¿ìœ¼ë¡œ ë³€í™˜
        formatted = re.sub(r'([^.]+?)ì€ ([^,ì´ë©°]+?)[ì´ê³ ,]\s*', r'â€¢ **\1**: \2\n', formatted)
        formatted = re.sub(r'([^.]+?)ëŠ” ([^,ì´ë©°]+?)[ì´ë©°,]\s*', r'â€¢ **\1**: \2\n', formatted)
        
        # 3. ì£¼ìš” ì •ë³´ ê°•ì¡°
        formatted = re.sub(r'(ëŒ€í†µë ¹|ì •ë¶€|ê´€ì„¸|í˜‘ìƒ|ëŒ€ì‘)', r'**\1**', formatted)
        
        # 4. ê³¼ë„í•œ ì¤„ë°”ê¿ˆ ì •ë¦¬
        formatted = re.sub(r'\n{3,}', '\n\n', formatted)
        
        return formatted.strip()
    
    def _generate_final_response(self, user_input: str, tool_result: str):
        """ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µ ìƒì„± - í† í° ì œí•œ ê³ ë ¤"""
        try:
            # ë„êµ¬ ê²°ê³¼ê°€ ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½
            if len(tool_result) > 2000:
                tool_result = tool_result[:2000] + "...(ìƒëµ)"
            
            response_prompt = f"""ì§ˆë¬¸: {user_input}
ê²°ê³¼: {tool_result}

ìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë„ì›€ë˜ëŠ” ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”."""
            
            messages = [
                SystemMessage(content="AI ì–´ì‹œìŠ¤í„´íŠ¸"),
                HumanMessage(content=response_prompt)
            ]
            
            response = self.llm.invoke(messages)
            return self._format_response(response.content)
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"ìµœì¢… ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            
            # í† í° ì œí•œ ì˜¤ë¥˜ ì²˜ë¦¬
            if "context_length_exceeded" in error_msg or "maximum context length" in error_msg:
                return self._format_response("ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì•˜ì§€ë§Œ ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ì–´ ìš”ì•½í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            
            return self._format_response("ë„êµ¬ ì‹¤í–‰ì€ ì„±ê³µí–ˆì§€ë§Œ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")