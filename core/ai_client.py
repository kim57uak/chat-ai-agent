from core.ai_agent import AIAgent
import logging

logger = logging.getLogger(__name__)


class AIClient:
    """AI í´ë¼ì´ì–¸íŠ¸ - ì—ì´ì „íŠ¸ ê¸°ë°˜ ì±„íŒ…"""

    def __init__(self, api_key, model_name="gpt-3.5-turbo"):
        self.api_key = api_key
        self.model_name = model_name
        self.agent = AIAgent(api_key, model_name)
        self.conversation_history = []  # ëŒ€í™” ê¸°ë¡ ì €ì¥

        # ì„¤ì • íŒŒì¼ì—ì„œ ëŒ€í™” ê¸°ë¡ ì„¤ì • ë¡œë“œ
        from core.file_utils import load_config

        config = load_config()
        conv_settings = config.get("conversation_settings", {})

        self.max_history_pairs = conv_settings.get("max_history_pairs", 5)
        self.max_tokens_estimate = conv_settings.get("max_tokens_estimate", 2000)
        self.enable_history = conv_settings.get("enable_history", True)
        self.token_optimization = conv_settings.get("token_optimization", True)

        # ìœ ì € í”„ë¡¬í”„íŠ¸ ì„¤ì •
        self.user_prompt = self._load_user_prompt()

    def chat(self, messages):
        """í† í° ìµœì í™”ëœ ëŒ€í™” ê¸°ë¡ ì‚¬ìš© (í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ ì²­í¬ ë¶„í• ) - ì•ˆì •ì„± ê°œì„ """
        try:
            # ì…ë ¥ ê²€ì¦
            if not messages or not isinstance(messages, list):
                return "ìœ íš¨í•˜ì§€ ì•Šì€ ë©”ì‹œì§€ í˜•ì‹ì…ë‹ˆë‹¤."

            # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
            user_message = ""
            for msg in reversed(messages):
                if isinstance(msg, dict) and msg.get("role") == "user":
                    user_message = msg.get("content", "").strip()
                    if user_message:
                        break

            # ì´ë¯¸ì§€ ë°ì´í„° ê°ì§€ (ì¤„ë°”ê¿ˆ ë¬´ì‹œ)
            cleaned_message = user_message.replace("\n", "")
            has_start_tag = "[IMAGE_BASE64]" in cleaned_message
            has_end_tag = "[/IMAGE_BASE64]" in cleaned_message
            has_image_data = has_start_tag and has_end_tag
            
            print(f"[AIClient.chat] ì´ë¯¸ì§€ ë°ì´í„° ê°ì§€: {has_image_data}")
            print(f"[AIClient.chat] ì‹œì‘ íƒœê·¸: {has_start_tag}, ì¢…ë£Œ íƒœê·¸: {has_end_tag}")
            
            if has_image_data:
                # ì´ë¯¸ì§€ OCRì— ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
                ocr_prompt = """ì´ ì´ë¯¸ì§€ì—ì„œ **ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ì¶”ì¶œ(OCR)**í•´ì£¼ì„¸ìš”.

**í•„ìˆ˜ ì‘ì—…:**
1. **ì™„ì „í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ**: ì´ë¯¸ì§€ ë‚´ ëª¨ë“  í•œê¸€, ì˜ì–´, ìˆ«ì, ê¸°í˜¸ë¥¼ ë¹ ì§ì—†ì´ ì¶”ì¶œ
2. **êµ¬ì¡° ë¶„ì„**: í‘œ, ëª©ë¡, ì œëª©, ë‹¨ë½ ë“±ì˜ ë¬¸ì„œ êµ¬ì¡° íŒŒì•…
3. **ë ˆì´ì•„ì›ƒ ì •ë³´**: í…ìŠ¤íŠ¸ì˜ ìœ„ì¹˜, í¬ê¸°, ë°°ì¹˜ ê´€ê³„ ì„¤ëª…
4. **ì •í™•í•œ ì „ì‚¬**: ì˜¤íƒ€ ì—†ì´ ì •í™•í•˜ê²Œ ëª¨ë“  ë¬¸ì ê¸°ë¡
5. **ë§¥ë½ ì„¤ëª…**: ë¬¸ì„œì˜ ì¢…ë¥˜ì™€ ëª©ì  íŒŒì•…

**ì‘ë‹µ í˜•ì‹:**
## ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸
[ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ë‚˜ì—´]

## ğŸ“‹ ë¬¸ì„œ êµ¬ì¡°
[í‘œ, ëª©ë¡, ì œëª© ë“±ì˜ êµ¬ì¡° ì„¤ëª…]

## ğŸ“ ë ˆì´ì•„ì›ƒ ì •ë³´
[í…ìŠ¤íŠ¸ ë°°ì¹˜ì™€ ìœ„ì¹˜ ê´€ê³„]

**ì¤‘ìš”**: ì´ë¯¸ì§€ì—ì„œ ì½ì„ ìˆ˜ ìˆëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì ˆëŒ€ ëˆ„ë½í•˜ì§€ ë§ê³  ì™„ì „íˆ ì¶”ì¶œí•´ì£¼ì„¸ìš”."""
                
                print(f"[AIClient.chat] ì´ë¯¸ì§€ OCR ëª¨ë“œ - ì „ìš© í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
                # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ì— OCR í”„ë¡¬í”„íŠ¸ ì¶”ê°€
                for i in range(len(messages) - 1, -1, -1):
                    if messages[i].get("role") == "user":
                        # ê¸°ì¡´ ë©”ì‹œì§€ì—ì„œ ì´ë¯¸ì§€ ë°ì´í„° ë¶€ë¶„ê³¼ í…ìŠ¤íŠ¸ ë¶€ë¶„ ë¶„ë¦¬
                        content = messages[i]["content"]
                        print(f"[AIClient.chat] ê¸°ì¡´ ë©”ì‹œì§€ ê¸¸ì´: {len(content)}")
                        print(f"[AIClient.chat] ê¸°ì¡´ ë©”ì‹œì§€ ë¯¸ë¦¬ë³´ê¸°: {content[:200]}...")
                        cleaned_content = content.replace("\n", "")
                        has_image_in_content = "[IMAGE_BASE64]" in cleaned_content
                        print(f"[AIClient.chat] ì½˜í…ì¸ ì— ì´ë¯¸ì§€ ë°ì´í„°: {has_image_in_content}")
                        if has_image_in_content:
                            # ì´ë¯¸ì§€ ë°ì´í„°ëŠ” ê·¸ëŒ€ë¡œ ë‘ê³  OCR í”„ë¡¬í”„íŠ¸ë§Œ ì¶”ê°€
                            messages[i]["content"] = f"{ocr_prompt}\n\n{content}"
                            print(f"[AIClient.chat] OCR í”„ë¡¬í”„íŠ¸ ì¶”ê°€ ì™„ë£Œ, ìµœì¢… ê¸¸ì´: {len(messages[i]['content'])}")
                        break
            else:
                # ì¼ë°˜ í…ìŠ¤íŠ¸ì˜ ê²½ìš° ê¸°ì¡´ ìœ ì € í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
                user_prompt = self.get_current_user_prompt()
                print(f"[AIClient.chat] í˜„ì¬ ëª¨ë¸: {self.model_name}")
                print(f"[AIClient.chat] ìœ ì € í”„ë¡¬í”„íŠ¸: {user_prompt}")
                if user_prompt and user_message:
                    # ì‚¬ìš©ì ë©”ì‹œì§€ì— í”„ë¡¬í”„íŠ¸ ì¶”ê°€
                    enhanced_message = f"{user_prompt}\n\n{user_message}"
                    # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
                    for i in range(len(messages) - 1, -1, -1):
                        if messages[i].get("role") == "user":
                            messages[i]["content"] = enhanced_message
                            break
                    print(f"[AIClient.chat] ìœ ì € í”„ë¡¬í”„íŠ¸ ì¶”ê°€ë¨")

            # ìš”ì²­ íŒŒë¼ë¯¸í„° ë¡œê¹…
            print(f"[AIClient.chat] ìš”ì²­ íŒŒë¼ë¯¸í„°:")
            print(f"  - ëª¨ë¸: {self.model_name}")
            print(f"  - ë©”ì‹œì§€ ìˆ˜: {len(messages)}")
            for i, msg in enumerate(messages):
                content_preview = (
                    msg.get("content", "")[:100] + "..."
                    if len(msg.get("content", "")) > 100
                    else msg.get("content", "")
                )
                print(f"  - [{i}] {msg.get('role', 'unknown')}: {content_preview}")

            if not user_message:
                return "ì²˜ë¦¬í•  ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            print(f"[AIClient.chat] ì±„íŒ… ìš”ì²­ ì²˜ë¦¬ ì‹œì‘: {user_message[:50]}...")
            logger.info(f"ì±„íŒ… ìš”ì²­ ì²˜ë¦¬ ì‹œì‘: {user_message[:50]}...")

            # ëŒ€í™” ê¸°ë¡ ì‚¬ìš© ì—¬ë¶€ í™•ì¸
            if not self.enable_history:
                return self._process_with_quota_handling(user_message, [])

            # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸ ë° ìµœì í™”
            self.conversation_history = [
                msg for msg in messages if isinstance(msg, dict)
            ]
            optimized_history = (
                self._optimize_conversation_history()
                if self.token_optimization
                else self.conversation_history.copy()
            )

            return self._process_with_quota_handling(user_message, optimized_history)

        except Exception as e:
            error_msg = str(e)
            logger.error(f"AI í´ë¼ì´ì–¸íŠ¸ ì±„íŒ… ì˜¤ë¥˜: {error_msg}")
            return f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg[:100]}..."

    def _process_with_quota_handling(
        self, user_message: str, history: list, force_agent: bool = False
    ):
        """í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ ì²­í¬ ë¶„í•  ì²˜ë¦¬ - ë‹¨ìˆœí™”"""
        import time

        try:
            start_time = time.time()
            mode_info = " (Agent ëª¨ë“œ)" if force_agent else " (Ask ëª¨ë“œ)"
            logger.info(
                f"AI ìš”ì²­ ì‹œì‘{mode_info}: {self.model_name} (íˆìŠ¤í† ë¦¬: {len(history)}ê°œ)"
            )

            response, used_tools = self.agent.process_message_with_history(
                user_message, history, force_agent
            )

            elapsed_time = time.time() - start_time

            if used_tools:
                logger.info(
                    f"ë„êµ¬ ì‚¬ìš© ì‘ë‹µ ì™„ë£Œ{mode_info}: {self.model_name} ({elapsed_time:.1f}ì´ˆ) - ë„êµ¬: {used_tools}"
                )
            else:
                logger.info(
                    f"ì¼ë°˜ ì±„íŒ… ì‘ë‹µ ì™„ë£Œ{mode_info}: {self.model_name} ({elapsed_time:.1f}ì´ˆ)"
                )

            return response, used_tools

        except Exception as e:
            error_msg = str(e)

            # í• ë‹¹ëŸ‰ ì´ˆê³¼ ì˜¤ë¥˜ ê°ì§€
            if "429" in error_msg and "quota" in error_msg.lower():
                logger.warning(
                    f"í• ë‹¹ëŸ‰ ì´ˆê³¼ ê°ì§€, ì²­í¬ ë¶„í•  ì²˜ë¦¬ ì‹œë„: {self.model_name}"
                )
                return self._handle_quota_exceeded(user_message, history)

            # ì—°ê²° ì˜¤ë¥˜ ê°ì§€
            elif any(
                keyword in error_msg.lower()
                for keyword in ["connection", "timeout", "network"]
            ):
                logger.error(f"ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {self.model_name} - {error_msg}")
                return "ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", []

            else:
                logger.error(f"AI í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜: {self.model_name} - {error_msg}")
                raise e

    def _handle_quota_exceeded(self, user_message: str, history: list):
        """í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ ì²­í¬ ë¶„í•  ì²˜ë¦¬"""
        # ê¸´ ë©”ì‹œì§€ë¥¼ ì²­í¬ë¡œ ë¶„í• 
        if len(user_message) > 1000:
            chunks = self._split_message_into_chunks(user_message, 800)
            responses = []

            for i, chunk in enumerate(chunks):
                try:
                    # ê° ì²­í¬ë¥¼ ê°„ë‹¨í•œ íˆìŠ¤í† ë¦¬ë¡œ ì²˜ë¦¬
                    simple_history = history[-2:] if history else []  # ìµœê·¼ 2ê°œë§Œ
                    chunk_response, _ = self.agent.process_message_with_history(
                        f"[{i+1}/{len(chunks)}] {chunk}",
                        simple_history,
                        force_agent=True,
                    )
                    responses.append(chunk_response)

                except Exception as chunk_error:
                    logger.error(f"ì²­í¬ {i+1} ì²˜ë¦¬ ì˜¤ë¥˜: {chunk_error}")
                    responses.append(
                        f"[ì²­í¬ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {str(chunk_error)[:100]}...]"
                    )

            return "\n\n".join(responses), []

        else:
            # ì§§ì€ ë©”ì‹œì§€ëŠ” íˆìŠ¤í† ë¦¬ ì—†ì´ ì²˜ë¦¬
            try:
                response, used_tools = self.agent.process_message(user_message)
                logger.info(f"í• ë‹¹ëŸ‰ ì´ˆê³¼ë¡œ íˆìŠ¤í† ë¦¬ ì—†ì´ ì²˜ë¦¬: {self.model_name}")
                return response, used_tools
            except Exception as fallback_error:
                return (
                    f"í• ë‹¹ëŸ‰ ì´ˆê³¼ ë° ëŒ€ì²´ ì²˜ë¦¬ ì‹¤íŒ¨: {str(fallback_error)[:200]}...",
                    [],
                )

    def _split_message_into_chunks(self, message: str, chunk_size: int = 800):
        """ë©”ì‹œì§€ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        if len(message) <= chunk_size:
            return [message]

        chunks = []
        sentences = message.split(". ")
        current_chunk = ""

        for sentence in sentences:
            if len(current_chunk + sentence) <= chunk_size:
                current_chunk += sentence + ". "
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + ". "

        if current_chunk:
            chunks.append(current_chunk.strip())

        return chunks

    def agent_chat(self, user_input: str):
        """ì—ì´ì „íŠ¸ ì±„íŒ… (í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ ì²­í¬ ë¶„í• ) - ì•ˆì •ì„± ê°œì„ """
        try:
            # ì…ë ¥ ê²€ì¦
            if not user_input or not isinstance(user_input, str):
                return "ìœ íš¨í•˜ì§€ ì•Šì€ ì…ë ¥ì…ë‹ˆë‹¤.", []

            user_input = user_input.strip()
            if not user_input:
                return "ë¹ˆ ë©”ì‹œì§€ëŠ” ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []

            logger.info(f"ì—ì´ì „íŠ¸ ì±„íŒ… ìš”ì²­: {user_input[:50]}...")

            # ëŒ€í™” ê¸°ë¡ì´ ë¹„ì–´ìˆìœ¼ë©´ íŒŒì¼ì—ì„œ ë¡œë“œ
            if not self.conversation_history:
                from core.conversation_history import ConversationHistory

                conv_hist = ConversationHistory()
                conv_hist.load_from_file()
                recent_messages = conv_hist.get_recent_messages(10)
                self.conversation_history = recent_messages
                logger.info(f"íŒŒì¼ì—ì„œ ëŒ€í™” ê¸°ë¡ ë¡œë“œ: {len(recent_messages)}ê°œ")

            optimized_history = self._optimize_conversation_history()
            logger.info(f"ìµœì í™”ëœ íˆìŠ¤í† ë¦¬ ì‚¬ìš©: {len(optimized_history)}ê°œ")

            result = self._process_with_quota_handling(
                user_input, optimized_history, force_agent=True
            )

            # ê²°ê³¼ê°€ íŠœí”Œì¸ì§€ í™•ì¸
            if isinstance(result, tuple):
                return result
            else:
                return result, []

        except Exception as e:
            error_msg = str(e)
            logger.error(f"ì—ì´ì „íŠ¸ ì±„íŒ… ì˜¤ë¥˜: {error_msg}")
            return (
                f"ì—ì´ì „íŠ¸ ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg[:100]}...",
                [],
            )

    def simple_chat(self, user_input: str):
        """ë‹¨ìˆœ ì±„íŒ… (ë„êµ¬ ì‚¬ìš© ì•ˆí•¨)"""
        try:
            # ì´ë¯¸ì§€ ë°ì´í„° ê°ì§€ ì‹œ OCR ìµœì í™” (ì¤„ë°”ê¿ˆ ë¬´ì‹œ)
            cleaned_input = user_input.replace("\n", "")
            has_start_tag = "[IMAGE_BASE64]" in cleaned_input
            has_end_tag = "[/IMAGE_BASE64]" in cleaned_input
            has_image_data = has_start_tag and has_end_tag
            
            print(f"[AIClient.simple_chat] ì´ë¯¸ì§€ ë°ì´í„° ê°ì§€: {has_image_data}")
            print(f"[AIClient.simple_chat] ì‹œì‘ íƒœê·¸: {has_start_tag}, ì¢…ë£Œ íƒœê·¸: {has_end_tag}")
            print(f"[AIClient.simple_chat] ì…ë ¥ ê¸¸ì´: {len(user_input)}")
            print(f"[AIClient.simple_chat] ì…ë ¥ ë¯¸ë¦¬ë³´ê¸°: {user_input[:200]}...")
            if "[IMAGE_BASE64]" in user_input:
                start_pos = user_input.find("[IMAGE_BASE64]")
                print(f"[AIClient.simple_chat] IMAGE_BASE64 ì‹œì‘ ìœ„ì¹˜: {start_pos}")
                print(f"[AIClient.simple_chat] í•´ë‹¹ ë¶€ë¶„: {user_input[start_pos:start_pos+50]}...")
            
            if has_image_data:
                # ì´ë¯¸ì§€ OCRì— ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
                ocr_prompt = """ì´ ì´ë¯¸ì§€ì—ì„œ **ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ì¶”ì¶œ(OCR)**í•´ì£¼ì„¸ìš”.

**í•„ìˆ˜ ì‘ì—…:**
1. **ì™„ì „í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ**: ì´ë¯¸ì§€ ë‚´ ëª¨ë“  í•œê¸€, ì˜ì–´, ìˆ«ì, ê¸°í˜¸ë¥¼ ë¹ ì§ì—†ì´ ì¶”ì¶œ
2. **êµ¬ì¡° ë¶„ì„**: í‘œ, ëª©ë¡, ì œëª©, ë‹¨ë½ ë“±ì˜ ë¬¸ì„œ êµ¬ì¡° íŒŒì•…
3. **ë ˆì´ì•„ì›ƒ ì •ë³´**: í…ìŠ¤íŠ¸ì˜ ìœ„ì¹˜, í¬ê¸°, ë°°ì¹˜ ê´€ê³„ ì„¤ëª…
4. **ì •í™•í•œ ì „ì‚¬**: ì˜¤íƒ€ ì—†ì´ ì •í™•í•˜ê²Œ ëª¨ë“  ë¬¸ì ê¸°ë¡
5. **ë§¥ë½ ì„¤ëª…**: ë¬¸ì„œì˜ ì¢…ë¥˜ì™€ ëª©ì  íŒŒì•…

**ì‘ë‹µ í˜•ì‹:**
## ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸
[ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ë‚˜ì—´]

## ğŸ“‹ ë¬¸ì„œ êµ¬ì¡°
[í‘œ, ëª©ë¡, ì œëª© ë“±ì˜ êµ¬ì¡° ì„¤ëª…]

## ğŸ“ ë ˆì´ì•„ì›ƒ ì •ë³´
[í…ìŠ¤íŠ¸ ë°°ì¹˜ì™€ ìœ„ì¹˜ ê´€ê³„]

**ì¤‘ìš”**: ì´ë¯¸ì§€ì—ì„œ ì½ì„ ìˆ˜ ìˆëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì ˆëŒ€ ëˆ„ë½í•˜ì§€ ë§ê³  ì™„ì „íˆ ì¶”ì¶œí•´ì£¼ì„¸ìš”."""
                
                enhanced_input = f"{ocr_prompt}\n\n{user_input}"
                print(f"[AIClient.simple_chat] OCR í”„ë¡¬í”„íŠ¸ ì¶”ê°€ ì™„ë£Œ")
                print(f"[AIClient.simple_chat] ìµœì¢… ì…ë ¥ ê¸¸ì´: {len(enhanced_input)}")
                result = self.agent.simple_chat(enhanced_input)
                print(f"[AIClient.simple_chat] AI ì‘ë‹µ ê¸¸ì´: {len(result)}")
                print(f"[AIClient.simple_chat] AI ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {result[:200]}...")
                return result
            else:
                print(f"[AIClient.simple_chat] ì¼ë°˜ í…ìŠ¤íŠ¸ ëª¨ë“œ")
                optimized_history = self._optimize_conversation_history()
                return self.agent.simple_chat_with_history(user_input, optimized_history)
        except Exception as e:
            print(f"[AIClient.simple_chat] ì˜¤ë¥˜ ë°œìƒ: {e}")
            logger.error(f"ë‹¨ìˆœ ì±„íŒ… ì˜¤ë¥˜: {e}")
            return f"ì˜¤ë¥˜: {e}"

    def _optimize_conversation_history(self):
        """ëŒ€í™” ê¸°ë¡ ìµœì í™” - í† í° ì‚¬ìš©ëŸ‰ ì ˆì•½"""
        if not self.conversation_history:
            return []

        # 1. ìµœê·¼ Nê°œ ëŒ€í™” ìŒë§Œ ìœ ì§€
        if len(self.conversation_history) > self.max_history_pairs * 2:
            # ë§ˆì§€ë§‰ ë©”ì‹œì§€ëŠ” í•­ìƒ ìœ ì§€
            recent_history = self.conversation_history[-(self.max_history_pairs * 2) :]
        else:
            recent_history = self.conversation_history.copy()

        # 2. í† í° ìˆ˜ ì¶”ì • ë° ì œí•œ
        optimized_history = self._limit_by_tokens(recent_history)

        return optimized_history

    def _estimate_tokens(self, text: str) -> int:
        """í† í° ìˆ˜ ëŒ€ëµ ì¶”ì • (í•œê¸€ 1ì = 1.5í† í°, ì˜ì–´ 1ë‹¨ì–´ = 1.3í† í°)"""
        if not text:
            return 0

        # í•œê¸€ê³¼ ì˜ì–´ ë¶„ë¦¬ ê³„ì‚°
        korean_chars = sum(1 for c in text if ord(c) >= 0xAC00 and ord(c) <= 0xD7A3)
        english_words = len([w for w in text.split() if w.isascii()])
        other_chars = len(text) - korean_chars

        estimated_tokens = int(
            korean_chars * 1.5 + english_words * 1.3 + other_chars * 0.8
        )
        return max(estimated_tokens, len(text) // 4)  # ìµœì†Œê°’ ë³´ì¥

    def _limit_by_tokens(self, history: list) -> list:
        """í† í° ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ëŒ€í™” ê¸°ë¡ ì œí•œ"""
        if not history:
            return []

        total_tokens = 0
        limited_history = []

        # ë§ˆì§€ë§‰ë¶€í„° ì—­ìˆœìœ¼ë¡œ ì²˜ë¦¬
        for msg in reversed(history):
            content = msg.get("content", "")
            msg_tokens = self._estimate_tokens(content)

            if total_tokens + msg_tokens > self.max_tokens_estimate:
                break

            limited_history.insert(0, msg)
            total_tokens += msg_tokens

        logger.info(
            f"ëŒ€í™” ê¸°ë¡ ìµœì í™”: {len(history)}ê°œ -> {len(limited_history)}ê°œ (ì˜ˆìƒ í† í°: {total_tokens})"
        )
        return limited_history

    def _load_user_prompt(self):
        """ìœ ì € í”„ë¡¬í”„íŠ¸ ë¡œë“œ"""
        try:
            from core.file_utils import load_config

            config = load_config()
            user_prompts = config.get(
                "user_prompt",
                {
                    "gpt": "ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¼ ë‹µë³€í•´ì£¼ì„¸ìš”: 1. êµ¬ì¡°í™”ëœ ë‹µë³€ 2. ê°€ë…ì„± ìš°ì„  3. ëª…í™•í•œ ë¶„ë¥˜ 4. í•µì‹¬ ìš”ì•½ 5. í•œêµ­ì–´ ì‚¬ìš©",
                    "gemini": "ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¼ ë‹µë³€í•´ì£¼ì„¸ìš”: 1. êµ¬ì¡°í™”ëœ ë‹µë³€ 2. ê°€ë…ì„± ìš°ì„  3. ëª…í™•í•œ ë¶„ë¥˜ 4. í•µì‹¬ ìš”ì•½ 5. í•œêµ­ì–´ ì‚¬ìš©",
                },
            )
            print(f"[ë””ë²„ê·¸] ë¡œë“œëœ ìœ ì € í”„ë¡¬í”„íŠ¸: {user_prompts}")
            return user_prompts
        except Exception as e:
            print(f"[ë””ë²„ê·¸] ìœ ì € í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return {
                "gpt": "ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¼ ë‹µë³€í•´ì£¼ì„¸ìš”: 1. êµ¬ì¡°í™”ëœ ë‹µë³€ 2. ê°€ë…ì„± ìš°ì„  3. ëª…í™•í•œ ë¶„ë¥˜ 4. í•µì‹¬ ìš”ì•½ 5. í•œêµ­ì–´ ì‚¬ìš©",
                "gemini": "ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¼ ë‹µë³€í•´ì£¼ì„¸ìš”: 1. êµ¬ì¡°í™”ëœ ë‹µë³€ 2. ê°€ë…ì„± ìš°ì„  3. ëª…í™•í•œ ë¶„ë¥˜ 4. í•µì‹¬ ìš”ì•½ 5. í•œêµ­ì–´ ì‚¬ìš©",
            }

    def get_current_user_prompt(self):
        """í˜„ì¬ ëª¨ë¸ì— ë§ëŠ” ìœ ì € í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
        if "gemini" in self.model_name.lower():
            return self.user_prompt.get("gemini", "")
        else:
            return self.user_prompt.get("gpt", "")

    def update_user_prompt(self, prompt_text, model_type="both"):
        """ìœ ì € í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸"""
        if model_type == "both":
            self.user_prompt["gpt"] = prompt_text
            self.user_prompt["gemini"] = prompt_text
        elif model_type == "gpt":
            self.user_prompt["gpt"] = prompt_text
        elif model_type == "gemini":
            self.user_prompt["gemini"] = prompt_text

        # ì„¤ì • íŒŒì¼ì— ì €ì¥
        self._save_user_prompt()

    def _save_user_prompt(self):
        """ìœ ì € í”„ë¡¬í”„íŠ¸ ì €ì¥"""
        try:
            from core.file_utils import load_config, save_config

            config = load_config()
            config["user_prompt"] = self.user_prompt
            save_config(config)
            logger.info(f"ìœ ì € í”„ë¡¬í”„íŠ¸ ì €ì¥ ì™„ë£Œ: {self.user_prompt}")
        except Exception as e:
            logger.error(f"ìœ ì € í”„ë¡¬í”„íŠ¸ ì €ì¥ ì˜¤ë¥˜: {e}")
            print(f"ìœ ì € í”„ë¡¬í”„íŠ¸ ì €ì¥ ì˜¤ë¥˜: {e}")


# ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ì „ì—­ í´ë¼ì´ì–¸íŠ¸
mcp_client = None


def get_mcp_client():
    global mcp_client
    return mcp_client


def set_mcp_client(client):
    global mcp_client
    mcp_client = client
