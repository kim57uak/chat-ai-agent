from typing import List, Dict, Tuple
from .base_chat_processor import BaseChatProcessor
from core.token_logger import TokenLogger
from core.token_tracker import token_tracker, StepType
from core.token_tracking import get_unified_tracker, ChatModeType
from core.logging import get_logger
import time

logger = get_logger("tool_chat_processor")


class ToolChatProcessor(BaseChatProcessor):
    """ë„êµ¬ ì‚¬ìš© ì±„íŒ… ì²˜ë¦¬ê¸°"""
    
    def __init__(self, model_strategy, tools: List = None):
        super().__init__(model_strategy)
        self.tools = tools or []
        self._agent_executor = None
    
    def supports_tools(self) -> bool:
        """ë„êµ¬ ì§€ì› ì—¬ë¶€"""
        return True
    
    def process_message(self, user_input: str, conversation_history: List[Dict] = None) -> Tuple[str, List]:
        """ë„êµ¬ ì‚¬ìš© ì±„íŒ… ì²˜ë¦¬ - ì‹œê°„ ì œí•œ ë° ë°˜ë³µ ì œí•œ ì ìš©"""
        try:
            # Unified tracker ì‹œì‘
            start_time = time.time()
            unified_tracker = None
            try:
                from core.security.secure_path_manager import secure_path_manager
                db_path = secure_path_manager.get_database_path()
                unified_tracker = get_unified_tracker(db_path)
                unified_tracker.start_conversation(
                    mode=ChatModeType.TOOL,
                    model=self.model_strategy.model_name,
                    session_id=self.session_id
                )
            except Exception as e:
                logger.debug(f"Unified tracker not initialized: {e}")
                unified_tracker = None
            
            # ëŒ€í™” íŠ¸ë˜í‚¹ ì‹œì‘ (í˜„ì¬ ëŒ€í™”ê°€ ì—†ëŠ” ê²½ìš°)
            if not token_tracker.current_conversation:
                token_tracker.start_conversation(user_input, self.model_strategy.model_name)
            
            # í† í° íŠ¸ë˜í‚¹ ì‹œì‘
            token_tracker.start_step(StepType.TOOL_DECISION, "Tool Usage Decision")
            
            if not self.validate_input(user_input):
                return "ìœ íš¨í•˜ì§€ ì•Šì€ ì…ë ¥ì…ë‹ˆë‹¤.", []
            
            if not self.tools:
                return "ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤.", []
            
            start_time = time.time()
            logger.info(f"ë„êµ¬ ì±„íŒ… ì‹œì‘: {user_input[:50]}...")
            
            # ë„êµ¬ ê²°ì • ë‹¨ê³„ ì¢…ë£Œ
            token_tracker.end_step(
                StepType.TOOL_DECISION,
                "Tool Usage Decision",
                input_text=user_input,
                output_text=f"Using {len(self.tools)} available tools"
            )
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸° ìƒì„± (ì§€ì—° ë¡œë”©)
            if not self._agent_executor:
                self._agent_executor = self.model_strategy.create_agent_executor(self.tools)
            
            if not self._agent_executor:
                return "ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []
            
            # ëª¨ë¸ë³„ ì‹œê°„ ì œí•œ ì„¤ì • (ë” ì—¬ìœ ë¡­ê²Œ)
            if 'gemini' in self.model_strategy.model_name.lower():
                timeout = 240  # GeminiëŠ” 240ì´ˆ
            elif 'gpt-4' in self.model_strategy.model_name.lower():
                timeout = 180  # GPT-4ëŠ” 180ì´ˆ
            else:
                timeout = 120  # ë‹¤ë¥¸ ëª¨ë¸ì€ 120ì´ˆ
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰ - ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨
            try:
                # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í¬í•¨í•œ ì…ë ¥ êµ¬ì„±
                agent_input = {"input": user_input}
                
                # ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ìˆìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
                if conversation_history:
                    history_context = self._format_conversation_history(conversation_history)
                    enhanced_input = f"Previous conversation context:\n{history_context}\n\nCurrent question: {user_input}"
                    agent_input["input"] = enhanced_input
                    logger.info(f"Agent ëª¨ë“œì— ëŒ€í™” íˆìŠ¤í† ë¦¬ {len(conversation_history)}ê°œ ì „ë‹¬")
                
                # ì—ì´ì „íŠ¸ ì‹¤í–‰ ì „ ì…ë ¥ í† í° ë¡œê¹…ì„ ìœ„í•œ ì¤€ë¹„
                input_text = agent_input["input"]
                
                # ë„êµ¬ ì‹¤í–‰ ë‹¨ê³„ ì‹œì‘
                token_tracker.start_step(StepType.TOOL_EXECUTION, "Agent Tool Execution")
                
                result = self._agent_executor.invoke(agent_input)
                
                # ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ í† í° ë¡œê¹… ë° íˆìŠ¤í† ë¦¬ ì €ì¥
                output_text = result.get("output", "")
                if output_text:
                    # MCP ë„êµ¬ ê²°ê³¼ë¥¼ í¬í•¨í•œ ì „ì²´ ì…ë ¥ í† í° ê³„ì‚°
                    total_input_text = input_text
                    
                    # ì¤‘ê°„ ë‹¨ê³„ì—ì„œ ë„êµ¬ ê²°ê³¼ ì¶”ì¶œí•˜ì—¬ ì…ë ¥ í† í°ì— í¬í•¨
                    intermediate_steps = result.get("intermediate_steps", [])
                    tool_results_text = ""
                    used_tools = []
                    
                    for step in intermediate_steps:
                        if len(step) >= 2:
                            action, observation = step[0], step[1]
                            # ë„êµ¬ëª… ì¶”ì¶œ
                            tool_name = getattr(action, 'tool', 'unknown_tool')
                            used_tools.append(tool_name)
                            
                            if observation and str(observation).strip():
                                tool_results_text += f"\nTool Result: {str(observation)}"
                    
                    # ë„êµ¬ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì…ë ¥ í† í°ì— ì¶”ê°€
                    if tool_results_text:
                        total_input_text += tool_results_text
                        logger.info(f"MCP ë„êµ¬ ê²°ê³¼ {len(tool_results_text)} ë¬¸ìë¥¼ ì…ë ¥ í† í°ì— ì¶”ê°€")
                    
                    # ì‹¤ì œ í† í° ì •ë³´ ì¶”ì¶œ
                    actual_input, actual_output = 0, 0
                    if hasattr(self.model_strategy, '_last_response') and self.model_strategy._last_response:
                        actual_input, actual_output = TokenLogger.extract_actual_tokens(self.model_strategy._last_response)
                        logger.info(f"ì‹¤ì œ í† í° ì¶”ì¶œ: IN:{actual_input}, OUT:{actual_output}")
                    else:
                        logger.warning("_last_response ì—†ìŒ - ì‹¤ì œ í† í° ì¶”ì¶œ ë¶ˆê°€")
                    
                    # ë„êµ¬ ì‹¤í–‰ ë‹¨ê³„ ì¢…ë£Œ
                    token_tracker.end_step(
                        StepType.TOOL_EXECUTION,
                        "Agent Tool Execution",
                        input_text=total_input_text,
                        output_text=output_text,
                        response_obj=getattr(self.model_strategy, '_last_response', None),
                        tool_name=",".join(used_tools) if used_tools else None,
                        additional_info={
                            "intermediate_steps_count": len(intermediate_steps),
                            "input_tokens": actual_input,
                            "output_tokens": actual_output,
                            "total_tokens": actual_input + actual_output
                        }
                    )
                    
                    # ì‹¤ì œ í† í° ì •ë³´ ì¶”ì¶œ
                    input_tokens, output_tokens = 0, 0
                    if hasattr(self.model_strategy, '_last_response') and self.model_strategy._last_response:
                        input_tokens, output_tokens = TokenLogger.extract_actual_tokens(self.model_strategy._last_response)
                        logger.info(f"TOOL ëª¨ë“œ ì‹¤ì œ í† í°: IN:{input_tokens}, OUT:{output_tokens}")
                    
                    # ì‹¤ì œ í† í°ì´ ì—†ìœ¼ë©´ ì¶”ì •ì¹˜ ì‚¬ìš© (ë„êµ¬ ê²°ê³¼ í¬í•¨)
                    if input_tokens == 0 and output_tokens == 0:
                        input_tokens = TokenLogger.estimate_tokens(total_input_text, self.model_strategy.model_name)
                        output_tokens = TokenLogger.estimate_tokens(output_text, self.model_strategy.model_name)
                        logger.warning(f"TOOL ëª¨ë“œ ì¶”ì • í† í° ì‚¬ìš©: IN:{input_tokens}, OUT:{output_tokens}")
                    
                    # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— í† í° ì •ë³´ì™€ í•¨ê»˜ ì €ì¥
                    if hasattr(self, 'conversation_history') and self.conversation_history:
                        total_tokens = input_tokens + output_tokens if input_tokens > 0 or output_tokens > 0 else None
                        self.conversation_history.add_message(
                            "assistant", 
                            output_text, 
                            model_name=self.model_strategy.model_name,
                            input_tokens=input_tokens if input_tokens > 0 else None,
                            output_tokens=output_tokens if output_tokens > 0 else None,
                            total_tokens=total_tokens
                        )
                    
            except Exception as agent_error:
                error_msg = str(agent_error)
                
                # No generation chunks ì˜¤ë¥˜ ì²˜ë¦¬
                if "No generation chunks were returned" in error_msg:
                    logger.warning(f"Generation chunks ì˜¤ë¥˜ ë°œìƒ, ë‹¨ìˆœ ì±„íŒ…ìœ¼ë¡œ ëŒ€ì²´: {error_msg[:100]}")
                    from .simple_chat_processor import SimpleChatProcessor
                    simple_processor = SimpleChatProcessor(self.model_strategy)
                    return simple_processor.process_message(user_input, conversation_history)
                
                # í† í° ì œí•œ ì˜¤ë¥˜ ì²˜ë¦¬ (ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘)
                if "context_length_exceeded" in error_msg or "maximum context length" in error_msg:
                    logger.warning(f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ í† í° ì œí•œ ì˜¤ë¥˜ ë°œìƒ, ë‹¨ìˆœ ì±„íŒ…ìœ¼ë¡œ ëŒ€ì²´: {error_msg[:100]}")
                    from .simple_chat_processor import SimpleChatProcessor
                    simple_processor = SimpleChatProcessor(self.model_strategy)
                    return simple_processor.process_message(user_input, conversation_history)
                
                # ì‹œê°„ ì´ˆê³¼ ë° Agent stopped ì˜¤ë¥˜ ì²˜ë¦¬ - Gemini íŠ¹ë³„ ì²˜ë¦¬
                if (self._is_agent_stopped_error(error_msg)):
                    logger.warning(f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œê°„/ë°˜ë³µ ì œí•œ ë„ë‹¬: {error_msg[:100]}")
                    # Geminiì˜ ê²½ìš° ë¶€ë¶„ ê²°ê³¼ë¼ë„ í™œìš© ì‹œë„
                    if 'gemini' in self.model_strategy.model_name.lower():
                        try:
                            # ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°ì—ì„œ ë¶€ë¶„ ê²°ê³¼ ì¶”ì¶œ ì‹œë„
                            partial_result = getattr(self._agent_executor, '_last_result', None)
                            if partial_result and isinstance(partial_result, dict):
                                return self._handle_agent_stopped(partial_result, user_input)
                        except:
                            pass
                    return "ìš”ì²­ì´ ë³µì¡í•˜ì—¬ ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì´ê³  ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", []
                
                # íŒŒì‹± ì˜¤ë¥˜ ë˜ëŠ” í˜•ì‹ ì˜¤ë¥˜ ì²˜ë¦¬
                if any(keyword in error_msg.lower() for keyword in ["parse", "format", "invalid format", "exact format"]):
                    logger.warning(f"ì—ì´ì „íŠ¸ í˜•ì‹ ì˜¤ë¥˜ ê°ì§€, ë‹¨ìˆœ ì±„íŒ…ìœ¼ë¡œ ì „í™˜: {error_msg[:100]}")
                    from .simple_chat_processor import SimpleChatProcessor
                    simple_processor = SimpleChatProcessor(self.model_strategy)
                    return simple_processor.process_message(user_input, conversation_history)
                else:
                    raise agent_error
            
            output = result.get("output", "")
            
            # Agent stopped ë©”ì‹œì§€ í™•ì¸ - ë‹¤ì–‘í•œ í˜•íƒœ ê°ì§€
            if self._is_agent_stopped_message(output):
                logger.warning(f"ì—ì´ì „íŠ¸ ì¤‘ë‹¨ ë©”ì‹œì§€ ê°ì§€: {output[:100]}")
                return self._handle_agent_stopped(result, user_input)
            
            # ì‚¬ìš©ëœ ë„êµ¬ ì •ë³´ ì¶”ì¶œ
            used_tools = self._extract_used_tools(result)
            
            # ê²°ê³¼ ê²€ì¦ ë° ì²˜ë¦¬
            if not output or not output.strip() or len(output.strip()) < 10:
                logger.warning("ì—ì´ì „íŠ¸ ê²°ê³¼ ë¶€ì¡±, ê²°ê³¼ í™•ì¸ ì¤‘...")
                return self._handle_agent_stopped(result, user_input)
            
            elapsed = time.time() - start_time
            logger.debug(f"ë„êµ¬ ì±„íŒ… ì™„ë£Œ: {elapsed:.2f}ì´ˆ")
            
            # Unified tracker ê¸°ë¡
            if unified_tracker:
                # ì‹¤ì œ í† í° ì¶”ì¶œ
                actual_input, actual_output = 0, 0
                if hasattr(self.model_strategy, '_last_response') and self.model_strategy._last_response:
                    actual_input, actual_output = TokenLogger.extract_actual_tokens(self.model_strategy._last_response)
                    logger.info(f"TOOL ëª¨ë“œ ì‹¤ì œ í† í°: IN:{actual_input}, OUT:{actual_output}")
                
                # ì‹¤ì œ í† í°ì´ ì—†ìœ¼ë©´ ì¶”ì •ì¹˜ ì‚¬ìš© (ë„êµ¬ ê²°ê³¼ í¬í•¨)
                if actual_input == 0 and actual_output == 0:
                    input_text = user_input
                    intermediate_steps = result.get("intermediate_steps", [])
                    if intermediate_steps:
                        for step in intermediate_steps:
                            if len(step) >= 2:
                                observation = str(step[1])
                                input_text += "\n" + observation
                    
                    actual_input = TokenLogger.estimate_tokens(input_text, self.model_strategy.model_name)
                    actual_output = TokenLogger.estimate_tokens(output, self.model_strategy.model_name)
                    logger.warning(f"TOOL ëª¨ë“œ ì¶”ì • í† í° ì‚¬ìš©: IN:{actual_input}, OUT:{actual_output}")
                
                if actual_input > 0:
                    duration_ms = (time.time() - start_time) * 1000
                    unified_tracker.track_agent(
                        agent_name="MCPAgent",
                        model=self.model_strategy.model_name,
                        input_tokens=actual_input,
                        output_tokens=actual_output,
                        tool_calls=used_tools,
                        duration_ms=duration_ms
                    )
                unified_tracker.end_conversation()
            
            # ëŒ€í™” ì¢…ë£Œ
            if token_tracker.current_conversation:
                token_tracker.end_conversation(output)
            
            return self.format_response(output), used_tools
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"ë„êµ¬ ì±„íŒ… ì˜¤ë¥˜: {e}")
            import traceback
            logger.error(f"Full traceback: {traceback.format_exc()}")
            
            # 'str' object has no attribute 'text' ì˜¤ë¥˜ íŠ¹ë³„ ì²˜ë¦¬
            if "'str' object has no attribute 'text'" in error_msg:
                logger.error("Claude ëª¨ë¸ì—ì„œ text ì†ì„± ì˜¤ë¥˜ ë°œìƒ - ë‹¨ìˆœ ì±„íŒ…ìœ¼ë¡œ ëŒ€ì²´")
                from .simple_chat_processor import SimpleChatProcessor
                simple_processor = SimpleChatProcessor(self.model_strategy)
                return simple_processor.process_message(user_input, conversation_history)
            
            # Agent stopped ì˜¤ë¥˜ ì²˜ë¦¬
            if self._is_agent_stopped_error(error_msg):
                return "ìš”ì²­ ì²˜ë¦¬ê°€ ë³µì¡í•˜ì—¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë” ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", []
            
            # í† í° ì œí•œ ì˜¤ë¥˜ ì²˜ë¦¬
            if "context_length_exceeded" in error_msg or "maximum context length" in error_msg:
                logger.warning("í† í° ì œí•œ ì˜¤ë¥˜ ë°œìƒ, ë‹¨ìˆœ ì±„íŒ…ìœ¼ë¡œ ëŒ€ì²´")
                from .simple_chat_processor import SimpleChatProcessor
                simple_processor = SimpleChatProcessor(self.model_strategy)
                return simple_processor.process_message(user_input, conversation_history)
            
            # ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€
            return "ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", []
    
    def _is_agent_stopped_error(self, error_msg: str) -> bool:
        """ì—ì´ì „íŠ¸ ì¤‘ë‹¨ ì˜¤ë¥˜ ë©”ì‹œì§€ ê°ì§€"""
        agent_stopped_patterns = [
            "Agent stopped due to iteration limit or time limit",
            "Agent stopped due to max iterations",
            "Agent stopped due to time limit",
            "max_execution_time",
            "max_iterations",
            "timeout",
            "time limit exceeded",
            "iteration limit exceeded"
        ]
        
        error_lower = error_msg.lower()
        return any(pattern.lower() in error_lower for pattern in agent_stopped_patterns)
    
    def _is_agent_stopped_message(self, output: str) -> bool:
        """ì—ì´ì „íŠ¸ ì¤‘ë‹¨ ë©”ì‹œì§€ ê°ì§€"""
        if not output:
            return False
            
        stopped_patterns = [
            "Agent stopped due to iteration limit or time limit",
            "Agent stopped due to max iterations", 
            "Agent stopped due to time limit",
            "I need to stop here",
            "I'll stop here",
            "I cannot continue",
            "ì‹œê°„ì´ ì´ˆê³¼",
            "ë°˜ë³µ ì œí•œ",
            "ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼"
        ]
        
        output_lower = output.lower()
        return any(pattern.lower() in output_lower for pattern in stopped_patterns)
    
    def _handle_agent_stopped(self, result: Dict, user_input: str) -> Tuple[str, List]:
        """ì—ì´ì „íŠ¸ ì¤‘ë‹¨ ìƒí™© ì²˜ë¦¬ - ë„êµ¬ ê²°ê³¼ í™œìš©"""
        intermediate_steps = result.get("intermediate_steps", [])
        
        if intermediate_steps:
            logger.info(f"ì¤‘ê°„ ë‹¨ê³„ {len(intermediate_steps)}ê°œ ë°œê²¬, ë¶€ë¶„ ê²°ê³¼ í™œìš©")
            
            # ëª¨ë“  ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ìˆ˜ì§‘
            tool_results = []
            used_tools = []
            
            for step in intermediate_steps:
                if len(step) >= 2:
                    action, observation = step[0], step[1]
                    
                    # ë„êµ¬ëª… ì¶”ì¶œ
                    tool_name = getattr(action, 'tool', 'unknown_tool')
                    used_tools.append(tool_name)
                    
                    # ê²°ê³¼ ë°ì´í„° ì¶”ì¶œ
                    if observation and str(observation).strip():
                        tool_results.append(str(observation))
            
            # ë„êµ¬ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í¬ë§·íŒ…í•˜ì—¬ ë°˜í™˜
            if tool_results:
                # ë§ˆì§€ë§‰ ë„êµ¬ ê²°ê³¼ ì‚¬ìš© (ê°€ì¥ ìµœì‹ )
                final_result = tool_results[-1]
                
                # JSON ë°ì´í„°ì¸ì§€ í™•ì¸í•˜ê³  íŒŒì‹± ì‹œë„
                try:
                    import json
                    if '{' in final_result and '}' in final_result:
                        # JSON ë¶€ë¶„ ì¶”ì¶œ
                        start = final_result.find('{')
                        end = final_result.rfind('}') + 1
                        json_str = final_result[start:end]
                        data = json.loads(json_str)
                        
                        # ì—¬í–‰ ìƒí’ˆ ë°ì´í„° í¬ë§·íŒ…
                        if 'data' in data and 'saleProductList' in data['data']:
                            products = data['data']['saleProductList']
                            if products:
                                response = "ê²€ìƒ‰ëœ ì—¬í–‰ ìƒí’ˆ ì •ë³´:\n\n"
                                for i, product in enumerate(products[:5], 1):
                                    response += f"{i}. **{product.get('saleProductName', 'N/A')}**\n"
                                    response += f"   - ìƒí’ˆì½”ë“œ: {product.get('saleProductCode', 'N/A')}\n"
                                    response += f"   - ê°€ê²©: {product.get('allProductPrice', 'N/A'):,}ì›\n"
                                    response += f"   - ì¶œë°œì¼: {product.get('departureDay', 'N/A')}\n"
                                    response += f"   - ë„ì°©ì¼: {product.get('arrivalDay', 'N/A')}\n\n"
                                
                                total_count = data['data'].get('resultCount', len(products))
                                response += f"ì´ {total_count}ê°œ ìƒí’ˆì´ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤."
                                return response, used_tools
                except:
                    pass
                
                # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ ì²˜ë¦¬
                formatted_result, tools = self._format_tool_result(final_result, used_tools)
                
                # MCP ë„êµ¬ ì‚¬ìš© ì‹œ í† í° ë¡œê¹… (ë¶€ë¶„ ê²°ê³¼)
                self._log_mcp_token_usage(user_input, tool_results, formatted_result)
                
                return formatted_result, tools
        
        return "ìš”ì²­ì´ ë³µì¡í•˜ì—¬ ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì´ê³  ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", []
    
    def _extract_used_tools(self, result: Dict) -> List:
        """ì‚¬ìš©ëœ ë„êµ¬ ì •ë³´ ì¶”ì¶œ"""
        used_tools = []
        intermediate_steps = result.get("intermediate_steps", [])
        
        for step in intermediate_steps:
            if len(step) >= 2:
                action = step[0]
                if hasattr(action, 'tool'):
                    used_tools.append(action.tool)
                elif isinstance(action, dict) and 'tool' in action:
                    used_tools.append(action['tool'])
        
        return list(set(used_tools))  # ì¤‘ë³µ ì œê±°
    
    def _format_conversation_history(self, conversation_history: List[Dict]) -> str:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        if not conversation_history:
            return ""
        
        formatted_history = []
        for msg in conversation_history[-5:]:  # ìµœê·¼ 5ê°œë§Œ ì‚¬ìš©
            role = msg.get('role', 'unknown')
            content = msg.get('content', '')
            if content and len(content.strip()) > 0:
                formatted_history.append(f"{role}: {content[:200]}...")
        
        return "\n".join(formatted_history)
    
    def _format_tool_result(self, result: str, used_tools: List) -> Tuple[str, List]:
        """ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ í¬ë§·íŒ…"""
        try:
            import json
            # JSON í˜•íƒœì˜ ê²°ê³¼ì¸ì§€ í™•ì¸
            if result.strip().startswith('{') and result.strip().endswith('}'):
                data = json.loads(result)
                
                # ì„±ê³µì ì¸ ì‘ì—… ì™„ë£Œ ë©”ì‹œì§€ ì²˜ë¦¬
                if 'content' in data and isinstance(data['content'], list):
                    for content_item in data['content']:
                        if isinstance(content_item, dict) and content_item.get('type') == 'text':
                            text_content = content_item.get('text', '')
                            if 'written' in text_content.lower() or 'created' in text_content.lower():
                                # íŒŒì¼ ì‘ì—… ì™„ë£Œ ë©”ì‹œì§€
                                if 'excel' in used_tools[0].lower() if used_tools else False:
                                    return "âœ… **ì—‘ì…€ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!**\n\nğŸ“Š ìš”ì²­í•˜ì‹  ë°ì´í„°ê°€ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.", used_tools
                                else:
                                    return f"âœ… **ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!**\n\n{text_content}", used_tools
                
                # êµ¬ì¡°í™”ëœ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
                if 'structuredContent' in data:
                    structured = data['structuredContent']
                    if isinstance(structured, dict) and 'result' in structured:
                        result_text = structured['result']
                        if 'written' in result_text.lower():
                            return "âœ… **íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!**\n\nğŸ“„ ìš”ì²­í•˜ì‹  ë°ì´í„°ê°€ íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.", used_tools
                        return f"âœ… **ì‘ì—… ì™„ë£Œ:** {result_text}", used_tools
                
                # ì¼ë°˜ì ì¸ ì„±ê³µ ì‘ë‹µ
                if data.get('isError') == False:
                    return "âœ… **ìš”ì²­í•˜ì‹  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!**", used_tools
            
            # JSONì´ ì•„ë‹Œ ì¼ë°˜ í…ìŠ¤íŠ¸ ê²°ê³¼
            if 'success' in result.lower() or 'completed' in result.lower():
                return f"âœ… **ì‘ì—… ì™„ë£Œ:** {result[:200]}", used_tools
            
            return f"ğŸ“‹ **ê²°ê³¼:** {result[:500]}{'...' if len(result) > 500 else ''}", used_tools
            
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
            return f"ğŸ“‹ **ê²°ê³¼:** {result[:500]}{'...' if len(result) > 500 else ''}", used_tools
        except Exception:
            return "âœ… **ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.**", used_tools
    
    def _log_mcp_token_usage(self, user_input: str, tool_results: List[str], ai_response: str):
        """MCP ë„êµ¬ ì‚¬ìš© ì‹œ í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…"""
        try:
            # ì „ì²´ ì…ë ¥ í† í° ê³„ì‚° (ì‚¬ìš©ì ì…ë ¥ + ë„êµ¬ ê²°ê³¼)
            total_input = user_input
            if tool_results:
                tool_text = "\n".join(tool_results)
                total_input += f"\n\nMCP Tool Results:\n{tool_text}"
            
            # í† í° ì¶”ì •
            input_tokens = TokenLogger.estimate_tokens(total_input, self.model_strategy.model_name)
            output_tokens = TokenLogger.estimate_tokens(ai_response, self.model_strategy.model_name)
            
            # ë¡œê¹…
            TokenLogger.log_token_usage(
                self.model_strategy.model_name, 
                total_input, 
                ai_response, 
                "mcp_partial_result"
            )
            
        except Exception as e:
            logger.warning(f"MCP í† í° ë¡œê¹… ì‹¤íŒ¨: {e}")