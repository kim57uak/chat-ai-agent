from typing import List, Dict, Tuple
from .base_chat_processor import BaseChatProcessor
from core.token_logger import TokenLogger
import logging
import time

logger = logging.getLogger(__name__)


class ToolChatProcessor(BaseChatProcessor):
    """ë„êµ¬ ì‚¬ìš© ì±„íŒ… ì²˜ë¦¬ê¸°"""
    
    def __init__(self, model_strategy, tools: List = None):
        super().__init__(model_strategy)
        self.tools = tools or []
        self._agent_executor = None
    
    def process_message(self, user_input: str, conversation_history: List[Dict] = None) -> Tuple[str, List]:
        """ë„êµ¬ ì‚¬ìš© ì±„íŒ… ì²˜ë¦¬ - ì‹œê°„ ì œí•œ ë° ë°˜ë³µ ì œí•œ ì ìš©"""
        try:
            if not self.validate_input(user_input):
                return "ìœ íš¨í•˜ì§€ ì•Šì€ ì…ë ¥ì…ë‹ˆë‹¤.", []
            
            if not self.tools:
                return "ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤.", []
            
            start_time = time.time()
            logger.info(f"ë„êµ¬ ì±„íŒ… ì‹œì‘: {user_input[:50]}...")
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸° ìƒì„± (ì§€ì—° ë¡œë”©)
            if not self._agent_executor:
                self._agent_executor = self.model_strategy.create_agent_executor(self.tools)
            
            if not self._agent_executor:
                return "ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []
            
            # ì‹œê°„ ì œí•œ ì„¤ì • (30ì´ˆ)
            timeout = 30
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰ - ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨
            try:
                # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í¬í•¨í•œ ì…ë ¥ êµ¬ì„±
                agent_input = {"input": user_input}
                
                # ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ìˆìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
                if conversation_history:
                    history_context = self._format_conversation_history(conversation_history)
                    enhanced_input = f"Previous conversation context:\n{history_context}\n\nCurrent question: {user_input}"
                    agent_input["input"] = enhanced_input
                    logger.info(f"Agent ëª¨ë“œì— ëŒ€í™” íˆìŠ¤í† ë¦¬ {len(conversation_history)}ê°œ ì „ë‹¬")
                
                # ì—ì´ì „íŠ¸ ì‹¤í–‰ ì „ ì…ë ¥ í† í° ë¡œê¹…ì„ ìœ„í•œ ì¤€ë¹„
                input_text = agent_input["input"]
                
                result = self._agent_executor.invoke(agent_input)
                
                # ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ í† í° ë¡œê¹…
                output_text = result.get("output", "")
                if output_text:
                    TokenLogger.log_token_usage(
                        self.model_strategy.model_name, input_text, output_text, "agent_execution"
                    )
                    
            except Exception as agent_error:
                error_msg = str(agent_error)
                
                # ì‹œê°„ ì´ˆê³¼ ë° Agent stopped ì˜¤ë¥˜ ì²˜ë¦¬
                if (self._is_agent_stopped_error(error_msg)):
                    logger.warning(f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œê°„/ë°˜ë³µ ì œí•œ ë„ë‹¬: {error_msg[:100]}")
                    return "ìš”ì²­ì´ ë³µì¡í•˜ì—¬ ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì´ê³  ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", []
                
                # íŒŒì‹± ì˜¤ë¥˜ ì²˜ë¦¬
                if "parse" in error_msg.lower() or "format" in error_msg.lower():
                    logger.warning(f"ì—ì´ì „íŠ¸ íŒŒì‹± ì˜¤ë¥˜: {error_msg[:200]}...")
                    
                    # ë‹¨ìˆœ ì±„íŒ…ìœ¼ë¡œ ëŒ€ì²´
                    logger.info("íŒŒì‹± ì˜¤ë¥˜ë¡œ ì¸í•´ ë‹¨ìˆœ ì±„íŒ…ìœ¼ë¡œ ëŒ€ì²´")
                    from .simple_chat_processor import SimpleChatProcessor
                    simple_processor = SimpleChatProcessor(self.model_strategy)
                    return simple_processor.process_message(user_input, conversation_history)
                else:
                    raise agent_error
            
            output = result.get("output", "")
            
            # Agent stopped ë©”ì‹œì§€ í™•ì¸ - ë‹¤ì–‘í•œ í˜•íƒœ ê°ì§€
            if self._is_agent_stopped_message(output):
                logger.warning(f"ì—ì´ì „íŠ¸ ì¤‘ë‹¨ ë©”ì‹œì§€ ê°ì§€: {output[:100]}")
                return self._handle_agent_stopped(result, user_input)
            
            # ì‚¬ìš©ëœ ë„êµ¬ ì •ë³´ ì¶”ì¶œ
            used_tools = self._extract_used_tools(result)
            
            # ê²°ê³¼ ê²€ì¦ ë° ì²˜ë¦¬
            if not output or not output.strip() or len(output.strip()) < 10:
                logger.warning("ì—ì´ì „íŠ¸ ê²°ê³¼ ë¶€ì¡±, ê²°ê³¼ í™•ì¸ ì¤‘...")
                return self._handle_agent_stopped(result, user_input)
            
            elapsed = time.time() - start_time
            logger.info(f"ë„êµ¬ ì±„íŒ… ì™„ë£Œ: {elapsed:.2f}ì´ˆ")
            return self.format_response(output), used_tools
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"ë„êµ¬ ì±„íŒ… ì˜¤ë¥˜: {e}")
            
            # Agent stopped ì˜¤ë¥˜ ì²˜ë¦¬
            if self._is_agent_stopped_error(error_msg):
                return "ìš”ì²­ ì²˜ë¦¬ê°€ ë³µì¡í•˜ì—¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë” ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", []
            
            # í† í° ì œí•œ ì˜¤ë¥˜ ì²˜ë¦¬
            if "context_length_exceeded" in error_msg or "maximum context length" in error_msg:
                logger.warning("í† í° ì œí•œ ì˜¤ë¥˜ ë°œìƒ, ë‹¨ìˆœ ì±„íŒ…ìœ¼ë¡œ ëŒ€ì²´")
                from .simple_chat_processor import SimpleChatProcessor
                simple_processor = SimpleChatProcessor(self.model_strategy)
                return simple_processor.process_message(user_input, conversation_history)
            
            return f"ë„êµ¬ ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)[:100]}...", []
    
    def _is_agent_stopped_error(self, error_msg: str) -> bool:
        """ì—ì´ì „íŠ¸ ì¤‘ë‹¨ ì˜¤ë¥˜ ë©”ì‹œì§€ ê°ì§€"""
        agent_stopped_patterns = [
            "Agent stopped due to iteration limit or time limit",
            "Agent stopped due to max iterations",
            "timeout",
            "time limit",
            "iteration limit",
            "max iterations"
        ]
        
        error_lower = error_msg.lower()
        return any(pattern.lower() in error_lower for pattern in agent_stopped_patterns)
    
    def _is_agent_stopped_message(self, output: str) -> bool:
        """ì—ì´ì „íŠ¸ ì¤‘ë‹¨ ë©”ì‹œì§€ ê°ì§€"""
        if not output:
            return False
            
        agent_stopped_patterns = [
            "Agent stopped due to iteration limit or time limit",
            "Agent stopped due to max iterations",
            "Agent stopped",
            "max iterations",
            "iteration limit",
            "time limit"
        ]
        
        output_lower = output.lower()
        return any(pattern.lower() in output_lower for pattern in agent_stopped_patterns)
    
    def supports_tools(self) -> bool:
        """ë„êµ¬ ì§€ì›í•¨"""
        return True
    
    def _format_conversation_history(self, conversation_history: List[Dict]) -> str:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        formatted_history = []
        for msg in conversation_history[-6:]:  # ìµœê·¼ 6ê°œë§Œ
            role = msg.get("role", "")
            content = msg.get("content", "")[:300]  # ë‚´ìš© ì œí•œ
            
            if role == "user":
                formatted_history.append(f"User: {content}")
            elif role == "assistant":
                formatted_history.append(f"Assistant: {content}")
        
        return "\n".join(formatted_history)
    
    def set_tools(self, tools: List):
        """ë„êµ¬ ì„¤ì •"""
        self.tools = tools
        self._agent_executor = None  # ì¬ìƒì„± í•„ìš”
    
    def _extract_used_tools(self, result: Dict) -> List:
        """ì‚¬ìš©ëœ ë„êµ¬ ì •ë³´ ì¶”ì¶œ"""
        used_tools = []
        if "intermediate_steps" in result:
            for step in result["intermediate_steps"]:
                if len(step) >= 2 and hasattr(step[0], "tool"):
                    used_tools.append(step[0].tool)
        return used_tools
    
    def _handle_agent_stopped(self, result: Dict, user_input: str) -> Tuple[str, List]:
        """ì—ì´ì „íŠ¸ ì¤‘ë‹¨ ì²˜ë¦¬ - ë„êµ¬ ì‚¬ìš© ì‹œ ë°˜ë“œì‹œ ë„êµ¬ ê²°ê³¼ ì‚¬ìš©"""
        logger.info(f"=== ì—ì´ì „íŠ¸ ê²°ê³¼ ë””ë²„ê¹… ===")
        logger.info(f"result keys: {list(result.keys())}")
        logger.info(f"intermediate_steps ì¡´ì¬: {'intermediate_steps' in result}")
        if "intermediate_steps" in result:
            logger.info(f"intermediate_steps ê¸¸ì´: {len(result['intermediate_steps'])}")
            logger.info(f"intermediate_steps ë‚´ìš©: {result['intermediate_steps']}")
        
        # 1. intermediate_stepsì—ì„œ ë„êµ¬ ê²°ê³¼ í™•ì¸
        if "intermediate_steps" in result and result["intermediate_steps"]:
            logger.info(f"ë„êµ¬ ì‚¬ìš© ê°ì§€: {len(result['intermediate_steps'])}ê°œ ë‹¨ê³„")
            
            for i, step in enumerate(result["intermediate_steps"]):
                logger.info(f"ë‹¨ê³„ {i} íƒ€ì…: {type(step)}, ê¸¸ì´: {len(step) if hasattr(step, '__len__') else 'N/A'}")
                
                if len(step) >= 2:
                    tool_action = step[0]
                    tool_result = step[1]
                    tool_name = getattr(tool_action, 'tool', 'unknown')
                    logger.info(f"ë‹¨ê³„ {i}: ë„êµ¬={tool_name}, ê²°ê³¼ ê¸¸ì´={len(str(tool_result))}")
                    
                    if tool_result is not None:
                        result_str = str(tool_result).strip()
                        if result_str:
                            logger.info(f"ìœ íš¨í•œ ë„êµ¬ ê²°ê³¼ ë°œê²¬: {result_str[:200]}...")
                            
                            # ë„êµ¬ ê²°ê³¼ë¥¼ AIê°€ ì •ë¦¬í•˜ë„ë¡ ìš”ì²­ (ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì ìš©)
                            final_response = self._process_large_result(user_input, result_str)
                            return final_response, [tool_name]
                        else:
                            logger.warning(f"ë‹¨ê³„ {i}: ë„êµ¬ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
                    else:
                        logger.warning(f"ë‹¨ê³„ {i}: ë„êµ¬ ê²°ê³¼ê°€ None")
        
        # 2. outputì— ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸ (Agent stopped ë©”ì‹œì§€ ì²˜ë¦¬)
        output = result.get("output", "")
        logger.info(f"output ì¡´ì¬: {bool(output)}, ê¸¸ì´: {len(output) if output else 0}")
        if output:
            logger.info(f"output ë‚´ìš©: {output[:200]}...")
            
        # Agent stopped ë©”ì‹œì§€ ê°ì§€ ë° ì²˜ë¦¬
        if output and self._is_agent_stopped_message(output):
            logger.warning("Agent stopped ë©”ì‹œì§€ ê°ì§€ - ë„êµ¬ ê²°ê³¼ì—ì„œ ì‘ë‹µ ìƒì„± ì‹œë„")
            # intermediate_stepsì—ì„œ ëª¨ë“  ë„êµ¬ ê²°ê³¼ ìˆ˜ì§‘
            if "intermediate_steps" in result and result["intermediate_steps"]:
                all_tool_results = []
                used_tool_names = []
                
                for step in result["intermediate_steps"]:
                    if len(step) >= 2 and step[1]:
                        tool_result = str(step[1]).strip()
                        tool_name = getattr(step[0], 'tool', 'unknown')
                        if tool_result:
                            all_tool_results.append(f"[{tool_name}] {tool_result}")
                            used_tool_names.append(tool_name)
                
                if all_tool_results:
                    combined_results = "\n\n".join(all_tool_results)
                    logger.info(f"Agent stopped ìƒí™©ì—ì„œ {len(all_tool_results)}ê°œ ë„êµ¬ ê²°ê³¼ë¡œ ì‘ë‹µ ìƒì„±")
                    return self._process_large_result(user_input, combined_results), used_tool_names
        
        if output and output.strip() and not self._is_agent_stopped_message(output) and len(output) > 50:
            logger.info(f"ì—ì´ì „íŠ¸ ì¶œë ¥ì—ì„œ ê²°ê³¼ ë°œê²¬")
            return self.format_response(output), self._extract_used_tools(result)
        
        # 3. ë„êµ¬ë¥¼ ì‚¬ìš©í–ˆì§€ë§Œ ê²°ê³¼ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°
        if "intermediate_steps" in result and result["intermediate_steps"]:
            logger.warning("ë„êµ¬ë¥¼ ì‚¬ìš©í–ˆì§€ë§Œ ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŒ")
            return "ë„êµ¬ë¥¼ ì‚¬ìš©í–ˆì§€ë§Œ ì˜ˆìƒí•œ ê²°ê³¼ë¥¼ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", []
        
        # 4. ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì€ ê²½ìš° - ë” ìœ ìš©í•œ ë©”ì‹œì§€ ì œê³µ
        logger.warning("ë„êµ¬ ì‚¬ìš© ì—†ì´ ì—ì´ì „íŠ¸ ì¤‘ë‹¨")
        return "ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì— ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ì‹œ í•´ì£¼ì‹œê±°ë‚˜, ë‹¨ìˆœ ì±„íŒ… ëª¨ë“œë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”.", []
    
    def _extract_response_from_error(self, llm_output: str, user_input: str) -> Tuple[str, List]:
        """íŒŒì‹± ì˜¤ë¥˜ì—ì„œ ì‘ë‹µ ì¶”ì¶œ"""
        try:
            # Final Answer ë¶€ë¶„ ì¶”ì¶œ ì‹œë„
            if "Final Answer:" in llm_output:
                final_answer = llm_output.split("Final Answer:")[-1].strip()
                if final_answer and len(final_answer) > 10:
                    logger.info(f"Final Answerì—ì„œ ì‘ë‹µ ì¶”ì¶œ: {final_answer[:100]}...")
                    return self.format_response(final_answer), []
            
            # ë„êµ¬ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
            if "Observation:" in llm_output:
                # ë§ˆì§€ë§‰ Observation ë¶€ë¶„ ì¶”ì¶œ
                observation_parts = llm_output.split("Observation:")
                if len(observation_parts) > 1:
                    tool_result = observation_parts[-1].strip()
                    if tool_result and len(tool_result) > 10:
                        logger.info(f"Observationì—ì„œ ë„êµ¬ ê²°ê³¼ ì¶”ì¶œ: {tool_result[:100]}...")
                        return self._generate_final_response(user_input, tool_result), []
            
            # ì „ì²´ ì¶œë ¥ì—ì„œ ì˜ë¯¸ ìˆëŠ” ë‚´ìš© ì¶”ì¶œ
            if len(llm_output.strip()) > 50:
                logger.info(f"ì „ì²´ LLM ì¶œë ¥ ì‚¬ìš©: {llm_output[:100]}...")
                return self.format_response(llm_output.strip()), []
            
            # ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ë‹¨ìˆœ ì±„íŒ…ìœ¼ë¡œ ëŒ€ì²´
            logger.warning("íŒŒì‹± ì˜¤ë¥˜ì—ì„œ ì‘ë‹µ ì¶”ì¶œ ì‹¤íŒ¨, ë‹¨ìˆœ ì±„íŒ…ìœ¼ë¡œ ëŒ€ì²´")
            from .simple_chat_processor import SimpleChatProcessor
            simple_processor = SimpleChatProcessor(self.model_strategy)
            return simple_processor.process_message(user_input)
            
        except Exception as e:
            logger.error(f"ì˜¤ë¥˜ ì‘ë‹µ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", []
    
    def _process_large_result(self, user_input: str, tool_result: str) -> str:
        """ëŒ€ìš©ëŸ‰ ë„êµ¬ ê²°ê³¼ ì²˜ë¦¬"""
        try:
            # 1. ê²°ê³¼ í¬ê¸° í™•ì¸
            result_size = len(tool_result)
            logger.info(f"ë„êµ¬ ê²°ê³¼ í¬ê¸°: {result_size} ë¬¸ì")
            
            # 2. í¬ê¸°ë³„ ì²˜ë¦¬ ì „ëµ
            if result_size < 2000:
                # ì‘ì€ ê²°ê³¼: ê·¸ëŒ€ë¡œ ì²˜ë¦¬
                return self._generate_final_response(user_input, tool_result)
            
            elif result_size < 10000:
                # ì¤‘ê°„ í¬ê¸°: ìš”ì•½ ì²˜ë¦¬
                return self._summarize_result(user_input, tool_result)
            
            else:
                # ëŒ€ìš©ëŸ‰: ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
                return self._chunk_process_result(user_input, tool_result)
                
        except Exception as e:
            logger.error(f"ëŒ€ìš©ëŸ‰ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return f"ê²°ê³¼ê°€ ë„ˆë¬´ ì»¤ì„œ ì²˜ë¦¬í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    def _summarize_result(self, user_input: str, tool_result: str) -> str:
        """ì¤‘ê°„ í¬ê¸° ê²°ê³¼ ìš”ì•½"""
        summary_prompt = f"""ë‹¤ìŒ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:

ì‚¬ìš©ì ì§ˆë¬¸: "{user_input}"

ë„êµ¬ ê²°ê³¼:
{tool_result[:5000]}

ìš”ì•½ ì§€ì¹¨:
- ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œ
- ì¤‘ìš”í•œ ìˆ˜ì¹˜ë‚˜ ë°ì´í„°ëŠ” ìœ ì§€
- ë¶ˆí•„ìš”í•œ ì„¸ë¶€ì‚¬í•­ì€ ì œê±°
- ìµœëŒ€ 1000ì ì´ë‚´ë¡œ ìš”ì•½"""

        try:
            messages = self.model_strategy.create_messages(summary_prompt)
            response = self.model_strategy.llm.invoke(messages)
            
            # ëª¨ë¸ë³„ ì‘ë‹µ ì¶”ì¶œ
            response_text = self._extract_response_text(response)
            return self.format_response(response_text)
        except Exception as e:
            logger.error(f"ìš”ì•½ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return self.format_response(f"ìš”ì•½ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n\n{tool_result[:1000]}...")
    
    def _chunk_process_result(self, user_input: str, tool_result: str) -> str:
        """ëŒ€ìš©ëŸ‰ ê²°ê³¼ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬"""
        chunk_size = 3000
        chunks = [tool_result[i:i+chunk_size] for i in range(0, len(tool_result), chunk_size)]
        
        # ì²« ë²ˆì§¸ ì²­í¬ë¡œ ì´ˆê¸° ì‘ë‹µ ìƒì„±
        first_chunk = chunks[0]
        
        summary_prompt = f"""ëŒ€ìš©ëŸ‰ ë°ì´í„°ì˜ ì²« ë²ˆì§¸ ë¶€ë¶„ì…ë‹ˆë‹¤. ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì‹œì‘í•´ì£¼ì„¸ìš”:

ì‚¬ìš©ì ì§ˆë¬¸: "{user_input}"

ë°ì´í„° (1/{len(chunks)} ë¶€ë¶„):
{first_chunk}

ì§€ì¹¨:
- ì´ê²ƒì€ ì „ì²´ ë°ì´í„°ì˜ ì¼ë¶€ì„ì„ ëª…ì‹œ
- í˜„ì¬ ë¶€ë¶„ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì •ë³´ ì œê³µ
- ì „ì²´ ë°ì´í„°ê°€ í¬ë‹¤ëŠ” ê²ƒì„ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼"""

        try:
            messages = self.model_strategy.create_messages(summary_prompt)
            response = self.model_strategy.llm.invoke(messages)
            
            # ëª¨ë¸ë³„ ì‘ë‹µ ì¶”ì¶œ
            response_text = self._extract_response_text(response)
            result = response_text + f"\n\nğŸ“Š **ë°ì´í„° ì •ë³´**: ì´ {len(chunks)}ê°œ ì„¹ì…˜ ì¤‘ ì²« ë²ˆì§¸ ë¶€ë¶„ì„ í‘œì‹œí–ˆìŠµë‹ˆë‹¤. ë” ìì„¸í•œ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”."
            
            return self.format_response(result)
        except Exception as e:
            logger.error(f"ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return self.format_response(f"ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n\n{first_chunk[:1000]}...")

    def _generate_final_response(self, user_input: str, tool_result: str) -> str:
        """ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µ ìƒì„± - í¬ê¸° ì œí•œ ì ìš©"""
        try:
            # ê²°ê³¼ í¬ê¸° í™•ì¸ ë° ì²˜ë¦¬ ë°©ì‹ ê²°ì •
            if len(tool_result) > 8000:
                return self._process_large_result(user_input, tool_result)
            
            # ë„êµ¬ ê²°ê³¼ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì˜¤ë¥˜ì¸ ê²½ìš° ì²˜ë¦¬
            if not tool_result or tool_result.strip() == "":
                return "ë„êµ¬ë¥¼ ì‹¤í–‰í–ˆì§€ë§Œ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            
            # ì˜¤ë¥˜ ë©”ì‹œì§€ì¸ ê²½ìš° ì²˜ë¦¬
            if "error" in tool_result.lower() or "failed" in tool_result.lower():
                return f"ë„êµ¬ ì‹¤í–‰ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {tool_result[:200]}..."
            
            # ì ì ˆí•œ í¬ê¸°ë¡œ ì œí•œ
            limited_result = tool_result[:6000] if len(tool_result) > 6000 else tool_result
            
            response_prompt = f"""ì‚¬ìš©ì ì§ˆë¬¸: "{user_input}"

ë„êµ¬ ì‹¤í–‰ ê²°ê³¼:
{limited_result}

ìœ„ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë‹µë³€ ì‘ì„± ì§€ì¹¨:
1. ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ì•Œê³  ì‹¶ì–´í•˜ëŠ” ì •ë³´ì— ì§‘ì¤‘
2. ê²°ê³¼ë¥¼ ë…¼ë¦¬ì ì´ê³  ì½ê¸° ì‰¬ìš´ êµ¬ì¡°ë¡œ ì •ë¦¬
3. ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê²Œ ì„¤ëª…
4. í‘œë‚˜ ëª©ë¡ì´ ìˆë‹¤ë©´ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬
5. ê¸°ìˆ ì  ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…
6. í•µì‹¬ ì •ë³´ë¥¼ ë†“ì¹˜ì§€ ì•Šê³  í¬í•¨

ì‚¬ìš©ìì—ê²Œ ë„ì›€ì´ ë˜ëŠ” ëª…í™•í•˜ê³  ìœ ìš©í•œ í•œêµ­ì–´ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."""

            messages = self.model_strategy.create_messages(response_prompt)
            response = self.model_strategy.llm.invoke(messages)
            
            # ëª¨ë¸ë³„ ì‘ë‹µ ì¶”ì¶œ
            final_response = self._extract_response_text(response)
            
            # í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…
            TokenLogger.log_messages_token_usage(
                self.model_strategy.model_name, messages, final_response, "tool_response_generation"
            )
            if not final_response or len(final_response) < 10:
                # ì‘ë‹µì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ë„êµ¬ ê²°ê³¼ë¥¼ ì§ì ‘ í¬ë§·íŒ…
                return self.format_response(f"ìš”ì²­í•˜ì‹  ì •ë³´ì…ë‹ˆë‹¤:\n\n{limited_result}")
            
            # ì›ë³¸ ê²°ê³¼ê°€ ì˜ë ¸ë‹¤ë©´ ì•Œë¦¼ ì¶”ê°€
            if len(tool_result) > 6000:
                final_response += f"\n\nğŸ’¡ **ì°¸ê³ **: ê²°ê³¼ê°€ ê¸¸ì–´ì„œ ì¼ë¶€ë§Œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•˜ì‹œë©´ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            
            return self.format_response(final_response)
            
        except Exception as e:
            logger.error(f"ìµœì¢… ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ì‹œ ë„êµ¬ ê²°ê³¼ë¥¼ ì§ì ‘ ë°˜í™˜
            return self.format_response(f"ë„êµ¬ ì‹¤í–‰ ê²°ê³¼:\n\n{tool_result[:1000]}{'...' if len(tool_result) > 1000 else ''}")
    
    def _extract_response_text(self, response) -> str:
        """ëª¨ë¸ë³„ ì‘ë‹µ êµ¬ì¡° ì°¨ì´ë¥¼ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            # OpenAI/Gemini ìŠ¤íƒ€ì¼: response.content
            if hasattr(response, 'content'):
                return response.content.strip()
            
            # Perplexity ìŠ¤íƒ€ì¼: ì§ì ‘ ë¬¸ìì—´ì´ê±°ë‚˜ ë‹¤ë¥¸ êµ¬ì¡°
            if isinstance(response, str):
                return response.strip()
            
            # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ì‘ë‹µ
            if isinstance(response, dict):
                # ì¼ë°˜ì ì¸ í‚¤ë“¤ ì‹œë„
                for key in ['content', 'text', 'message', 'response', 'output']:
                    if key in response and response[key]:
                        return str(response[key]).strip()
            
            # ê¸°íƒ€ ê°ì²´ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
            if hasattr(response, 'text'):
                return response.text.strip()
            
            if hasattr(response, 'message'):
                return response.message.strip()
            
            # ë§ˆì§€ë§‰ ìˆ˜ë‹¨: ë¬¸ìì—´ ë³€í™˜
            response_str = str(response).strip()
            if response_str and response_str != 'None':
                return response_str
            
            return "ì‘ë‹µì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        except Exception as e:
            logger.error(f"ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return f"ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)[:100]}"