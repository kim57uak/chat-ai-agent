from abc import ABC, abstractmethod
from typing import List, Dict, Any, Tuple, Optional
from langchain.schema import HumanMessage, SystemMessage, AIMessage
import logging
import re
import base64

logger = logging.getLogger(__name__)


class ChatProcessor(ABC):
    """ì±„íŒ… ì²˜ë¦¬ë¥¼ ìœ„í•œ ì¶”ìƒ í´ë˜ìŠ¤"""
    
    @abstractmethod
    def process_chat(self, user_input: str, llm: Any, conversation_history: List[Dict] = None) -> str:
        pass


class SimpleChatProcessor(ChatProcessor):
    """ë‹¨ìˆœ ì±„íŒ… ì²˜ë¦¬ê¸°"""
    
    def process_chat(self, user_input: str, llm: Any, conversation_history: List[Dict] = None) -> str:
        """ì¼ë°˜ ì±„íŒ… (ë„êµ¬ ì‚¬ìš© ì—†ìŒ)"""
        try:
            # í†µì¼ëœ ì‹œìŠ¤í…œ ë©”ì‹œì§€ - ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œì— íŠ¹í™”
            system_content = """You are an expert AI assistant specialized in image analysis and text extraction (OCR).

**Primary Mission for Images:**
- **COMPLETE TEXT EXTRACTION**: Extract every single character, number, and symbol from images with 100% accuracy
- **ZERO OMISSIONS**: Never skip or miss any text, no matter how small or unclear
- **PERFECT TRANSCRIPTION**: Reproduce all text exactly as it appears, including spacing and formatting
- **STRUCTURAL ANALYSIS**: Identify tables, lists, headers, paragraphs, and document layout
- **MULTILINGUAL SUPPORT**: Handle Korean, English, numbers, and special characters flawlessly

**Response Format for Images:**
## ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸
[ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ë‚˜ì—´ - ì ˆëŒ€ ëˆ„ë½ ê¸ˆì§€]

## ğŸ“‹ ë¬¸ì„œ êµ¬ì¡°
[í‘œ, ëª©ë¡, ì œëª© ë“±ì˜ êµ¬ì¡° ì„¤ëª…]

## ğŸ“ ë ˆì´ì•„ì›ƒ ì •ë³´
[í…ìŠ¤íŠ¸ ë°°ì¹˜ì™€ ìœ„ì¹˜ ê´€ê³„]

**Critical Rules:**
- NEVER say "í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤" or "ì¶”ì¶œí•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤"
- ALWAYS extract something, even if text is small or unclear
- If text is unclear, provide your best interpretation with [ë¶ˆëª…í™•] notation
- Focus on TEXT EXTRACTION as the absolute priority

**For General Questions:**
- Always respond in natural, conversational Korean
- Organize information clearly with headings and bullet points
- Highlight important information using **bold** formatting
- Be friendly, helpful, and accurate"""

            # Gemini ëª¨ë¸ì˜ ê²½ìš° ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì¸ê°„ ë©”ì‹œì§€ë¡œ ë³€í™˜
            model_name = getattr(llm, 'model_name', str(llm))
            if 'gemini' in model_name.lower():
                messages = [HumanMessage(content=system_content)]
            else:
                messages = [SystemMessage(content=system_content)]

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€
            if conversation_history:
                messages.extend(self._convert_history_to_messages(conversation_history, model_name))

            # ì´ë¯¸ì§€ ë°ì´í„° ì²˜ë¦¬
            if "[IMAGE_BASE64]" in user_input and "[/IMAGE_BASE64]" in user_input:
                processed_input = self._process_image_input(user_input, model_name)
                messages.append(processed_input)
            else:
                messages.append(HumanMessage(content=user_input))

            response = llm.invoke(messages)
            return response.content

        except Exception as e:
            logger.error(f"ì¼ë°˜ ì±„íŒ… ì˜¤ë¥˜: {e}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
    
    def _convert_history_to_messages(self, conversation_history: List[Dict], model_name: str):
        """ëŒ€í™” ê¸°ë¡ì„ LangChain ë©”ì‹œì§€ë¡œ ë³€í™˜"""
        messages = []
        
        # ìµœê·¼ ëŒ€í™” ê¸°ë¡ ì‚¬ìš©
        recent_history = (
            conversation_history[-6:]
            if len(conversation_history) > 6
            else conversation_history
        )

        for msg in recent_history:
            role = msg.get("role", "")
            content = msg.get("content", "")[:500]  # ë‚´ìš© ì œí•œ
            if role == "user":
                messages.append(HumanMessage(content=content))
            elif role == "assistant":
                messages.append(AIMessage(content=content))

        return messages
    
    def _process_image_input(self, user_input: str, model_name: str):
        """ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ LangChain ë©”ì‹œì§€ë¡œ ë³€í™˜"""
        # ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ
        image_match = re.search(
            r"\[IMAGE_BASE64\](.*?)\[/IMAGE_BASE64\]", user_input, re.DOTALL
        )
        if not image_match:
            return HumanMessage(content=user_input)

        image_data = image_match.group(1).strip()
        text_content = user_input.replace(image_match.group(0), "").strip()

        # Base64 ë°ì´í„° ê²€ì¦
        try:
            base64.b64decode(image_data)
        except Exception as e:
            logger.error(f"ì˜ëª»ëœ Base64 ì´ë¯¸ì§€ ë°ì´í„°: {e}")
            return HumanMessage(content="ì˜ëª»ëœ ì´ë¯¸ì§€ ë°ì´í„°ì…ë‹ˆë‹¤.")

        # í…ìŠ¤íŠ¸ ì¶”ì¶œì— íŠ¹í™”ëœ í”„ë¡¬í”„íŠ¸
        if not text_content:
            text_content = """Please **extract all text accurately (OCR)** from this image.

**Required Tasks:**
1. **Complete Text Extraction**: Extract all Korean, English, numbers, and symbols without omission
2. **Structure Analysis**: Identify document structures like tables, lists, headings, paragraphs
3. **Layout Information**: Describe text position, size, and arrangement relationships
4. **Accurate Transcription**: Record all characters precisely without typos
5. **Context Description**: Identify document type and purpose

**Response Format:**
## ğŸ“„ Extracted Text
[List all text accurately]

## ğŸ“‹ Document Structure
[Describe structure of tables, lists, headings, etc.]

## ğŸ“ Layout Information
[Text arrangement and positional relationships]

**Important**: Please extract all readable text from the image completely without any omissions."""

        try:
            # Gemini ëª¨ë¸ì˜ ê²½ìš° íŠ¹ë³„í•œ í˜•ì‹ ì‚¬ìš©
            if 'gemini' in model_name.lower():
                return HumanMessage(
                    content=[
                        {"type": "text", "text": text_content},
                        {
                            "type": "image_url",
                            "image_url": f"data:image/jpeg;base64,{image_data}",
                        },
                    ]
                )
            else:
                # OpenAI GPT-4V í˜•ì‹
                return HumanMessage(
                    content=[
                        {"type": "text", "text": text_content},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_data}"
                            },
                        },
                    ]
                )
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return HumanMessage(
                content=f"{text_content}\n\n[ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}]"
            )


class ToolChatProcessor(ChatProcessor):
    """ë„êµ¬ ì‚¬ìš© ì±„íŒ… ì²˜ë¦¬ê¸°"""
    
    def __init__(self, tools: List[Any], agent_executor_factory):
        self.tools = tools
        self.agent_executor_factory = agent_executor_factory
        self.agent_executor = None
    
    def process_chat(self, user_input: str, llm: Any, conversation_history: List[Dict] = None) -> Tuple[str, List]:
        """ë„êµ¬ë¥¼ ì‚¬ìš©í•œ ì±„íŒ…"""
        import time
        start_time = time.time()
        logger.info(f"ğŸš€ ë„êµ¬ ì±„íŒ… ì‹œì‘: {user_input[:50]}...")
        
        try:
            # í† í° ì œí•œ ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì œí•œ
            if "context_length_exceeded" in str(getattr(self, "_last_error", "")):
                logger.warning("í† í° ì œí•œ ì˜¤ë¥˜ë¡œ ì¸í•´ ì¼ë°˜ ì±„íŒ…ìœ¼ë¡œ ëŒ€ì²´")
                simple_processor = SimpleChatProcessor()
                return simple_processor.process_chat(user_input, llm), []

            # Gemini ëª¨ë¸ì€ ì§ì ‘ ë„êµ¬ í˜¸ì¶œ ë°©ì‹ ì‚¬ìš©
            model_name = getattr(llm, 'model_name', str(llm))
            if 'gemini' in model_name.lower():
                logger.info("ğŸ”§ Gemini ë„êµ¬ ì±„íŒ… ì‹œì‘")
                gemini_start = time.time()
                result = self._gemini_tool_chat(user_input, llm)
                logger.info(f"ğŸ”§ Gemini ë„êµ¬ ì±„íŒ… ì™„ë£Œ: {time.time() - gemini_start:.2f}ì´ˆ")
                return result

            # GPT ëª¨ë¸ì€ ê¸°ì¡´ ì—ì´ì „íŠ¸ ë°©ì‹ ì‚¬ìš©
            if not self.agent_executor:
                logger.info("ğŸ”§ ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸° ìƒì„± ì‹œì‘")
                agent_create_start = time.time()
                self.agent_executor = self.agent_executor_factory.create_agent_executor(llm, self.tools)
                logger.info(f"ğŸ”§ ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸° ìƒì„± ì™„ë£Œ: {time.time() - agent_create_start:.2f}ì´ˆ")

            if not self.agent_executor:
                return "ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤.", []

            logger.info("ğŸ”§ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œì‘")
            agent_invoke_start = time.time()
            result = self.agent_executor.invoke({"input": user_input})
            logger.info(f"ğŸ”§ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ: {time.time() - agent_invoke_start:.2f}ì´ˆ")
            output = result.get("output", "")

            # ì‚¬ìš©ëœ ë„êµ¬ ì •ë³´ ì¶”ì¶œ
            used_tools = []
            if "intermediate_steps" in result:
                for step in result["intermediate_steps"]:
                    if len(step) >= 2 and hasattr(step[0], "tool"):
                        used_tools.append(step[0].tool)

            if "Agent stopped" in output or not output.strip():
                logger.warning("ì—ì´ì „íŠ¸ ì¤‘ë‹¨ë¡œ ì¸í•´ ì¼ë°˜ ì±„íŒ…ìœ¼ë¡œ ëŒ€ì²´")
                simple_processor = SimpleChatProcessor()
                return simple_processor.process_chat(user_input, llm), []

            elapsed = time.time() - start_time
            logger.info(f"âœ… ë„êµ¬ ì±„íŒ… ì™„ë£Œ: {elapsed:.2f}ì´ˆ")
            return output, used_tools

        except Exception as e:
            elapsed = time.time() - start_time
            error_msg = str(e)
            self._last_error = error_msg
            logger.error(f"âŒ ë„êµ¬ ì‚¬ìš© ì±„íŒ… ì˜¤ë¥˜: {elapsed:.2f}ì´ˆ, ì˜¤ë¥˜: {e}")

            # í† í° ì œí•œ ì˜¤ë¥˜ ì²˜ë¦¬
            if (
                "context_length_exceeded" in error_msg
                or "maximum context length" in error_msg
            ):
                logger.warning("í† í° ì œí•œ ì˜¤ë¥˜ ë°œìƒ, ì¼ë°˜ ì±„íŒ…ìœ¼ë¡œ ëŒ€ì²´")
                simple_processor = SimpleChatProcessor()
                return simple_processor.process_chat(user_input, llm), []

            simple_processor = SimpleChatProcessor()
            return simple_processor.process_chat(user_input, llm), []
    
    def _gemini_tool_chat(self, user_input: str, llm: Any) -> Tuple[str, List]:
        """Gemini ëª¨ë¸ìš© ë„êµ¬ ì±„íŒ… (ê°„ë‹¨í•œ êµ¬í˜„)"""
        # ì‹¤ì œ êµ¬í˜„ì€ ê¸°ì¡´ ë¡œì§ì„ ì°¸ì¡°í•˜ì—¬ ì‘ì„±
        return f"Gemini ë„êµ¬ ì±„íŒ… ê²°ê³¼: {user_input}", []