from typing import List, Dict, Any, Optional
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.schema import BaseMessage, HumanMessage, SystemMessage, AIMessage
from langchain.agents import AgentExecutor, create_react_agent
from langchain.prompts import PromptTemplate
from .base_model_strategy import BaseModelStrategy
from ui.prompts import prompt_manager, ModelType
import logging

logger = logging.getLogger(__name__)


class GeminiStrategy(BaseModelStrategy):
    """Google Gemini ëª¨ë¸ ì „ëžµ"""
    
    def create_llm(self):
        """Gemini LLM ìƒì„±"""
        return ChatGoogleGenerativeAI(
            model=self.model_name,
            google_api_key=self.api_key,
            temperature=0.1,
            convert_system_message_to_human=True,
            max_tokens=4096,
        )
    
    def create_messages(self, user_input: str, system_prompt: str = None, conversation_history: List[Dict] = None) -> List[BaseMessage]:
        """Gemini ë©”ì‹œì§€ í˜•ì‹ ìƒì„± - ëŒ€í™” ížˆìŠ¤í† ë¦¬ í¬í•¨"""
        messages = []
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        if system_prompt:
            enhanced_prompt = self.enhance_prompt_with_format(system_prompt)
        else:
            enhanced_prompt = self.get_default_system_prompt()
        
        # ëŒ€í™” ížˆìŠ¤í† ë¦¬ê°€ ìžˆìœ¼ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if conversation_history:
            history_context = self._format_conversation_history(conversation_history)
            enhanced_prompt += f"\n\n**Previous Conversation Context:**\n{history_context}\n\nPlease consider this conversation history when responding."
        
        messages.append(HumanMessage(content=enhanced_prompt))
        
        # ëŒ€í™” ížˆìŠ¤í† ë¦¬ë¥¼ ì‹¤ì œ ë©”ì‹œì§€ë¡œ ë³€í™˜
        if conversation_history:
            for msg in conversation_history:
                role = msg.get("role", "")
                content = msg.get("content", "")
                
                if role == "user" and content.strip():
                    messages.append(HumanMessage(content=content))
                elif role in ["assistant", "agent"] and content.strip():
                    messages.append(AIMessage(content=content))
        
        # í˜„ìž¬ ì‚¬ìš©ìž ìž…ë ¥ ì¶”ê°€
        messages.append(HumanMessage(content=user_input))
        return messages
    
    def _format_conversation_history(self, conversation_history: List[Dict]) -> str:
        """ëŒ€í™” ížˆìŠ¤í† ë¦¬ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        formatted_history = []
        for msg in conversation_history:
            role = msg.get("role", "")
            content = msg.get("content", "")
            
            if role == "user":
                formatted_history.append(f"User: {content}")
            elif role in ["assistant", "agent"]:
                formatted_history.append(f"Assistant: {content}")
        
        return "\n".join(formatted_history)
    
    def process_image_input(self, user_input: str) -> BaseMessage:
        """Gemini ì´ë¯¸ì§€ ìž…ë ¥ ì²˜ë¦¬"""
        import re
        import base64
        
        image_match = re.search(
            r"\[IMAGE_BASE64\](.*?)\[/IMAGE_BASE64\]", user_input, re.DOTALL
        )
        if not image_match:
            return HumanMessage(content=user_input)
        
        image_data = image_match.group(1).strip()
        text_content = user_input.replace(image_match.group(0), "").strip()
        
        try:
            base64.b64decode(image_data)
        except Exception as e:
            logger.error(f"Invalid Base64 image data: {e}")
            return HumanMessage(content="Invalid image data.")
        
        if not text_content:
            text_content = self._get_ocr_prompt()
        
        # Gemini 2.0 Flashì— ìµœì í™”ëœ í˜•ì‹
        return HumanMessage(
            content=[
                {"type": "text", "text": text_content},
                {
                    "type": "image_url",
                    "image_url": f"data:image/jpeg;base64,{image_data}",
                },
            ]
        )
    
    def should_use_tools(self, user_input: str, force_agent: bool = False) -> bool:
        """Geminiê°€ ìžì—°ì–´ë¥¼ ì´í•´í•˜ì—¬ ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ë¥¼ ì§€ëŠ¥ì ìœ¼ë¡œ ê²°ì •"""
        import time
        
        start_time = time.time()
        logger.info(f"ðŸ¤” Gemini ë„êµ¬ ì‚¬ìš© íŒë‹¨ ì‹œìž‘: {user_input[:30]}...")
        
        # Agent ëª¨ë“œê°€ ê°•ì œëœ ê²½ìš° í•­ìƒ ë„êµ¬ ì‚¬ìš©
        if force_agent:
            logger.info("ðŸ”§ Agent ëª¨ë“œê°€ ê°•ì œë˜ì–´ ë„êµ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤")
            return True
        
        try:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ì •ë³´ ìˆ˜ì§‘
            available_tools = []
            if hasattr(self, 'tools') and self.tools:
                for tool in self.tools[:5]:  # ì£¼ìš” ë„êµ¬ 5ê°œë§Œ
                    tool_desc = getattr(tool, 'description', tool.name)
                    available_tools.append(f"- {tool.name}: {tool_desc[:80]}")
            
            tools_info = "\n".join(available_tools) if available_tools else "ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ì—†ìŒ"
            
            # Agent ëª¨ë“œ ì„ íƒ ì‹œ ë” ì ê·¹ì ì¸ íŒë‹¨ ê¸°ì¤€ ì ìš©
            agent_context = ""
            if force_agent:
                agent_context = "\n\nIMPORTANT: The user has specifically selected Agent mode, indicating they want to use available tools when possible. Be more inclined to use tools for information gathering, searches, or data processing tasks."
            
            # ì¤‘ì•™ê´€ë¦¬ ì‹œìŠ¤í…œì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
            available_tools = getattr(self, 'tools', [])
            decision_prompt = prompt_manager.get_tool_decision_prompt(
                ModelType.GOOGLE.value, user_input, available_tools
            )
            
            # Agent ëª¨ë“œ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            if force_agent:
                decision_prompt += "\n\nIMPORTANT: The user has specifically selected Agent mode, indicating they want to use available tools when possible. Be more inclined to use tools for information gathering, searches, or data processing tasks."
            
            # GeminiëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì¸ê°„ ë©”ì‹œì§€ë¡œ ë³€í™˜
            messages = [
                HumanMessage(content="You are an expert at analyzing user requests to determine if tools are needed. When creating tables, ALWAYS use proper markdown table format with pipe separators and header separator row."),
                HumanMessage(content=decision_prompt),
            ]
            
            llm_start = time.time()
            response = self.llm.invoke(messages)
            llm_elapsed = time.time() - llm_start
            decision = response.content.strip().upper()
            
            result = "YES" in decision
            mode_info = " (Agent ëª¨ë“œ)" if force_agent else " (Ask ëª¨ë“œ)"
            total_elapsed = time.time() - start_time
            logger.info(
                f"ðŸ¤” Gemini ë„êµ¬ ì‚¬ìš© íŒë‹¨{mode_info}: {decision} -> {result} (LLM: {llm_elapsed:.2f}ì´ˆ, ì´: {total_elapsed:.2f}ì´ˆ)"
            )
            return result
            
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"âŒ Gemini ë„êµ¬ ì‚¬ìš© íŒë‹¨ ì˜¤ë¥˜: {elapsed:.2f}ì´ˆ, ì˜¤ë¥˜: {e}")
            return False
    
    def create_agent_executor(self, tools: List) -> Optional[AgentExecutor]:
        """Gemini ReAct ì—ì´ì „íŠ¸ ìƒì„± (ë„êµ¬ í˜¸í™˜ì„± ê°œì„ )"""
        if not tools:
            return None
        
        # ì¤‘ì•™ê´€ë¦¬ ì‹œìŠ¤í…œì—ì„œ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
        agent_system_prompt = prompt_manager.get_agent_system_prompt(ModelType.GOOGLE.value)
        
        # GeminiëŠ” ReAct ì—ì´ì „íŠ¸ë§Œ ì§€ì›
        react_prompt = PromptTemplate.from_template(
            f"""{agent_system_prompt}

Available tools:
{{tools}}

Tool names: {{tool_names}}

Question: {{input}}
{{agent_scratchpad}}
            """
        )

        agent = create_react_agent(self.llm, tools, react_prompt)
        return AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True,
            max_iterations=5,
            max_execution_time=30,
            handle_parsing_errors="Invalid format! You must follow the exact format: Thought -> Action -> Action Input. Do NOT include both Action and Final Answer in the same response.",
            early_stopping_method="force",
            return_intermediate_steps=True,
        )
    
    def _get_ocr_prompt(self) -> str:
        """OCR ì „ìš© í”„ë¡¬í”„íŠ¸"""
        return prompt_manager.get_ocr_prompt()