from typing import List, Dict, Any, Optional
from langchain.schema import BaseMessage, HumanMessage, SystemMessage, AIMessage
from langchain.agents import AgentExecutor, create_react_agent
from langchain.prompts import PromptTemplate
from .base_model_strategy import BaseModelStrategy
from core.perplexity_llm import PerplexityLLM
from core.perplexity_wrapper import PerplexityWrapper
from core.perplexity_output_parser import PerplexityOutputParser
from ui.prompts import prompt_manager, ModelType
from core.token_logger import TokenLogger
import logging

logger = logging.getLogger(__name__)


class PerplexityStrategy(BaseModelStrategy):
    """Perplexity ëª¨ë¸ ì „ëµ - ë‹¨ìˆœí™”ëœ êµ¬í˜„"""
    
    def create_llm(self):
        """Perplexity LLM ìƒì„±"""
        params = self.get_model_parameters()
        wrapper = PerplexityWrapper(
            pplx_api_key=self.api_key,
            model=self.model_name
        )
        # íŒŒë¼ë¯¸í„°ë¥¼ wrapperì— ì €ì¥í•˜ì—¬ generate í˜¸ì¶œ ì‹œ ì‚¬ìš©
        wrapper._model_params = params
        return wrapper
    
    def create_messages(self, user_input: str, system_prompt: str = None, conversation_history: List[Dict] = None) -> List[BaseMessage]:
        """Perplexity ë©”ì‹œì§€ í˜•ì‹ ìƒì„± - ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨"""
        messages = []
        
        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì–¸ì–´ ê°ì§€ (ì›ë³¸ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©)
        user_language = self.detect_user_language(user_input)
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        if system_prompt:
            enhanced_prompt = self.enhance_prompt_with_format(system_prompt)
        else:
            enhanced_prompt = self.get_perplexity_system_prompt()
        
        # ì–¸ì–´ë³„ ì‘ë‹µ ì§€ì¹¨ ì¶”ê°€
        if user_language == "ko":
            enhanced_prompt += "\n\n**ì¤‘ìš”**: ì‚¬ìš©ìê°€ í•œêµ­ì–´ë¡œ ì§ˆë¬¸í–ˆìœ¼ë¯€ë¡œ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”."
        else:
            enhanced_prompt += "\n\n**Important**: The user asked in English, so please respond in English."
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ìˆìœ¼ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì»¨í…ìŠ¤íŠ¸ ê°•ì¡° ì¶”ê°€
        if conversation_history:
            history_context = self._format_conversation_history(conversation_history)
            enhanced_prompt += f"\n\n=== CONVERSATION HISTORY (HIGHEST PRIORITY) ===\n{history_context}\n\n**ABSOLUTE PRIORITY RULE**: \n1. ALWAYS check this conversation history FIRST before searching\n2. If the answer exists in this history, use it directly\n3. Only search for NEW information not in this conversation\n4. When referencing history, say \"Based on our conversation...\"\n5. Remember names, preferences, and context from above messages\n==========================================="
            
            logger.info(f"Perplexityì— ëŒ€í™” íˆìŠ¤í† ë¦¬ {len(conversation_history)}ê°œ ë©”ì‹œì§€ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€")
        
        # PerplexityëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì²« ë²ˆì§¸ ë©”ì‹œì§€ë¡œ ì²˜ë¦¬
        messages.append(SystemMessage(content=enhanced_prompt))
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì‹¤ì œ ë©”ì‹œì§€ë¡œ ë³€í™˜ - êµëŒ€ íŒ¨í„´ ë³´ì¥
        if conversation_history:
            last_role = None
            for i, msg in enumerate(conversation_history):
                role = msg.get("role", "")
                content = msg.get("content", "")
                
                if not content.strip():
                    continue
                
                # ì—°ì†ëœ ê°™ì€ role ë°©ì§€
                if role == "user" and last_role != "user":
                    messages.append(HumanMessage(content=content))
                    logger.debug(f"  íˆìŠ¤í† ë¦¬ ë©”ì‹œì§€ {i+1}: user - {content[:50]}...")
                    last_role = "user"
                elif role in ["assistant", "agent"] and last_role != "assistant":
                    messages.append(AIMessage(content=content))
                    logger.debug(f"  íˆìŠ¤í† ë¦¬ ë©”ì‹œì§€ {i+1}: assistant - {content[:50]}...")
                    last_role = "assistant"
                elif role == "user" and last_role == "user":
                    # ì—°ì†ëœ user ë©”ì‹œì§€ëŠ” ë§ˆì§€ë§‰ ë©”ì‹œì§€ì— ë³‘í•©
                    if messages and isinstance(messages[-1], HumanMessage):
                        messages[-1].content += f"\n\n{content}"
                        logger.debug(f"  ì—°ì† user ë©”ì‹œì§€ ë³‘í•©: {content[:30]}...")
        
        # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€ - ë§ˆì§€ë§‰ì´ userë©´ ë³‘í•©
        if messages and isinstance(messages[-1], HumanMessage):
            messages[-1].content += f"\n\n{user_input}"
            logger.info(f"  í˜„ì¬ ì…ë ¥ì„ ë§ˆì§€ë§‰ user ë©”ì‹œì§€ì— ë³‘í•©")
        else:
            messages.append(HumanMessage(content=user_input))
        
        logger.info(f"Perplexityì— ìµœì¢… ì „ë‹¬ë˜ëŠ” ë©”ì‹œì§€ ìˆ˜: {len(messages)}")
        return messages
    
    def _format_conversation_history(self, conversation_history: List[Dict]) -> str:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ… - ê°•í™”ëœ ë²„ì „"""
        if not conversation_history:
            return "No previous conversation."
        
        formatted_history = []
        formatted_history.append("ğŸ’¬ **CONVERSATION CONTEXT (Remember this!):**")
        formatted_history.append("=" * 50)
        
        for i, msg in enumerate(conversation_history, 1):
            role = msg.get("role", "")
            content = msg.get("content", "").strip()
            
            if not content:
                continue
                
            if role == "user":
                formatted_history.append(f"[{i}] ğŸ‘¤ **User said**: {content}")
            elif role in ["assistant", "agent"]:
                formatted_history.append(f"[{i}] ğŸ¤– **I replied**: {content}")
        
        formatted_history.append("=" * 50)
        formatted_history.append("ğŸ“ **IMPORTANT**: This conversation history contains personal context, names, preferences, and previous discussions. Use this information to provide contextual responses.")
        
        return "\n".join(formatted_history)
    
    def process_image_input(self, user_input: str) -> BaseMessage:
        """PerplexityëŠ” ì´ë¯¸ì§€ ì²˜ë¦¬ ë¯¸ì§€ì›"""
        # ì´ë¯¸ì§€ íƒœê·¸ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬
        import re
        cleaned_input = re.sub(r'\[IMAGE_BASE64\].*?\[/IMAGE_BASE64\]', '', user_input, flags=re.DOTALL)
        return HumanMessage(content=cleaned_input.strip() or "ì´ë¯¸ì§€ ì²˜ë¦¬ëŠ” ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    def should_use_tools(self, user_input: str) -> bool:
        """ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ ê²°ì • - ê°•í™”ëœ ì»¨í…ìŠ¤íŠ¸ ì´í•´"""
        try:
            # í‚¤ì›Œë“œ ê¸°ë°˜ 1ì°¨ í•„í„°ë§
            tool_keywords = [
                'ê²€ìƒ‰', 'search', 'ì°¾ì•„', 'ì¡°íšŒ', 'í™•ì¸', 'check', 'ê°€ì ¸ì™€', 'get',
                'ë°ì´í„°ë² ì´ìŠ¤', 'database', 'mysql', 'sql', 'ì¿¼ë¦¬', 'query',
                'ì´ë©”ì¼', 'email', 'gmail', 'ë©”ì¼', 'mail',
                'íŒŒì¼', 'file', 'ì—‘ì…€', 'excel', 'ë¬¸ì„œ', 'document',
                'ì§€ë¼', 'jira', 'ì´ìŠˆ', 'issue', 'í‹°ì¼“', 'ticket',
                'ì»¨í”Œë£¨ì–¸ìŠ¤', 'confluence', 'ìœ„í‚¤', 'wiki',
                'ì—¬í–‰', 'travel', 'í•˜ë‚˜íˆ¬ì–´', 'hanatour', 'ìƒí’ˆ', 'product',
                'ì§€ë„', 'map', 'ìœ„ì¹˜', 'location', 'ì£¼ì†Œ', 'address',
                'ë‚ ì”¨', 'weather', 'ë‰´ìŠ¤', 'news', 'ìµœì‹ ', 'latest', 'í˜„ì¬', 'current',
                'ì˜¤ëŠ˜', 'today', 'ì–´ì œ', 'yesterday', 'ìµœê·¼', 'recent',
                'ìƒì„±', 'create', 'ë§Œë“¤ì–´', 'make', 'ì‘ì„±', 'write',
                'ì—…ë°ì´íŠ¸', 'update', 'ìˆ˜ì •', 'modify', 'ë³€ê²½', 'change',
                'ì‚­ì œ', 'delete', 'ì œê±°', 'remove',
                'ë‹¤ìš´ë¡œë“œ', 'download', 'ì—…ë¡œë“œ', 'upload',
                'ì‹¤í–‰', 'execute', 'ì‹¤ì‹œê°„', 'realtime', 'real-time'
            ]
            
            user_lower = user_input.lower()
            has_tool_keywords = any(keyword in user_lower for keyword in tool_keywords)
            
            if not has_tool_keywords:
                logger.info(f"ğŸš« í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§: ë„êµ¬ ì‚¬ìš© ë¶ˆí•„ìš” - '{user_input}'")
                return False
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ì •ë³´ ìˆ˜ì§‘
            available_tools = []
            if hasattr(self, 'tools') and self.tools:
                for tool in self.tools[:15]:  # ë” ë§ì€ ë„êµ¬ í‘œì‹œ
                    tool_desc = getattr(tool, 'description', tool.name)
                    available_tools.append(f"- {tool.name}: {tool_desc[:120]}")
            
            if not available_tools:
                logger.info(f"ğŸš« ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ì—†ìŒ")
                return False
            
            tools_info = "\n".join(available_tools)
            
            # ê°•í™”ëœ ë„êµ¬ íŒë‹¨ í”„ë¡¬í”„íŠ¸
            decision_prompt = f"""TASK: Determine if the user request requires external tools or data.

USER REQUEST: "{user_input}"

AVAILABLE TOOLS:
{tools_info}

**DECISION CRITERIA:**

USE TOOLS (Answer YES) when request involves:
âœ… External data retrieval (search, database queries, file access)
âœ… Real-time information (current news, weather, stock prices)
âœ… Specific system operations (Jira issues, email management)
âœ… File operations (Excel, documents, downloads)
âœ… API calls to external services
âœ… Time-sensitive data (today's data, recent updates)
âœ… User's personal/work data (my files, assigned issues)

NO TOOLS (Answer NO) when request is:
âŒ General knowledge questions I can answer directly
âŒ Explanations, concepts, tutorials
âŒ Creative writing, brainstorming
âŒ Code examples without external data
âŒ Mathematical calculations
âŒ Theoretical discussions

**CRITICAL**: If the request mentions specific external systems, data sources, or requires current information, ALWAYS use tools.

Answer with ONLY: YES or NO"""
            
            # Perplexity LLMì— ì§ì ‘ ìš”ì²­
            response = self.llm._call(decision_prompt)
            decision = response.strip().upper()
            
            # í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…
            TokenLogger.log_token_usage(
                self.model_name, decision_prompt, decision, "tool_decision"
            )
            
            result = "YES" in decision
            logger.info(f"ğŸ¤” Perplexity ë„êµ¬ ì‚¬ìš© íŒë‹¨: '{user_input}' -> {decision} -> {result}")
            return result
            
        except Exception as e:
            logger.error(f"Perplexity ë„êµ¬ ì‚¬ìš© íŒë‹¨ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨
            tool_keywords = ['ê²€ìƒ‰', 'search', 'ì°¾ì•„', 'ì¡°íšŒ', 'í™•ì¸', 'check', 'ê°€ì ¸ì™€', 'get', 'ë°ì´í„°ë² ì´ìŠ¤', 'mysql', 'jira', 'email']
            return any(keyword in user_input.lower() for keyword in tool_keywords)
    
    def create_agent_executor(self, tools: List) -> Optional[AgentExecutor]:
        """Perplexity ReAct ì—ì´ì „íŠ¸ ìƒì„± - ë‹¨ìˆœí™”ëœ êµ¬í˜„"""
        if not tools:
            return None
        
        react_prompt = PromptTemplate.from_template(
            """You are an expert data analyst that uses tools to gather information and provides comprehensive analysis.

**CRITICAL: THOROUGH OBSERVATION ANALYSIS REQUIRED**

**EXACT FORMAT (MANDATORY):**

Thought: [Analyze what information is needed for the user's question]
Action: [exact_tool_name]
Action Input: {{"param": "value"}}

(System provides Observation with tool results)

Thought: [CRITICAL ANALYSIS STEP: Read the ENTIRE Observation carefully. Extract ALL key information including names, numbers, dates, details. Identify patterns and relationships. Organize findings logically. This analysis determines the quality of your Final Answer.]
Final Answer: [Comprehensive Korean response based EXCLUSIVELY on Observation data. Include specific details, exact numbers, names, and all relevant information from the tool results. Structure the response clearly with proper formatting. Do NOT add external knowledge - use ONLY the data provided in the Observation.]

**ANALYSIS REQUIREMENTS:**
1. **COMPLETE DATA PROCESSING**: Read every part of the Observation
2. **EXTRACT SPECIFICS**: Include exact names, numbers, dates from results
3. **LOGICAL ORGANIZATION**: Structure information clearly
4. **COMPREHENSIVE COVERAGE**: Address all aspects relevant to user's question
5. **DATA-ONLY RESPONSES**: Base answer EXCLUSIVELY on Observation data

**PARSING RULES:**
- Use EXACT keywords: "Thought:", "Action:", "Action Input:", "Final Answer:"
- Action Input MUST be valid JSON
- NEVER mix Action and Final Answer
- Analyze Observation thoroughly before Final Answer

Tools: {tools}
Tool names: {tool_names}

Question: {input}
Thought:{agent_scratchpad}"""
        )

        try:
            # ì»¤ìŠ¤í…€ íŒŒì„œ ì‚¬ìš©
            custom_parser = PerplexityOutputParser()
            
            # ì—ì´ì „íŠ¸ ìƒì„± ì‹œ ì»¤ìŠ¤í…€ íŒŒì„œ ì‚¬ìš©
            agent = create_react_agent(self.llm, tools, react_prompt, output_parser=custom_parser)
            
            return AgentExecutor(
                agent=agent,
                tools=tools,
                verbose=True,
                max_iterations=5,
                max_execution_time=60,
                handle_parsing_errors="CRITICAL: Follow the exact format. After receiving Observation, analyze ALL the data thoroughly in your Thought, then provide a comprehensive Final Answer based ONLY on the Observation data. Include specific details from the results.",
                early_stopping_method="force",
                return_intermediate_steps=True,
            )
        except Exception as e:
            logger.error(f"Perplexity agent creation failed: {e}")
            return None
    
    def get_perplexity_system_prompt(self) -> str:
        """Perplexity ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ - ë„êµ¬ ì¸ì‹ ê°•í™”"""
        base_prompt = prompt_manager.get_system_prompt(ModelType.PERPLEXITY.value)
        
        # ë„êµ¬ê°€ ìˆì„ ë•Œ ë„êµ¬ ì¸ì‹ ê°•í™” í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        if hasattr(self, 'tools') and self.tools:
            tool_awareness = prompt_manager.get_custom_prompt(ModelType.PERPLEXITY.value, "tool_awareness")
            agent_system = prompt_manager.get_agent_system_prompt(ModelType.PERPLEXITY.value)
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ìƒì„±
            tool_list = []
            for tool in self.tools[:10]:
                tool_desc = getattr(tool, 'description', tool.name)
                tool_list.append(f"- {tool.name}: {tool_desc[:80]}")
            
            tools_summary = "\n".join(tool_list) if tool_list else "No tools available"
            
            enhanced_prompt = f"""{base_prompt}

{tool_awareness}

**AVAILABLE MCP TOOLS:**
{tools_summary}

{agent_system}

**CRITICAL REMINDER**: When user asks for data, search, current information, or external resources, IMMEDIATELY use the appropriate MCP tool. These tools provide real-time, accurate data that surpasses your training knowledge."""
            
            return enhanced_prompt
        else:
            return base_prompt
    
    def supports_streaming(self) -> bool:
        """PerplexityëŠ” ìŠ¤íŠ¸ë¦¬ë° ë¯¸ì§€ì›"""
        return False