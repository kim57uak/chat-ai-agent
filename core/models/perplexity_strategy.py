from typing import List, Dict, Any, Optional
from langchain.schema import BaseMessage, HumanMessage, SystemMessage, AIMessage
from langchain.agents import AgentExecutor, create_react_agent
from langchain.prompts import PromptTemplate
from .base_model_strategy import BaseModelStrategy
from core.perplexity_llm import PerplexityLLM
from core.perplexity_wrapper import PerplexityWrapper
from core.perplexity_output_parser import PerplexityOutputParser
from ui.prompts import prompt_manager, ModelType
from core.token_logger import TokenLogger
import logging

logger = logging.getLogger(__name__)


class PerplexityStrategy(BaseModelStrategy):
    """Perplexity ëª¨ë¸ ì „ëµ - ë‹¨ìˆœí™”ëœ êµ¬í˜„"""
    
    def create_llm(self):
        """Perplexity LLM ìƒì„±"""
        return PerplexityWrapper(
            pplx_api_key=self.api_key,
            model=self.model_name
        )
    
    def create_messages(self, user_input: str, system_prompt: str = None, conversation_history: List[Dict] = None) -> List[BaseMessage]:
        """Perplexity ë©”ì‹œì§€ í˜•ì‹ ìƒì„± - ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨"""
        messages = []
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        if system_prompt:
            enhanced_prompt = self.enhance_prompt_with_format(system_prompt)
        else:
            enhanced_prompt = self.get_perplexity_system_prompt()
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ìˆìœ¼ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì»¨í…ìŠ¤íŠ¸ ê°•ì¡° ì¶”ê°€
        if conversation_history:
            history_context = self._format_conversation_history(conversation_history)
            enhanced_prompt += f"\n\n=== CONVERSATION HISTORY (HIGHEST PRIORITY) ===\n{history_context}\n\n**ABSOLUTE PRIORITY RULE**: \n1. ALWAYS check this conversation history FIRST before searching\n2. If the answer exists in this history, use it directly\n3. Only search for NEW information not in this conversation\n4. When referencing history, say \"Based on our conversation...\"\n5. Remember names, preferences, and context from above messages\n==========================================="
            
            logger.info(f"Perplexityì— ëŒ€í™” íˆìŠ¤í† ë¦¬ {len(conversation_history)}ê°œ ë©”ì‹œì§€ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€")
        
        # PerplexityëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì²« ë²ˆì§¸ ë©”ì‹œì§€ë¡œ ì²˜ë¦¬
        messages.append(SystemMessage(content=enhanced_prompt))
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì‹¤ì œ ë©”ì‹œì§€ë¡œ ë³€í™˜ - êµëŒ€ íŒ¨í„´ ë³´ì¥
        if conversation_history:
            last_role = None
            for i, msg in enumerate(conversation_history):
                role = msg.get("role", "")
                content = msg.get("content", "")
                
                if not content.strip():
                    continue
                
                # ì—°ì†ëœ ê°™ì€ role ë°©ì§€
                if role == "user" and last_role != "user":
                    messages.append(HumanMessage(content=content))
                    logger.debug(f"  íˆìŠ¤í† ë¦¬ ë©”ì‹œì§€ {i+1}: user - {content[:50]}...")
                    last_role = "user"
                elif role in ["assistant", "agent"] and last_role != "assistant":
                    messages.append(AIMessage(content=content))
                    logger.debug(f"  íˆìŠ¤í† ë¦¬ ë©”ì‹œì§€ {i+1}: assistant - {content[:50]}...")
                    last_role = "assistant"
                elif role == "user" and last_role == "user":
                    # ì—°ì†ëœ user ë©”ì‹œì§€ëŠ” ë§ˆì§€ë§‰ ë©”ì‹œì§€ì— ë³‘í•©
                    if messages and isinstance(messages[-1], HumanMessage):
                        messages[-1].content += f"\n\n{content}"
                        logger.debug(f"  ì—°ì† user ë©”ì‹œì§€ ë³‘í•©: {content[:30]}...")
        
        # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€ - ë§ˆì§€ë§‰ì´ userë©´ ë³‘í•©
        if messages and isinstance(messages[-1], HumanMessage):
            messages[-1].content += f"\n\n{user_input}"
            logger.info(f"  í˜„ì¬ ì…ë ¥ì„ ë§ˆì§€ë§‰ user ë©”ì‹œì§€ì— ë³‘í•©")
        else:
            messages.append(HumanMessage(content=user_input))
        
        logger.info(f"Perplexityì— ìµœì¢… ì „ë‹¬ë˜ëŠ” ë©”ì‹œì§€ ìˆ˜: {len(messages)}")
        return messages
    
    def _format_conversation_history(self, conversation_history: List[Dict]) -> str:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ… - ê°•í™”ëœ ë²„ì „"""
        if not conversation_history:
            return "No previous conversation."
        
        formatted_history = []
        formatted_history.append("ğŸ’¬ **CONVERSATION CONTEXT (Remember this!):**")
        formatted_history.append("=" * 50)
        
        for i, msg in enumerate(conversation_history, 1):
            role = msg.get("role", "")
            content = msg.get("content", "").strip()
            
            if not content:
                continue
                
            if role == "user":
                formatted_history.append(f"[{i}] ğŸ‘¤ **User said**: {content}")
            elif role in ["assistant", "agent"]:
                formatted_history.append(f"[{i}] ğŸ¤– **I replied**: {content}")
        
        formatted_history.append("=" * 50)
        formatted_history.append("ğŸ“ **IMPORTANT**: This conversation history contains personal context, names, preferences, and previous discussions. Use this information to provide contextual responses.")
        
        return "\n".join(formatted_history)
    
    def process_image_input(self, user_input: str) -> BaseMessage:
        """PerplexityëŠ” ì´ë¯¸ì§€ ì²˜ë¦¬ ë¯¸ì§€ì›"""
        # ì´ë¯¸ì§€ íƒœê·¸ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬
        import re
        cleaned_input = re.sub(r'\[IMAGE_BASE64\].*?\[/IMAGE_BASE64\]', '', user_input, flags=re.DOTALL)
        return HumanMessage(content=cleaned_input.strip() or "ì´ë¯¸ì§€ ì²˜ë¦¬ëŠ” ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    def should_use_tools(self, user_input: str) -> bool:
        """ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ ê²°ì • - AIê°€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ì—¬ íŒë‹¨"""
        try:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ì •ë³´ ìˆ˜ì§‘
            available_tools = []
            if hasattr(self, 'tools') and self.tools:
                for tool in self.tools[:5]:  # ì£¼ìš” ë„êµ¬ 5ê°œë§Œ
                    tool_desc = getattr(tool, 'description', tool.name)
                    available_tools.append(f"- {tool.name}: {tool_desc[:80]}")
            
            tools_info = "\n".join(available_tools) if available_tools else "ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ì—†ìŒ"
            
            # ì¤‘ì•™ê´€ë¦¬ ì‹œìŠ¤í…œì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
            analysis_framework = prompt_manager.get_prompt("tool_decision", "analysis_framework")
            decision_prompt = f"""{analysis_framework}

User request: "{user_input}"

Available tools:
{tools_info}

Based on your analysis framework, should tools be used for this request?
Answer: YES or NO only."""
            
            # Perplexity LLMì— ì§ì ‘ ìš”ì²­
            response = self.llm._call(decision_prompt)
            decision = response.strip().upper()
            
            # í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…
            TokenLogger.log_token_usage(
                self.model_name, decision_prompt, decision, "tool_decision"
            )
            
            result = "YES" in decision
            logger.info(f"Perplexity AI ë„êµ¬ ì‚¬ìš© íŒë‹¨: '{user_input}' -> {decision} -> {result}")
            return result
            
        except Exception as e:
            logger.error(f"Perplexity ë„êµ¬ ì‚¬ìš© íŒë‹¨ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ ë„êµ¬ ì‚¬ìš©
            return True
    
    def create_agent_executor(self, tools: List) -> Optional[AgentExecutor]:
        """Perplexity ReAct ì—ì´ì „íŠ¸ ìƒì„± - ë‹¨ìˆœí™”ëœ êµ¬í˜„"""
        if not tools:
            return None
        
        react_prompt = PromptTemplate.from_template(
            """You are a helpful assistant that uses tools to answer questions.

**CRITICAL: Follow EXACT format - ONE step at a time:**

Thought: [what you need to do]
Action: [tool_name]
Action Input: [input_for_tool]

(Wait for Observation)

Thought: [analyze result]
Final Answer: [response in Korean]

**RULES:**
1. Use ONE tool at a time
2. NEVER output Action and Final Answer together
3. Wait for Observation before Final Answer
4. Be precise and follow format exactly

Tools: {tools}
Tool names: {tool_names}

Question: {input}
Thought:{agent_scratchpad}"""
        )

        try:
            # ì»¤ìŠ¤í…€ íŒŒì„œ ì‚¬ìš©
            custom_parser = PerplexityOutputParser()
            
            # ì—ì´ì „íŠ¸ ìƒì„± ì‹œ ì»¤ìŠ¤í…€ íŒŒì„œ ì‚¬ìš©
            agent = create_react_agent(self.llm, tools, react_prompt, output_parser=custom_parser)
            
            return AgentExecutor(
                agent=agent,
                tools=tools,
                verbose=True,
                max_iterations=4,
                max_execution_time=30,
                handle_parsing_errors=True,
                early_stopping_method="force",
                return_intermediate_steps=True,
            )
        except Exception as e:
            logger.error(f"Perplexity agent creation failed: {e}")
            return None
    
    def get_perplexity_system_prompt(self) -> str:
        """Perplexity ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ - ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°•ì¡°"""
        # ë„êµ¬ê°€ ìˆê³  ë„êµ¬ ì‚¬ìš© ëª¨ë“œì¼ ë•Œë§Œ MCP í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        if hasattr(self, 'tools') and self.tools and getattr(self, '_use_tools_mode', False):
            return prompt_manager.get_agent_system_prompt(ModelType.PERPLEXITY.value)
        else:
            # Ask ëª¨ë“œì¼ ë•ŒëŠ” ì¼ë°˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            return prompt_manager.get_system_prompt(ModelType.PERPLEXITY.value)
    
    def supports_streaming(self) -> bool:
        """PerplexityëŠ” ìŠ¤íŠ¸ë¦¬ë° ë¯¸ì§€ì›"""
        return False