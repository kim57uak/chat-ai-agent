from typing import List, Dict, Any, Optional
from langchain.schema import BaseMessage, HumanMessage, SystemMessage, AIMessage
from langchain.agents import AgentExecutor, create_react_agent
from langchain.prompts import PromptTemplate
from .base_model_strategy import BaseModelStrategy
from core.perplexity_llm import PerplexityLLM
from core.perplexity_wrapper import PerplexityWrapper
from core.perplexity_output_parser import PerplexityOutputParser
from core.enhanced_system_prompts import SystemPrompts
import logging

logger = logging.getLogger(__name__)


class PerplexityStrategy(BaseModelStrategy):
    """Perplexity ëª¨ë¸ ì „ëµ - ë‹¨ìˆœí™”ëœ êµ¬í˜„"""
    
    def create_llm(self):
        """Perplexity LLM ìƒì„±"""
        return PerplexityWrapper(
            pplx_api_key=self.api_key,
            model=self.model_name
        )
    
    def create_messages(self, user_input: str, system_prompt: str = None, conversation_history: List[Dict] = None) -> List[BaseMessage]:
        """Perplexity ë©”ì‹œì§€ í˜•ì‹ ìƒì„± - ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨"""
        messages = []
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        if system_prompt:
            enhanced_prompt = self.enhance_prompt_with_format(system_prompt)
        else:
            enhanced_prompt = self.get_perplexity_system_prompt()
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ìˆìœ¼ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì»¨í…ìŠ¤íŠ¸ ê°•ì¡° ì¶”ê°€
        if conversation_history:
            history_context = self._format_conversation_history(conversation_history)
            enhanced_prompt += f"\n\n=== CONVERSATION HISTORY (HIGHEST PRIORITY) ===\n{history_context}\n\n**ABSOLUTE PRIORITY RULE**: \n1. ALWAYS check this conversation history FIRST before searching\n2. If the answer exists in this history, use it directly\n3. Only search for NEW information not in this conversation\n4. When referencing history, say \"Based on our conversation...\"\n5. Remember names, preferences, and context from above messages\n==========================================="
            
            logger.info(f"Perplexityì— ëŒ€í™” íˆìŠ¤í† ë¦¬ {len(conversation_history)}ê°œ ë©”ì‹œì§€ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€")
        
        # PerplexityëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì²« ë²ˆì§¸ ë©”ì‹œì§€ë¡œ ì²˜ë¦¬
        messages.append(SystemMessage(content=enhanced_prompt))
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì‹¤ì œ ë©”ì‹œì§€ë¡œ ë³€í™˜ - êµëŒ€ íŒ¨í„´ ë³´ì¥
        if conversation_history:
            last_role = None
            for i, msg in enumerate(conversation_history):
                role = msg.get("role", "")
                content = msg.get("content", "")
                
                if not content.strip():
                    continue
                
                # ì—°ì†ëœ ê°™ì€ role ë°©ì§€
                if role == "user" and last_role != "user":
                    messages.append(HumanMessage(content=content))
                    logger.debug(f"  íˆìŠ¤í† ë¦¬ ë©”ì‹œì§€ {i+1}: user - {content[:50]}...")
                    last_role = "user"
                elif role in ["assistant", "agent"] and last_role != "assistant":
                    messages.append(AIMessage(content=content))
                    logger.debug(f"  íˆìŠ¤í† ë¦¬ ë©”ì‹œì§€ {i+1}: assistant - {content[:50]}...")
                    last_role = "assistant"
                elif role == "user" and last_role == "user":
                    # ì—°ì†ëœ user ë©”ì‹œì§€ëŠ” ë§ˆì§€ë§‰ ë©”ì‹œì§€ì— ë³‘í•©
                    if messages and isinstance(messages[-1], HumanMessage):
                        messages[-1].content += f"\n\n{content}"
                        logger.debug(f"  ì—°ì† user ë©”ì‹œì§€ ë³‘í•©: {content[:30]}...")
        
        # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€ - ë§ˆì§€ë§‰ì´ userë©´ ë³‘í•©
        if messages and isinstance(messages[-1], HumanMessage):
            messages[-1].content += f"\n\n{user_input}"
            logger.info(f"  í˜„ì¬ ì…ë ¥ì„ ë§ˆì§€ë§‰ user ë©”ì‹œì§€ì— ë³‘í•©")
        else:
            messages.append(HumanMessage(content=user_input))
        
        logger.info(f"Perplexityì— ìµœì¢… ì „ë‹¬ë˜ëŠ” ë©”ì‹œì§€ ìˆ˜: {len(messages)}")
        return messages
    
    def _format_conversation_history(self, conversation_history: List[Dict]) -> str:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ… - ê°•í™”ëœ ë²„ì „"""
        if not conversation_history:
            return "No previous conversation."
        
        formatted_history = []
        formatted_history.append("ğŸ’¬ **CONVERSATION CONTEXT (Remember this!):**")
        formatted_history.append("=" * 50)
        
        for i, msg in enumerate(conversation_history, 1):
            role = msg.get("role", "")
            content = msg.get("content", "").strip()
            
            if not content:
                continue
                
            if role == "user":
                formatted_history.append(f"[{i}] ğŸ‘¤ **User said**: {content}")
            elif role in ["assistant", "agent"]:
                formatted_history.append(f"[{i}] ğŸ¤– **I replied**: {content}")
        
        formatted_history.append("=" * 50)
        formatted_history.append("ğŸ“ **IMPORTANT**: This conversation history contains personal context, names, preferences, and previous discussions. Use this information to provide contextual responses.")
        
        return "\n".join(formatted_history)
    
    def process_image_input(self, user_input: str) -> BaseMessage:
        """PerplexityëŠ” ì´ë¯¸ì§€ ì²˜ë¦¬ ë¯¸ì§€ì›"""
        # ì´ë¯¸ì§€ íƒœê·¸ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬
        import re
        cleaned_input = re.sub(r'\[IMAGE_BASE64\].*?\[/IMAGE_BASE64\]', '', user_input, flags=re.DOTALL)
        return HumanMessage(content=cleaned_input.strip() or "ì´ë¯¸ì§€ ì²˜ë¦¬ëŠ” ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    def should_use_tools(self, user_input: str) -> bool:
        """ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ ê²°ì • - AIê°€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ì—¬ íŒë‹¨"""
        try:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ì •ë³´ ìˆ˜ì§‘
            available_tools = []
            if hasattr(self, 'tools') and self.tools:
                for tool in self.tools[:5]:  # ì£¼ìš” ë„êµ¬ 5ê°œë§Œ
                    tool_desc = getattr(tool, 'description', tool.name)
                    available_tools.append(f"- {tool.name}: {tool_desc[:80]}")
            
            tools_info = "\n".join(available_tools) if available_tools else "ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ì—†ìŒ"
            
            decision_prompt = f"""User request: "{user_input}"

Available tools:
{tools_info}

Analyze if this request requires using external tools to provide accurate information.

Use tools for:
- Real-time data queries (databases, web searches, file systems)
- Specific information lookups that I don't have in my knowledge
- External API calls or system operations
- Current/live information requests
- Data processing or calculations requiring external resources

Do NOT use tools for:
- General knowledge questions I can answer
- Simple conversations or greetings
- Creative writing or brainstorming
- Explanations of concepts I know
- Opinion-based discussions

Answer: YES or NO only."""
            
            # Perplexity LLMì— ì§ì ‘ ìš”ì²­
            response = self.llm._call(decision_prompt)
            decision = response.strip().upper()
            
            result = "YES" in decision
            logger.info(f"Perplexity AI ë„êµ¬ ì‚¬ìš© íŒë‹¨: '{user_input}' -> {decision} -> {result}")
            return result
            
        except Exception as e:
            logger.error(f"Perplexity ë„êµ¬ ì‚¬ìš© íŒë‹¨ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ ë„êµ¬ ì‚¬ìš©
            return True
    
    def create_agent_executor(self, tools: List) -> Optional[AgentExecutor]:
        """Perplexity ReAct ì—ì´ì „íŠ¸ ìƒì„± - ë‹¨ìˆœí™”ëœ êµ¬í˜„"""
        if not tools:
            return None
        
        react_prompt = PromptTemplate.from_template(
            """You are a helpful assistant that uses tools to answer questions.

**CRITICAL: Follow EXACT format - ONE step at a time:**

Thought: [what you need to do]
Action: [tool_name]
Action Input: [input_for_tool]

(Wait for Observation)

Thought: [analyze result]
Final Answer: [response in Korean]

**RULES:**
1. Use ONE tool at a time
2. NEVER output Action and Final Answer together
3. Wait for Observation before Final Answer
4. Be precise and follow format exactly

Tools: {tools}
Tool names: {tool_names}

Question: {input}
Thought:{agent_scratchpad}"""
        )

        try:
            # ì»¤ìŠ¤í…€ íŒŒì„œ ì‚¬ìš©
            custom_parser = PerplexityOutputParser()
            
            # ì—ì´ì „íŠ¸ ìƒì„± ì‹œ ì»¤ìŠ¤í…€ íŒŒì„œ ì‚¬ìš©
            agent = create_react_agent(self.llm, tools, react_prompt, output_parser=custom_parser)
            
            return AgentExecutor(
                agent=agent,
                tools=tools,
                verbose=True,
                max_iterations=4,
                max_execution_time=30,
                handle_parsing_errors=True,
                early_stopping_method="force",
                return_intermediate_steps=True,
            )
        except Exception as e:
            logger.error(f"Perplexity agent creation failed: {e}")
            return None
    
    def get_perplexity_system_prompt(self) -> str:
        """Perplexity ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ - ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°•ì¡°"""
        # ë„êµ¬ê°€ ìˆê³  ë„êµ¬ ì‚¬ìš© ëª¨ë“œì¼ ë•Œë§Œ MCP í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        if hasattr(self, 'tools') and self.tools and getattr(self, '_use_tools_mode', False):
            return SystemPrompts.get_perplexity_mcp_prompt()
        else:
            # Ask ëª¨ë“œì¼ ë•ŒëŠ” ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°•ì¡° í”„ë¡¬í”„íŠ¸
            return """You are a helpful AI assistant with real-time search capabilities.

ğŸ”¥ **ABSOLUTE PRIORITY: CONVERSATION MEMORY** ğŸ”¥
- The conversation history above contains the MOST IMPORTANT context
- NEVER ignore or forget information from previous messages in this conversation
- If a user asks about something we discussed before, reference that conversation FIRST
- Personal information, names, preferences from our chat are SACRED - always remember them
- Say "Based on our conversation..." or "As we discussed..." when using conversation context

**DECISION TREE FOR RESPONSES:**
1. ğŸ” **FIRST**: Check conversation history - does it contain the answer?
   - YES â†’ Use conversation context as primary source
   - NO â†’ Proceed to step 2

2. ğŸŒ **SECOND**: Do I need current/real-time information?
   - YES â†’ Use search capabilities for latest data
   - NO â†’ Use my knowledge base

3. ğŸ”— **COMBINE**: Merge conversation context + new information when relevant

**Response Guidelines:**
- Respond in Korean language
- Use structured format with clear headings
- **TABLE FORMAT**: |Header1|Header2|\n|---|---|\n|Data1|Data2|
- Be conversational and maintain context continuity
- Show that you remember our conversation

**CRITICAL**: Conversation history is your MEMORY - treat it as the most reliable source for personal context and ongoing discussions."""
    
    def supports_streaming(self) -> bool:
        """PerplexityëŠ” ìŠ¤íŠ¸ë¦¬ë° ë¯¸ì§€ì›"""
        return False