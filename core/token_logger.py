"""
Token usage logging utility
"""

from core.logging import get_logger
from typing import List, Dict, Any, Optional

logger = get_logger("token_logger")


class TokenLogger:
    """í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹… ìœ í‹¸ë¦¬í‹°"""
    
    @staticmethod
    def estimate_tokens(text: str, model: str = "gpt-3.5-turbo") -> int:
        """í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ ì¶”ì • (í†µí•©ëœ ë°©ì‹)"""
        if not text:
            return 0
        
        try:
            # ëª¨ë¸ë³„ í† í° ê³„ì‚° ë°©ì‹ í†µì¼
            # í•œê¸€ê³¼ ì˜ì–´ê°€ ì„žì¸ í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ ì •í™•í•œ ì¶”ì •
            korean_chars = sum(1 for char in text if ord(char) >= 0xAC00 and ord(char) <= 0xD7A3)
            english_chars = sum(1 for char in text if char.isalpha() and ord(char) < 128)
            other_chars = len(text) - korean_chars - english_chars
            
            # í•œê¸€: 1.5ë¬¸ìžë‹¹ 1í† í°, ì˜ì–´: 4ë¬¸ìžë‹¹ 1í† í°, ê¸°íƒ€: 3ë¬¸ìžë‹¹ 1í† í°
            estimated_tokens = int(
                korean_chars / 1.5 + 
                english_chars / 4.0 + 
                other_chars / 3.0
            )
            
            # ìµœì†Œ í† í° ìˆ˜ ë³´ìž¥
            return max(1, estimated_tokens) if text.strip() else 0
            
        except Exception:
            # í´ë°±: ì „ì²´ ê¸¸ì´ ê¸°ë°˜ ì¶”ì •
            return max(1, len(text) // 3) if text.strip() else 0
    
    @staticmethod
    def tokens_to_kb(tokens: int) -> float:
        """í† í°ì„ KBë¡œ ë³€í™˜ (ëŒ€ëžµì )"""
        # 1í† í° â‰ˆ 4ë°”ì´íŠ¸ë¡œ ì¶”ì •
        return (tokens * 4) / 1024
    
    @staticmethod
    def log_token_usage(
        model_name: str,
        input_text: str,
        output_text: str,
        operation: str = "chat"
    ):
        """í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…"""
        input_tokens = TokenLogger.estimate_tokens(input_text, model_name)
        output_tokens = TokenLogger.estimate_tokens(output_text, model_name)
        total_tokens = input_tokens + output_tokens
        
        input_kb = TokenLogger.tokens_to_kb(input_tokens)
        output_kb = TokenLogger.tokens_to_kb(output_tokens)
        total_kb = TokenLogger.tokens_to_kb(total_tokens)
        
        logger.info(
            f"ðŸ”¢ Token Usage [{model_name}] {operation}: "
            f"Input: {input_tokens:,} tokens ({input_kb:.2f}KB), "
            f"Output: {output_tokens:,} tokens ({output_kb:.2f}KB), "
            f"Total: {total_tokens:,} tokens ({total_kb:.2f}KB)"
        )
    
    @staticmethod
    def log_messages_token_usage(
        model_name: str,
        messages: List[Any],
        output_text: str,
        operation: str = "chat"
    ):
        """ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì˜ í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…"""
        input_text = ""
        for msg in messages:
            if hasattr(msg, 'content'):
                if isinstance(msg.content, str):
                    input_text += msg.content + "\n"
                elif isinstance(msg.content, list):
                    for item in msg.content:
                        if isinstance(item, dict) and item.get('type') == 'text':
                            input_text += item.get('text', '') + "\n"
        
        TokenLogger.log_token_usage(model_name, input_text, output_text, operation)
    
    @staticmethod
    def extract_actual_tokens(response_obj) -> tuple[int, int]:
        """API ì‘ë‹µì—ì„œ ì‹¤ì œ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ (í†µí•© ë²„ì „)"""
        if not response_obj:
            return 0, 0
            
        try:
            # 1. OpenAI ì§ì ‘ ì‘ë‹µ í˜•ì‹
            if hasattr(response_obj, 'usage'):
                usage = response_obj.usage
                input_tokens = getattr(usage, 'prompt_tokens', getattr(usage, 'input_tokens', 0))
                output_tokens = getattr(usage, 'completion_tokens', getattr(usage, 'output_tokens', 0))
                if input_tokens > 0 or output_tokens > 0:
                    return input_tokens, output_tokens
            
            # 2. Langchain ì‘ë‹µ í˜•ì‹
            if hasattr(response_obj, 'response_metadata'):
                metadata = response_obj.response_metadata
                
                # token_usage í•„ë“œ í™•ì¸
                if 'token_usage' in metadata:
                    token_usage = metadata['token_usage']
                    input_tokens = token_usage.get('prompt_tokens', token_usage.get('input_tokens', 0))
                    output_tokens = token_usage.get('completion_tokens', token_usage.get('output_tokens', 0))
                    if input_tokens > 0 or output_tokens > 0:
                        return input_tokens, output_tokens
                
                # usage_metadata í•„ë“œ í™•ì¸
                if 'usage_metadata' in metadata:
                    usage_metadata = metadata['usage_metadata']
                    input_tokens = usage_metadata.get('input_tokens', usage_metadata.get('prompt_tokens', 0))
                    output_tokens = usage_metadata.get('output_tokens', usage_metadata.get('completion_tokens', 0))
                    if input_tokens > 0 or output_tokens > 0:
                        return input_tokens, output_tokens
            
            # 3. Google Gemini ì§ì ‘ ì‘ë‹µ í˜•ì‹
            if hasattr(response_obj, 'usage_metadata'):
                usage = response_obj.usage_metadata
                input_tokens = getattr(usage, 'prompt_token_count', getattr(usage, 'input_tokens', 0))
                output_tokens = getattr(usage, 'candidates_token_count', getattr(usage, 'output_tokens', 0))
                if input_tokens > 0 or output_tokens > 0:
                    return input_tokens, output_tokens
            
            # 4. ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ì‘ë‹µ (ì—ì´ì „íŠ¸ ì‘ë‹µ ë“±)
            if isinstance(response_obj, list) and response_obj:
                total_input = 0
                total_output = 0
                for item in response_obj:
                    input_tokens, output_tokens = TokenLogger.extract_actual_tokens(item)
                    total_input += input_tokens
                    total_output += output_tokens
                if total_input > 0 or total_output > 0:
                    return total_input, total_output
            
            # 5. ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ì‘ë‹µ
            if isinstance(response_obj, dict):
                # ì§ì ‘ usage í•„ë“œ
                if 'usage' in response_obj:
                    usage = response_obj['usage']
                    input_tokens = usage.get('prompt_tokens', usage.get('input_tokens', 0))
                    output_tokens = usage.get('completion_tokens', usage.get('output_tokens', 0))
                    if input_tokens > 0 or output_tokens > 0:
                        return input_tokens, output_tokens
                
                # ì¤‘ì²©ëœ êµ¬ì¡°ì—ì„œ í† í° ì •ë³´ ì°¾ê¸°
                for key, value in response_obj.items():
                    if isinstance(value, dict):
                        key_lower = str(key).lower()
                        if 'token' in key_lower or 'usage' in key_lower:
                            input_tokens, output_tokens = TokenLogger.extract_actual_tokens(value)
                            if input_tokens > 0 or output_tokens > 0:
                                return input_tokens, output_tokens
            
            return 0, 0
            
        except Exception as e:
            logger.debug(f"í† í° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return 0, 0
    
    @staticmethod
    def log_actual_token_usage(
        model_name: str,
        response_obj,
        operation: str = "chat"
    ):
        """ì‹¤ì œ API ì‘ë‹µì—ì„œ í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…"""
        input_tokens, output_tokens = TokenLogger.extract_actual_tokens(response_obj)
        
        if input_tokens > 0 or output_tokens > 0:
            total_tokens = input_tokens + output_tokens
            logger.info(
                f"ðŸ”¢ Actual Token Usage [{model_name}] {operation}: "
                f"Input: {input_tokens:,} tokens, "
                f"Output: {output_tokens:,} tokens, "
                f"Total: {total_tokens:,} tokens"
            )
            return input_tokens, output_tokens
        
        return 0, 0