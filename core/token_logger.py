"""
Token usage logging utility
"""

import logging
from typing import List, Dict, Any, Optional

logger = logging.getLogger(__name__)


class TokenLogger:
    """í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹… ìœ í‹¸ë¦¬í‹°"""
    
    @staticmethod
    def estimate_tokens(text: str, model: str = "gpt-3.5-turbo") -> int:
        """í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ ì¶”ì • (ê°„ë‹¨í•œ ë°©ì‹)"""
        try:
            # ê°„ë‹¨í•œ í† í° ì¶”ì •: 1í† í° â‰ˆ 4ë¬¸ìž (ì˜ì–´ ê¸°ì¤€)
            # í•œê¸€ì˜ ê²½ìš° ë” ì ì€ ë¬¸ìž ìˆ˜ë¡œ í† í°ì´ êµ¬ì„±ë¨
            if any(ord(char) > 127 for char in text):  # í•œê¸€/íŠ¹ìˆ˜ë¬¸ìž í¬í•¨
                return len(text) // 2  # í•œê¸€ì€ ëŒ€ëžµ 2ë¬¸ìžë‹¹ 1í† í°
            else:
                return len(text) // 4  # ì˜ì–´ëŠ” ëŒ€ëžµ 4ë¬¸ìžë‹¹ 1í† í°
        except Exception:
            return len(text) // 3  # ê¸°ë³¸ ì¶”ì •
    
    @staticmethod
    def tokens_to_kb(tokens: int) -> float:
        """í† í°ì„ KBë¡œ ë³€í™˜ (ëŒ€ëžµì )"""
        # 1í† í° â‰ˆ 4ë°”ì´íŠ¸ë¡œ ì¶”ì •
        return (tokens * 4) / 1024
    
    @staticmethod
    def log_token_usage(
        model_name: str,
        input_text: str,
        output_text: str,
        operation: str = "chat"
    ):
        """í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…"""
        input_tokens = TokenLogger.estimate_tokens(input_text, model_name)
        output_tokens = TokenLogger.estimate_tokens(output_text, model_name)
        total_tokens = input_tokens + output_tokens
        
        input_kb = TokenLogger.tokens_to_kb(input_tokens)
        output_kb = TokenLogger.tokens_to_kb(output_tokens)
        total_kb = TokenLogger.tokens_to_kb(total_tokens)
        
        logger.info(
            f"ðŸ”¢ Token Usage [{model_name}] {operation}: "
            f"Input: {input_tokens:,} tokens ({input_kb:.2f}KB), "
            f"Output: {output_tokens:,} tokens ({output_kb:.2f}KB), "
            f"Total: {total_tokens:,} tokens ({total_kb:.2f}KB)"
        )
    
    @staticmethod
    def log_messages_token_usage(
        model_name: str,
        messages: List[Any],
        output_text: str,
        operation: str = "chat"
    ):
        """ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì˜ í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…"""
        input_text = ""
        for msg in messages:
            if hasattr(msg, 'content'):
                if isinstance(msg.content, str):
                    input_text += msg.content + "\n"
                elif isinstance(msg.content, list):
                    for item in msg.content:
                        if isinstance(item, dict) and item.get('type') == 'text':
                            input_text += item.get('text', '') + "\n"
        
        TokenLogger.log_token_usage(model_name, input_text, output_text, operation)
    
    @staticmethod
    def extract_actual_tokens(response_obj) -> tuple[int, int]:
        """API ì‘ë‹µì—ì„œ ì‹¤ì œ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ"""
        try:
            if not response_obj:
                return 0, 0
            
            # OpenAI ì§ì ‘ ì‘ë‹µ í˜•ì‹
            if hasattr(response_obj, 'usage'):
                usage = response_obj.usage
                return getattr(usage, 'prompt_tokens', 0), getattr(usage, 'completion_tokens', 0)
            
            # Langchain ì‘ë‹µ í˜•ì‹
            if hasattr(response_obj, 'response_metadata'):
                metadata = response_obj.response_metadata
                if 'token_usage' in metadata:
                    token_usage = metadata['token_usage']
                    return token_usage.get('prompt_tokens', 0), token_usage.get('completion_tokens', 0)
                if 'usage_metadata' in metadata:
                    usage_metadata = metadata['usage_metadata']
                    return usage_metadata.get('input_tokens', 0), usage_metadata.get('output_tokens', 0)
            
            # Google Gemini ì‘ë‹µ í˜•ì‹
            if hasattr(response_obj, 'usage_metadata'):
                usage = response_obj.usage_metadata
                return getattr(usage, 'prompt_token_count', 0), getattr(usage, 'candidates_token_count', 0)
            
            # Anthropic Claude ì‘ë‹µ í˜•ì‹
            if hasattr(response_obj, 'usage'):
                usage = response_obj.usage
                return getattr(usage, 'input_tokens', 0), getattr(usage, 'output_tokens', 0)
            
            # Perplexity ì‘ë‹µ í˜•ì‹
            if hasattr(response_obj, 'model_extra') and 'usage' in response_obj.model_extra:
                usage = response_obj.model_extra['usage']
                return usage.get('prompt_tokens', 0), usage.get('completion_tokens', 0)
            
            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ì‘ë‹µ (ì—ì´ì „íŠ¸ ì‘ë‹µ ë“±)
            if isinstance(response_obj, list) and response_obj:
                for item in response_obj:
                    input_tokens, output_tokens = TokenLogger.extract_actual_tokens(item)
                    if input_tokens > 0 or output_tokens > 0:
                        return input_tokens, output_tokens
            
            # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ì‘ë‹µ
            if isinstance(response_obj, dict):
                # ì§ì ‘ í† í° ì •ë³´ê°€ ìžˆëŠ” ê²½ìš°
                if 'usage' in response_obj:
                    usage = response_obj['usage']
                    return usage.get('prompt_tokens', usage.get('input_tokens', 0)), usage.get('completion_tokens', usage.get('output_tokens', 0))
                
                # ì¤‘ì²©ëœ êµ¬ì¡°ì—ì„œ í† í° ì •ë³´ ì°¾ê¸°
                for key, value in response_obj.items():
                    if isinstance(value, dict) and ('tokens' in str(key).lower() or 'usage' in str(key).lower()):
                        input_tokens, output_tokens = TokenLogger.extract_actual_tokens(value)
                        if input_tokens > 0 or output_tokens > 0:
                            return input_tokens, output_tokens
            
            return 0, 0
        except Exception as e:
            logger.debug(f"í† í° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return 0, 0
    
    @staticmethod
    def log_actual_token_usage(
        model_name: str,
        response_obj,
        operation: str = "chat"
    ):
        """ì‹¤ì œ API ì‘ë‹µì—ì„œ í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…"""
        input_tokens, output_tokens = TokenLogger.extract_actual_tokens(response_obj)
        
        if input_tokens > 0 or output_tokens > 0:
            total_tokens = input_tokens + output_tokens
            logger.info(
                f"ðŸ”¢ Actual Token Usage [{model_name}] {operation}: "
                f"Input: {input_tokens:,} tokens, "
                f"Output: {output_tokens:,} tokens, "
                f"Total: {total_tokens:,} tokens"
            )
            return input_tokens, output_tokens
        
        return 0, 0