"""
Token usage logging utility
"""

import logging
from typing import List, Dict, Any, Optional

logger = logging.getLogger(__name__)


class TokenLogger:
    """í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹… ìœ í‹¸ë¦¬í‹°"""
    
    @staticmethod
    def estimate_tokens(text: str, model: str = "gpt-3.5-turbo") -> int:
        """í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ ì¶”ì • (ê°„ë‹¨í•œ ë°©ì‹)"""
        try:
            # ê°„ë‹¨í•œ í† í° ì¶”ì •: 1í† í° â‰ˆ 4ë¬¸ì (ì˜ì–´ ê¸°ì¤€)
            # í•œê¸€ì˜ ê²½ìš° ë” ì ì€ ë¬¸ì ìˆ˜ë¡œ í† í°ì´ êµ¬ì„±ë¨
            if any(ord(char) > 127 for char in text):  # í•œê¸€/íŠ¹ìˆ˜ë¬¸ì í¬í•¨
                return len(text) // 2  # í•œê¸€ì€ ëŒ€ëµ 2ë¬¸ìë‹¹ 1í† í°
            else:
                return len(text) // 4  # ì˜ì–´ëŠ” ëŒ€ëµ 4ë¬¸ìë‹¹ 1í† í°
        except Exception:
            return len(text) // 3  # ê¸°ë³¸ ì¶”ì •
    
    @staticmethod
    def tokens_to_kb(tokens: int) -> float:
        """í† í°ì„ KBë¡œ ë³€í™˜ (ëŒ€ëµì )"""
        # 1í† í° â‰ˆ 4ë°”ì´íŠ¸ë¡œ ì¶”ì •
        return (tokens * 4) / 1024
    
    @staticmethod
    def log_token_usage(
        model_name: str,
        input_text: str,
        output_text: str,
        operation: str = "chat"
    ):
        """í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…"""
        input_tokens = TokenLogger.estimate_tokens(input_text, model_name)
        output_tokens = TokenLogger.estimate_tokens(output_text, model_name)
        total_tokens = input_tokens + output_tokens
        
        input_kb = TokenLogger.tokens_to_kb(input_tokens)
        output_kb = TokenLogger.tokens_to_kb(output_tokens)
        total_kb = TokenLogger.tokens_to_kb(total_tokens)
        
        logger.info(
            f"ğŸ”¢ Token Usage [{model_name}] {operation}: "
            f"Input: {input_tokens} tokens ({input_kb:.2f}KB), "
            f"Output: {output_tokens} tokens ({output_kb:.2f}KB), "
            f"Total: {total_tokens} tokens ({total_kb:.2f}KB)"
        )
    
    @staticmethod
    def log_messages_token_usage(
        model_name: str,
        messages: List[Any],
        output_text: str,
        operation: str = "chat"
    ):
        """ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì˜ í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…"""
        input_text = ""
        for msg in messages:
            if hasattr(msg, 'content'):
                if isinstance(msg.content, str):
                    input_text += msg.content + "\n"
                elif isinstance(msg.content, list):
                    for item in msg.content:
                        if isinstance(item, dict) and item.get('type') == 'text':
                            input_text += item.get('text', '') + "\n"
        
        TokenLogger.log_token_usage(model_name, input_text, output_text, operation)