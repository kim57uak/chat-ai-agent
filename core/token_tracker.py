"""
Token usage tracking system for precise measurement across all AI interactions
"""

import logging
import time
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
import json
from datetime import datetime
from core.token_logger import TokenLogger

logger = logging.getLogger(__name__)


class StepType(Enum):
    """í† í° ì‚¬ìš© ë‹¨ê³„ íƒ€ì…"""
    INITIAL_PROMPT = "initial_prompt"
    TOOL_DECISION = "tool_decision"
    TOOL_EXECUTION = "tool_execution"
    TOOL_RESULT_PROCESSING = "tool_result_processing"
    FINAL_RESPONSE = "final_response"
    CONVERSATION_HISTORY = "conversation_history"


@dataclass
class TokenUsageStep:
    """ë‹¨ê³„ë³„ í† í° ì‚¬ìš©ëŸ‰ ì •ë³´"""
    step_type: StepType
    step_name: str
    model_name: str
    input_tokens: int = 0
    output_tokens: int = 0
    estimated_input_tokens: int = 0
    estimated_output_tokens: int = 0
    timestamp: float = field(default_factory=time.time)
    duration_ms: float = 0
    input_text_length: int = 0
    output_text_length: int = 0
    tool_name: Optional[str] = None
    additional_info: Dict[str, Any] = field(default_factory=dict)
    
    @property
    def total_tokens(self) -> int:
        return self.input_tokens + self.output_tokens
    
    @property
    def total_estimated_tokens(self) -> int:
        return self.estimated_input_tokens + self.estimated_output_tokens


@dataclass
class ConversationTokenUsage:
    """ëŒ€í™” ì „ì²´ì˜ í† í° ì‚¬ìš©ëŸ‰ ì •ë³´"""
    conversation_id: str
    user_input: str
    final_response: str
    model_name: str
    steps: List[TokenUsageStep] = field(default_factory=list)
    start_time: float = field(default_factory=time.time)
    end_time: Optional[float] = None
    total_duration_ms: float = 0
    
    @property
    def total_input_tokens(self) -> int:
        return sum(step.input_tokens for step in self.steps)
    
    @property
    def total_output_tokens(self) -> int:
        return sum(step.output_tokens for step in self.steps)
    
    @property
    def total_tokens(self) -> int:
        return self.total_input_tokens + self.total_output_tokens
    
    @property
    def total_estimated_input_tokens(self) -> int:
        return sum(step.estimated_input_tokens for step in self.steps)
    
    @property
    def total_estimated_output_tokens(self) -> int:
        return sum(step.estimated_output_tokens for step in self.steps)
    
    @property
    def total_estimated_tokens(self) -> int:
        return self.total_estimated_input_tokens + self.total_estimated_output_tokens


class TokenTracker:
    """ì •í™•í•œ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì  ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.current_conversation: Optional[ConversationTokenUsage] = None
        self.conversation_history: List[ConversationTokenUsage] = []
        self.step_start_time: Optional[float] = None
    
    def start_conversation(self, user_input: str, model_name: str) -> str:
        """ìƒˆë¡œìš´ ëŒ€í™” ì¶”ì  ì‹œì‘"""
        # ì´ì „ ëŒ€í™”ê°€ ìˆê³  ì•„ì§ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì¶”ê°€
        if self.current_conversation and self.current_conversation not in self.conversation_history:
            self.conversation_history.append(self.current_conversation)
            logger.info(f"ğŸ“ Previous conversation {self.current_conversation.conversation_id} moved to history")
        
        conversation_id = f"conv_{int(time.time() * 1000)}"
        self.current_conversation = ConversationTokenUsage(
            conversation_id=conversation_id,
            user_input=user_input,
            final_response="",
            model_name=model_name
        )
        logger.info(f"ğŸ¯ Started tracking conversation: {conversation_id}")
        return conversation_id
    
    def start_step(self, step_type: StepType, step_name: str, tool_name: Optional[str] = None):
        """ë‹¨ê³„ ì‹œì‘"""
        self.step_start_time = time.time()
        logger.debug(f"ğŸ“Š Starting step: {step_name} ({step_type.value})")
    
    def end_step(self, 
                 step_type: StepType, 
                 step_name: str,
                 input_text: str = "",
                 output_text: str = "",
                 response_obj: Any = None,
                 tool_name: Optional[str] = None,
                 additional_info: Dict[str, Any] = None) -> TokenUsageStep:
        """ë‹¨ê³„ ì¢…ë£Œ ë° í† í° ì‚¬ìš©ëŸ‰ ê¸°ë¡"""
        if not self.current_conversation:
            logger.warning("No active conversation to track")
            return None
        
        # ì‹¤ì œ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
        actual_input_tokens, actual_output_tokens = TokenLogger.extract_actual_tokens(response_obj)
        
        # ì¶”ì • í† í° ì‚¬ìš©ëŸ‰ ê³„ì‚°
        estimated_input_tokens = TokenLogger.estimate_tokens(input_text, self.current_conversation.model_name)
        estimated_output_tokens = TokenLogger.estimate_tokens(output_text, self.current_conversation.model_name)
        
        # ë‹¨ê³„ ì •ë³´ ìƒì„±
        duration_ms = (time.time() - self.step_start_time) * 1000 if self.step_start_time else 0
        
        # additional_infoì— ì‹¤ì œ í† í° ì •ë³´ ì¶”ê°€ (UIì—ì„œ ì‚¬ìš©)
        enhanced_additional_info = additional_info or {}
        enhanced_additional_info.update({
            'input_tokens': actual_input_tokens,
            'output_tokens': actual_output_tokens,
            'estimated_input_tokens': estimated_input_tokens,
            'estimated_output_tokens': estimated_output_tokens
        })
        
        step = TokenUsageStep(
            step_type=step_type,
            step_name=step_name,
            model_name=self.current_conversation.model_name,
            input_tokens=actual_input_tokens,
            output_tokens=actual_output_tokens,
            estimated_input_tokens=estimated_input_tokens,
            estimated_output_tokens=estimated_output_tokens,
            duration_ms=duration_ms,
            input_text_length=len(input_text),
            output_text_length=len(output_text),
            tool_name=tool_name,
            additional_info=enhanced_additional_info
        )
        
        self.current_conversation.steps.append(step)
        
        # ë¡œê¹…
        self._log_step_usage(step)
        
        return step
    
    def end_conversation(self, final_response: str = ""):
        """ëŒ€í™” ì¢…ë£Œ ë° ì „ì²´ í† í° ì‚¬ìš©ëŸ‰ ìš”ì•½"""
        if not self.current_conversation:
            return
        
        self.current_conversation.final_response = final_response
        self.current_conversation.end_time = time.time()
        self.current_conversation.total_duration_ms = (
            self.current_conversation.end_time - self.current_conversation.start_time
        ) * 1000
        
        # ì „ì²´ ìš”ì•½ ë¡œê¹…
        self._log_conversation_summary(self.current_conversation)
        
        # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
        if self.current_conversation not in self.conversation_history:
            self.conversation_history.append(self.current_conversation)
            logger.info(f"ğŸ“š Conversation {self.current_conversation.conversation_id} added to history")
        
        # í˜„ì¬ ëŒ€í™”ë¥¼ Noneìœ¼ë¡œ ì„¤ì •í•˜ì§€ ì•Šê³  ìœ ì§€ (UIì—ì„œ ê³„ì† ì°¸ì¡°í•  ìˆ˜ ìˆë„ë¡)
        # self.current_conversation = None  # ì£¼ì„ ì²˜ë¦¬
    
    def _log_step_usage(self, step: TokenUsageStep):
        """ë‹¨ê³„ë³„ í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…"""
        actual_str = f"Input: {step.input_tokens:,}, Output: {step.output_tokens:,}, Total: {step.total_tokens:,}"
        estimated_str = f"Input: {step.estimated_input_tokens:,}, Output: {step.estimated_output_tokens:,}, Total: {step.total_estimated_tokens:,}"
        
        tool_info = f" [Tool: {step.tool_name}]" if step.tool_name else ""
        
        logger.info(
            f"ğŸ“Š Step [{step.step_type.value}] {step.step_name}{tool_info} "
            f"({step.duration_ms:.1f}ms)\n"
            f"   ğŸ”¢ Actual Tokens: {actual_str}\n"
            f"   ğŸ“ Estimated Tokens: {estimated_str}\n"
            f"   ğŸ“ Text Length: Input {step.input_text_length:,}, Output {step.output_text_length:,}"
        )
    
    def _log_conversation_summary(self, conversation: ConversationTokenUsage):
        """ëŒ€í™” ì „ì²´ í† í° ì‚¬ìš©ëŸ‰ ìš”ì•½ ë¡œê¹…"""
        logger.info(
            f"\nğŸ¯ Conversation Summary [{conversation.conversation_id}] "
            f"({conversation.total_duration_ms:.1f}ms)\n"
            f"   Model: {conversation.model_name}\n"
            f"   Steps: {len(conversation.steps)}\n"
            f"   ğŸ”¢ Total Actual Tokens: Input {conversation.total_input_tokens:,}, "
            f"Output {conversation.total_output_tokens:,}, Total {conversation.total_tokens:,}\n"
            f"   ğŸ“ Total Estimated Tokens: Input {conversation.total_estimated_input_tokens:,}, "
            f"Output {conversation.total_estimated_output_tokens:,}, Total {conversation.total_estimated_tokens:,}\n"
            f"   ğŸ’° Accuracy: Input {self._calculate_accuracy(conversation.total_input_tokens, conversation.total_estimated_input_tokens):.1f}%, "
            f"Output {self._calculate_accuracy(conversation.total_output_tokens, conversation.total_estimated_output_tokens):.1f}%"
        )
        
        # ë‹¨ê³„ë³„ ìƒì„¸ ì •ë³´
        for i, step in enumerate(conversation.steps, 1):
            tool_info = f" [{step.tool_name}]" if step.tool_name else ""
            logger.info(
                f"   Step {i}: {step.step_name}{tool_info} - "
                f"Actual: {step.total_tokens:,} tokens, "
                f"Estimated: {step.total_estimated_tokens:,} tokens "
                f"({step.duration_ms:.1f}ms)"
            )
    
    def _calculate_accuracy(self, actual: int, estimated: int) -> float:
        """í† í° ì¶”ì • ì •í™•ë„ ê³„ì‚°"""
        if actual == 0:
            return 100.0 if estimated == 0 else 0.0
        return min(100.0, (1 - abs(actual - estimated) / actual) * 100)
    
    def get_session_total_tokens(self) -> Tuple[int, int, int]:
        """ì„¸ì…˜ ì „ì²´ í† í° ì‚¬ìš©ëŸ‰ ë°˜í™˜ (input, output, total)"""
        total_input = 0
        total_output = 0
        
        # íˆìŠ¤í† ë¦¬ ëŒ€í™” í† í° í¬í•¨ (ì‹¤ì œ í† í° ìš°ì„ , ì—†ìœ¼ë©´ ì¶”ì •)
        for conv in self.conversation_history:
            if conv.total_tokens > 0:  # ì‹¤ì œ í† í°ì´ ìˆìœ¼ë©´
                total_input += conv.total_input_tokens
                total_output += conv.total_output_tokens
            else:  # ì‹¤ì œ í† í°ì´ ì—†ìœ¼ë©´ ì¶”ì • í† í° ì‚¬ìš©
                total_input += conv.total_estimated_input_tokens
                total_output += conv.total_estimated_output_tokens
        
        # í˜„ì¬ ëŒ€í™” í† í° í¬í•¨ (ì‹¤ì œ í† í° ìš°ì„ , ì—†ìœ¼ë©´ ì¶”ì •)
        if self.current_conversation:
            if self.current_conversation.total_tokens > 0:  # ì‹¤ì œ í† í°ì´ ìˆìœ¼ë©´
                total_input += self.current_conversation.total_input_tokens
                total_output += self.current_conversation.total_output_tokens
            else:  # ì‹¤ì œ í† í°ì´ ì—†ìœ¼ë©´ ì¶”ì • í† í° ì‚¬ìš©
                total_input += self.current_conversation.total_estimated_input_tokens
                total_output += self.current_conversation.total_estimated_output_tokens
        
        return total_input, total_output, total_input + total_output
    
    def get_conversation_stats(self) -> Dict[str, Any]:
        """ëŒ€í™” í†µê³„ ì •ë³´ ë°˜í™˜"""
        # í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ëŒ€í™”ê°€ ìˆìœ¼ë©´ ìš°ì„  ë°˜í™˜
        if self.current_conversation:
            return {
                "conversation_id": self.current_conversation.conversation_id,
                "model_name": self.current_conversation.model_name,
                "steps_count": len(self.current_conversation.steps),
                "total_actual_tokens": self.current_conversation.total_tokens,
                "total_estimated_tokens": self.current_conversation.total_estimated_tokens,
                "duration_ms": self.current_conversation.total_duration_ms,
                "steps": [
                    {
                        "step_name": step.step_name,
                        "step_type": step.step_type.value,
                        "actual_tokens": step.total_tokens,
                        "estimated_tokens": step.total_estimated_tokens,
                        "duration_ms": step.duration_ms,
                        "tool_name": step.tool_name,
                        "additional_info": step.additional_info
                    }
                    for step in self.current_conversation.steps
                ]
            }
        
        # í˜„ì¬ ëŒ€í™”ê°€ ì—†ìœ¼ë©´ ìµœê·¼ ëŒ€í™” í™•ì¸
        if self.conversation_history:
            last_conv = self.conversation_history[-1]
            return {
                "conversation_id": last_conv.conversation_id,
                "model_name": last_conv.model_name,
                "steps_count": len(last_conv.steps),
                "total_actual_tokens": last_conv.total_tokens,
                "total_estimated_tokens": last_conv.total_estimated_tokens,
                "duration_ms": last_conv.total_duration_ms,
                "steps": [
                    {
                        "step_name": step.step_name,
                        "step_type": step.step_type.value,
                        "actual_tokens": step.total_tokens,
                        "estimated_tokens": step.total_estimated_tokens,
                        "duration_ms": step.duration_ms,
                        "tool_name": step.tool_name,
                        "additional_info": step.additional_info
                    }
                    for step in last_conv.steps
                ]
            }
        
        return {}
    
    def export_conversation_data(self, filepath: str):
        """ëŒ€í™” ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        data = {
            "export_time": datetime.now().isoformat(),
            "conversations": []
        }
        
        for conv in self.conversation_history:
            conv_data = {
                "conversation_id": conv.conversation_id,
                "model_name": conv.model_name,
                "user_input": conv.user_input[:200] + "..." if len(conv.user_input) > 200 else conv.user_input,
                "start_time": datetime.fromtimestamp(conv.start_time).isoformat(),
                "end_time": datetime.fromtimestamp(conv.end_time).isoformat() if conv.end_time else None,
                "total_duration_ms": conv.total_duration_ms,
                "total_actual_tokens": conv.total_tokens,
                "total_estimated_tokens": conv.total_estimated_tokens,
                "steps": [
                    {
                        "step_name": step.step_name,
                        "step_type": step.step_type.value,
                        "actual_input_tokens": step.input_tokens,
                        "actual_output_tokens": step.output_tokens,
                        "estimated_input_tokens": step.estimated_input_tokens,
                        "estimated_output_tokens": step.estimated_output_tokens,
                        "duration_ms": step.duration_ms,
                        "tool_name": step.tool_name,
                        "timestamp": datetime.fromtimestamp(step.timestamp).isoformat()
                    }
                    for step in conv.steps
                ]
            }
            data["conversations"].append(conv_data)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“ Exported {len(self.conversation_history)} conversations to {filepath}")


# ì „ì—­ í† í° íŠ¸ë˜ì»¤ ì¸ìŠ¤í„´ìŠ¤
token_tracker = TokenTracker()