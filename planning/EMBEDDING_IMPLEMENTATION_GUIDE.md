# ì„ë² ë”© ëª¨ë¸ êµ¬í˜„ ê°€ì´ë“œ

## êµ¬í˜„ ìš°ì„ ìˆœìœ„

### 1ë‹¨ê³„: í•µì‹¬ ì¸í”„ë¼ (ì™„ë£Œ)
- âœ… BaseEmbeddingModel ì¶”ìƒ í´ë˜ìŠ¤
- âœ… EmbeddingModelFactory íŒ©í† ë¦¬
- âœ… ê¸°ë³¸ ì„¤ì • ê´€ë¦¬ ì‹œìŠ¤í…œ
- âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œìŠ¤í…œ

### 2ë‹¨ê³„: ëª¨ë¸ í†µí•© (ì§„í–‰ì¤‘)
- âœ… SentenceTransformersEmbedding êµ¬í˜„
- âœ… OpenAIEmbedding API ë˜í¼
- ğŸ”„ í•œêµ­ì–´ ëª¨ë¸ ìµœì í™”
- â³ ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ

### 3ë‹¨ê³„: ì„±ëŠ¥ ìµœì í™” (ì˜ˆì •)
- â³ GPU ê°€ì† ì§€ì›
- â³ ë©€í‹°ìŠ¤ë ˆë”© ì²˜ë¦¬
- â³ ìºì‹± ì‹œìŠ¤í…œ ê°œì„ 
- â³ ë²¤ì¹˜ë§ˆí‚¹ ë„êµ¬

## ì½”ë“œ êµ¬ì¡°

### ë””ë ‰í† ë¦¬ êµ¬ì¡°
```
core/rag/embeddings/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base_embedding.py          # ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤
â”œâ”€â”€ embedding_factory.py       # íŒ©í† ë¦¬ íŒ¨í„´
â”œâ”€â”€ sentence_transformers_embedding.py  # ë¡œì»¬ ëª¨ë¸
â”œâ”€â”€ openai_embedding.py        # API ê¸°ë°˜ ëª¨ë¸
â”œâ”€â”€ embedding_cache.py         # ìºì‹± ì‹œìŠ¤í…œ
â”œâ”€â”€ embedding_config.py        # ì„¤ì • ê´€ë¦¬
â””â”€â”€ model_downloader.py        # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
```

### í•µì‹¬ í´ë˜ìŠ¤ êµ¬í˜„

#### BaseEmbeddingModel
```python
from abc import ABC, abstractmethod
from typing import List, Optional
import numpy as np

class BaseEmbeddingModel(ABC):
    """ì„ë² ë”© ëª¨ë¸ì˜ ê¸°ë³¸ ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self, model_name: str, **kwargs):
        self.model_name = model_name
        self.config = kwargs
    
    @abstractmethod
    def encode(self, texts: List[str]) -> np.ndarray:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        pass
    
    @abstractmethod
    def get_dimension(self) -> int:
        """ì„ë² ë”© ë²¡í„° ì°¨ì› ë°˜í™˜"""
        pass
    
    @abstractmethod
    def is_available(self) -> bool:
        """ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        pass
```

#### EmbeddingModelFactory
```python
from typing import Dict, Type, List
from .base_embedding import BaseEmbeddingModel

class EmbeddingModelFactory:
    """ì„ë² ë”© ëª¨ë¸ ìƒì„± íŒ©í† ë¦¬"""
    
    _models: Dict[str, Type[BaseEmbeddingModel]] = {}
    
    @classmethod
    def register_model(cls, model_type: str, model_class: Type[BaseEmbeddingModel]):
        """ìƒˆë¡œìš´ ëª¨ë¸ íƒ€ì… ë“±ë¡"""
        cls._models[model_type] = model_class
    
    @classmethod
    def create_model(cls, model_name: str, **kwargs) -> BaseEmbeddingModel:
        """ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        config = EmbeddingConfig.get_model_config(model_name)
        model_type = config.get('type', 'sentence_transformers')
        
        if model_type not in cls._models:
            raise ValueError(f"Unknown model type: {model_type}")
        
        model_class = cls._models[model_type]
        return model_class(model_name, **config, **kwargs)
    
    @classmethod
    def get_available_models(cls) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
        return list(EmbeddingConfig.get_all_models().keys())
```

### êµ¬ì²´ì  êµ¬í˜„ ì˜ˆì‹œ

#### SentenceTransformersEmbedding
```python
from sentence_transformers import SentenceTransformer
import numpy as np
from typing import List
from .base_embedding import BaseEmbeddingModel

class SentenceTransformersEmbedding(BaseEmbeddingModel):
    """Sentence Transformers ê¸°ë°˜ ì„ë² ë”© ëª¨ë¸"""
    
    def __init__(self, model_name: str, **kwargs):
        super().__init__(model_name, **kwargs)
        self.device = kwargs.get('device', 'auto')
        self.cache_folder = kwargs.get('cache_folder', './models/embeddings/')
        self._model = None
    
    def _load_model(self):
        """ì§€ì—° ë¡œë”©ìœ¼ë¡œ ëª¨ë¸ ì´ˆê¸°í™”"""
        if self._model is None:
            self._model = SentenceTransformer(
                self.model_name,
                device=self.device,
                cache_folder=self.cache_folder
            )
    
    def encode(self, texts: List[str]) -> np.ndarray:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        self._load_model()
        return self._model.encode(texts, convert_to_numpy=True)
    
    def get_dimension(self) -> int:
        """ì„ë² ë”© ë²¡í„° ì°¨ì› ë°˜í™˜"""
        self._load_model()
        return self._model.get_sentence_embedding_dimension()
    
    def is_available(self) -> bool:
        """ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            self._load_model()
            return True
        except Exception:
            return False
```

#### OpenAIEmbedding
```python
import openai
import numpy as np
from typing import List
from .base_embedding import BaseEmbeddingModel

class OpenAIEmbedding(BaseEmbeddingModel):
    """OpenAI API ê¸°ë°˜ ì„ë² ë”© ëª¨ë¸"""
    
    def __init__(self, model_name: str, **kwargs):
        super().__init__(model_name, **kwargs)
        self.api_key = kwargs.get('api_key')
        self.client = openai.OpenAI(api_key=self.api_key)
        self.dimension = kwargs.get('dimension', 1536)
    
    def encode(self, texts: List[str]) -> np.ndarray:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        response = self.client.embeddings.create(
            model=self.model_name,
            input=texts
        )
        
        embeddings = []
        for data in response.data:
            embeddings.append(data.embedding)
        
        return np.array(embeddings)
    
    def get_dimension(self) -> int:
        """ì„ë² ë”© ë²¡í„° ì°¨ì› ë°˜í™˜"""
        return self.dimension
    
    def is_available(self) -> bool:
        """ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return self.api_key is not None
```

## ì„¤ì • ê´€ë¦¬ ì‹œìŠ¤í…œ

### EmbeddingConfig í´ë˜ìŠ¤
```python
import json
from pathlib import Path
from typing import Dict, Any

class EmbeddingConfig:
    """ì„ë² ë”© ëª¨ë¸ ì„¤ì • ê´€ë¦¬"""
    
    _config_path = Path("core/rag/config/embedding_config.json")
    _config_cache = None
    
    @classmethod
    def load_config(cls) -> Dict[str, Any]:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        if cls._config_cache is None:
            with open(cls._config_path, 'r', encoding='utf-8') as f:
                cls._config_cache = json.load(f)
        return cls._config_cache
    
    @classmethod
    def get_model_config(cls, model_name: str) -> Dict[str, Any]:
        """íŠ¹ì • ëª¨ë¸ì˜ ì„¤ì • ë°˜í™˜"""
        config = cls.load_config()
        return config.get('models', {}).get(model_name, {})
    
    @classmethod
    def get_default_model(cls) -> str:
        """ê¸°ë³¸ ëª¨ë¸ëª… ë°˜í™˜"""
        config = cls.load_config()
        return config.get('default_model', 'dragonkue/KoEn-E5-Tiny')
    
    @classmethod
    def get_all_models(cls) -> Dict[str, Dict[str, Any]]:
        """ëª¨ë“  ëª¨ë¸ ì„¤ì • ë°˜í™˜"""
        config = cls.load_config()
        return config.get('models', {})
```

## ìºì‹± ì‹œìŠ¤í…œ

### EmbeddingCache í´ë˜ìŠ¤
```python
import hashlib
import pickle
import sqlite3
from pathlib import Path
from typing import List, Optional
import numpy as np

class EmbeddingCache:
    """ì„ë² ë”© ê²°ê³¼ ìºì‹± ì‹œìŠ¤í…œ"""
    
    def __init__(self, cache_dir: Path):
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.db_path = cache_dir / "embedding_cache.db"
        self._init_db()
    
    def _init_db(self):
        """ìºì‹œ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS embedding_cache (
                    text_hash TEXT PRIMARY KEY,
                    model_name TEXT,
                    embedding BLOB,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
    
    def _get_text_hash(self, text: str, model_name: str) -> str:
        """í…ìŠ¤íŠ¸ì™€ ëª¨ë¸ëª…ìœ¼ë¡œ í•´ì‹œ ìƒì„±"""
        content = f"{model_name}:{text}"
        return hashlib.sha256(content.encode()).hexdigest()
    
    def get(self, text: str, model_name: str) -> Optional[np.ndarray]:
        """ìºì‹œì—ì„œ ì„ë² ë”© ì¡°íšŒ"""
        text_hash = self._get_text_hash(text, model_name)
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                "SELECT embedding FROM embedding_cache WHERE text_hash = ?",
                (text_hash,)
            )
            row = cursor.fetchone()
            
            if row:
                return pickle.loads(row[0])
        
        return None
    
    def set(self, text: str, model_name: str, embedding: np.ndarray):
        """ìºì‹œì— ì„ë² ë”© ì €ì¥"""
        text_hash = self._get_text_hash(text, model_name)
        embedding_blob = pickle.dumps(embedding)
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(
                """INSERT OR REPLACE INTO embedding_cache 
                   (text_hash, model_name, embedding) VALUES (?, ?, ?)""",
                (text_hash, model_name, embedding_blob)
            )
```

## ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œìŠ¤í…œ

### ModelDownloader í´ë˜ìŠ¤
```python
from pathlib import Path
from typing import Optional
import requests
from tqdm import tqdm

class ModelDownloader:
    """ì„ë² ë”© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ê´€ë¦¬"""
    
    def __init__(self, cache_dir: Path):
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(parents=True, exist_ok=True)
    
    def download_model(self, model_name: str, progress_callback: Optional[callable] = None) -> bool:
        """ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        try:
            from sentence_transformers import SentenceTransformer
            
            # ì§„í–‰ë¥  ì½œë°± ì„¤ì •
            if progress_callback:
                progress_callback(0, f"Downloading {model_name}...")
            
            # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (sentence-transformersê°€ ìë™ ì²˜ë¦¬)
            model = SentenceTransformer(model_name, cache_folder=str(self.cache_dir))
            
            if progress_callback:
                progress_callback(100, f"Downloaded {model_name}")
            
            return True
            
        except Exception as e:
            if progress_callback:
                progress_callback(-1, f"Error downloading {model_name}: {str(e)}")
            return False
    
    def is_model_cached(self, model_name: str) -> bool:
        """ëª¨ë¸ì´ ë¡œì»¬ì— ìºì‹œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        model_path = self.cache_dir / model_name.replace('/', '_')
        return model_path.exists()
    
    def get_model_size(self, model_name: str) -> Optional[int]:
        """ëª¨ë¸ í¬ê¸° ë°˜í™˜ (ë°”ì´íŠ¸)"""
        if self.is_model_cached(model_name):
            model_path = self.cache_dir / model_name.replace('/', '_')
            return sum(f.stat().st_size for f in model_path.rglob('*') if f.is_file())
        return None
```

## í†µí•© ì‚¬ìš© ì˜ˆì‹œ

### RAG ì‹œìŠ¤í…œê³¼ì˜ í†µí•©
```python
from core.rag.embeddings import EmbeddingModelFactory

class RAGEmbeddingManager:
    """RAG ì‹œìŠ¤í…œì˜ ì„ë² ë”© ê´€ë¦¬ì"""
    
    def __init__(self):
        self.current_model = None
        self.model_name = EmbeddingConfig.get_default_model()
        self._load_model()
    
    def _load_model(self):
        """í˜„ì¬ ì„¤ì •ëœ ëª¨ë¸ ë¡œë“œ"""
        try:
            self.current_model = EmbeddingModelFactory.create_model(self.model_name)
        except Exception as e:
            logger.error(f"Failed to load embedding model {self.model_name}: {e}")
            # í´ë°± ëª¨ë¸ ì‹œë„
            self.model_name = "sentence-transformers/all-MiniLM-L6-v2"
            self.current_model = EmbeddingModelFactory.create_model(self.model_name)
    
    def embed_documents(self, documents: List[str]) -> np.ndarray:
        """ë¬¸ì„œë“¤ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        if not self.current_model:
            raise RuntimeError("No embedding model available")
        
        return self.current_model.encode(documents)
    
    def embed_query(self, query: str) -> np.ndarray:
        """ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        return self.embed_documents([query])[0]
    
    def switch_model(self, model_name: str):
        """ì„ë² ë”© ëª¨ë¸ ë³€ê²½"""
        self.model_name = model_name
        self._load_model()
```

## íŒ©í† ë¦¬ ë“±ë¡

### ëª¨ë¸ íƒ€ì… ë“±ë¡
```python
# core/rag/embeddings/__init__.py
from .embedding_factory import EmbeddingModelFactory
from .sentence_transformers_embedding import SentenceTransformersEmbedding
from .openai_embedding import OpenAIEmbedding

# ëª¨ë¸ íƒ€ì… ë“±ë¡
EmbeddingModelFactory.register_model('sentence_transformers', SentenceTransformersEmbedding)
EmbeddingModelFactory.register_model('openai_api', OpenAIEmbedding)

__all__ = [
    'EmbeddingModelFactory',
    'BaseEmbeddingModel',
    'SentenceTransformersEmbedding',
    'OpenAIEmbedding'
]
```

## í…ŒìŠ¤íŠ¸ ì½”ë“œ

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ
```python
import unittest
from core.rag.embeddings import EmbeddingModelFactory

class TestEmbeddingModels(unittest.TestCase):
    
    def test_sentence_transformers_model(self):
        """Sentence Transformers ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
        model = EmbeddingModelFactory.create_model('dragonkue/KoEn-E5-Tiny')
        
        texts = ["ì•ˆë…•í•˜ì„¸ìš”", "Hello world"]
        embeddings = model.encode(texts)
        
        self.assertEqual(len(embeddings), 2)
        self.assertEqual(embeddings.shape[1], model.get_dimension())
    
    def test_model_caching(self):
        """ëª¨ë¸ ìºì‹± í…ŒìŠ¤íŠ¸"""
        cache = EmbeddingCache(Path("./test_cache"))
        
        # ìºì‹œ ì €ì¥
        embedding = np.array([1.0, 2.0, 3.0])
        cache.set("test text", "test_model", embedding)
        
        # ìºì‹œ ì¡°íšŒ
        cached_embedding = cache.get("test text", "test_model")
        np.testing.assert_array_equal(embedding, cached_embedding)
```

## ì„±ëŠ¥ ìµœì í™” íŒ

### 1. ë°°ì¹˜ ì²˜ë¦¬
- ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ì—¬ GPU í™œìš©ë„ í–¥ìƒ
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ê³ ë ¤í•œ ë™ì  ë°°ì¹˜ í¬ê¸° ì¡°ì •

### 2. ì§€ì—° ë¡œë”©
- ëª¨ë¸ì„ ì‹¤ì œ ì‚¬ìš© ì‹œì ì— ë¡œë“œí•˜ì—¬ ì´ˆê¸°í™” ì‹œê°„ ë‹¨ì¶•
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”

### 3. ìºì‹± ì „ëµ
- ìì£¼ ì‚¬ìš©ë˜ëŠ” ì„ë² ë”© ê²°ê³¼ë¥¼ ë©”ëª¨ë¦¬ì— ìºì‹œ
- ë””ìŠ¤í¬ ìºì‹œë¡œ ì¬ì‹œì‘ í›„ì—ë„ ì„±ëŠ¥ ìœ ì§€

ì´ êµ¬í˜„ ê°€ì´ë“œë¥¼ ë”°ë¼ ë‹¨ê³„ì ìœ¼ë¡œ ì„ë² ë”© ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ë©´ í™•ì¥ ê°€ëŠ¥í•˜ê³  ì„±ëŠ¥ì´ ìš°ìˆ˜í•œ RAG ì‹œìŠ¤í…œì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.