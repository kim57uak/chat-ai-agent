# ğŸ”¢ Token Tracking System Enhancement Plan

## ğŸ“‹ Overview

**Goal**: Implement comprehensive token tracking system with 4-dimensional analysis (Mode, Model, Agent, Time) and persistent storage.

**Current Issues**:
- No distinction between chat modes (SIMPLE/TOOL/RAG)
- No model-specific tracking (GPT-4 vs Gemini costs differ)
- No agent-level breakdown (RAGAgent vs MCPAgent)
- All statistics lost on app restart

**Target**: Complete tracking system with DB persistence, cost calculation, and historical analysis.

---

## ğŸ¯ Tracking Dimensions

### 1. Chat Mode
- **SIMPLE**: LLM only (no tools)
- **TOOL**: MCP tools only
- **RAG**: RAG + Multi-Agent + MCP (integrated)

### 2. Model
- OpenAI: gpt-4, gpt-4-turbo, gpt-3.5-turbo
- Google: gemini-2.0-flash, gemini-2.5-flash, gemini-pro
- Perplexity: sonar-pro, sonar
- Pollinations: free models

### 3. Agent (RAG mode only)
- RAGAgent: Internal document retrieval
- MCPAgent: External tools/web services
- PythonREPLAgent: Python code execution
- FileSystemAgent: File operations (read/write/delete)
- PandasAgent: Data analysis (future)
- SQLAgent: Database queries (future)

### 4. Time
- Current session
- Last 7 days
- Last 30 days
- All time

---

## ğŸ“Š Database Schema

### New Tables

#### 1. token_usage
```sql
CREATE TABLE token_usage (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    session_id INTEGER NOT NULL,
    message_id INTEGER,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    
    -- Tracking dimensions
    chat_mode TEXT NOT NULL,           -- 'simple', 'tool', 'rag'
    model_name TEXT NOT NULL,          -- 'gemini-2.0-flash'
    agent_name TEXT,                   -- 'RAGAgent', 'MCPAgent', NULL
    
    -- Token counts
    input_tokens INTEGER NOT NULL,
    output_tokens INTEGER NOT NULL,
    total_tokens INTEGER NOT NULL,
    
    -- Cost
    cost_usd REAL NOT NULL,
    
    -- Metadata
    duration_ms REAL,
    tool_calls TEXT,                   -- JSON array of tool names
    additional_info TEXT,              -- JSON for extra data
    
    FOREIGN KEY (session_id) REFERENCES sessions(id) ON DELETE CASCADE,
    FOREIGN KEY (message_id) REFERENCES messages(id) ON DELETE SET NULL
);

CREATE INDEX idx_token_usage_session ON token_usage(session_id);
CREATE INDEX idx_token_usage_timestamp ON token_usage(timestamp);
CREATE INDEX idx_token_usage_mode ON token_usage(chat_mode);
CREATE INDEX idx_token_usage_model ON token_usage(model_name);
```

#### 2. session_token_summary
```sql
CREATE TABLE session_token_summary (
    session_id INTEGER PRIMARY KEY,
    
    -- Totals
    total_input_tokens INTEGER DEFAULT 0,
    total_output_tokens INTEGER DEFAULT 0,
    total_tokens INTEGER DEFAULT 0,
    total_cost_usd REAL DEFAULT 0.0,
    
    -- Breakdowns (JSON)
    mode_breakdown TEXT,               -- {"simple": 100, "tool": 200, "rag": 300}
    model_breakdown TEXT,              -- {"gpt-4": 100, "gemini": 200}
    agent_breakdown TEXT,              -- {"RAGAgent": 100, "MCPAgent": 200}
    
    -- Timestamps
    first_message_at DATETIME,
    last_updated DATETIME DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (session_id) REFERENCES sessions(id) ON DELETE CASCADE
);
```

#### 3. global_token_stats
```sql
CREATE TABLE global_token_stats (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    stat_date DATE UNIQUE NOT NULL,
    
    -- Daily totals
    total_tokens INTEGER DEFAULT 0,
    total_cost_usd REAL DEFAULT 0.0,
    
    -- Breakdowns (JSON)
    mode_breakdown TEXT,
    model_breakdown TEXT,
    agent_breakdown TEXT,
    
    -- Metadata
    session_count INTEGER DEFAULT 0,
    message_count INTEGER DEFAULT 0,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_global_stats_date ON global_token_stats(stat_date);
```

---

## ğŸ—ï¸ Architecture

### File Structure
```
core/
â”œâ”€â”€ token_tracking/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ unified_token_tracker.py      # Main tracker
â”‚   â”œâ”€â”€ model_pricing.py              # Pricing database
â”‚   â”œâ”€â”€ token_storage.py              # DB operations
â”‚   â””â”€â”€ token_statistics.py           # Statistics aggregation
ui/
â”œâ”€â”€ components/
â”‚   â””â”€â”€ advanced_token_display.py     # Enhanced UI
```

### Core Components

#### 1. Model Pricing (`model_pricing.py`)
```python
MODEL_PRICING = {
    # OpenAI (per 1K tokens)
    "gpt-4": {"input": 0.03, "output": 0.06},
    "gpt-4-turbo": {"input": 0.01, "output": 0.03},
    "gpt-3.5-turbo": {"input": 0.0005, "output": 0.0015},
    
    # Google Gemini 2.0 Flash Series (Pay-as-you-go pricing)
    "gemini-2.0-flash": {"input": 0.0001, "output": 0.0004},
    "gemini-2.0-flash-exp": {"input": 0.0001, "output": 0.0004},
    "gemini-2.0-flash-001": {"input": 0.0001, "output": 0.0004},
    "gemini-2.0-flash-lite": {"input": 0.00005, "output": 0.0002},
    "gemini-2.0-flash-lite-001": {"input": 0.00005, "output": 0.0002},
    "gemini-2.0-flash-thinking-exp": {"input": 0.0001, "output": 0.0004},
    "gemini-flash-latest": {"input": 0.0001, "output": 0.0004},
    "gemini-flash-lite-latest": {"input": 0.00005, "output": 0.0002},
    
    # Google Gemini 2.0 Pro Series (Pay-as-you-go pricing)
    "gemini-2.0-pro-exp": {"input": 0.00125, "output": 0.005},
    "gemini-2.0-pro-exp-02-05": {"input": 0.00125, "output": 0.005},
    
    # Google Gemini 2.5 Flash Series (Pay-as-you-go pricing)
    "gemini-2.5-flash": {"input": 0.0001, "output": 0.0004},
    "gemini-2.5-flash-lite": {"input": 0.00005, "output": 0.0002},
    "gemini-2.5-flash-preview-05-20": {"input": 0.0001, "output": 0.0004},
    "gemini-2.5-flash-lite-preview-06-17": {"input": 0.00005, "output": 0.0002},
    
    # Google Gemini 2.5 Pro Series (Pay-as-you-go pricing)
    "gemini-2.5-pro": {"input": 0.00125, "output": 0.005},
    "gemini-2.5-pro-preview-03-25": {"input": 0.00125, "output": 0.005},
    "gemini-2.5-pro-preview-05-06": {"input": 0.00125, "output": 0.005},
    "gemini-2.5-pro-preview-06-05": {"input": 0.00125, "output": 0.005},
    
    # Google Gemini Legacy (Pay-as-you-go pricing)
    "gemini-pro-latest": {"input": 0.000125, "output": 0.000375},
    "gemini-exp-1206": {"input": 0.000125, "output": 0.000375},
    
    # Perplexity (per 1K tokens)
    # Sonar Series (Online models with web search)
    "sonar": {"input": 0.001, "output": 0.001},
    "sonar-pro": {"input": 0.003, "output": 0.015},
    "sonar-reasoning": {"input": 0.001, "output": 0.005},
    
    # Chat Series (Offline models without web search)
    "llama-3.1-sonar-small-128k-chat": {"input": 0.0002, "output": 0.0002},
    "llama-3.1-sonar-large-128k-chat": {"input": 0.001, "output": 0.001},
    "llama-3.1-sonar-huge-128k-chat": {"input": 0.005, "output": 0.005},
    
    # Pollinations (Free)
    "pollinations": {"input": 0.0, "output": 0.0},
    "pollinations-mistral": {"input": 0.0, "output": 0.0}
}

class ModelPricing:
    @staticmethod
    def get_cost(model: str, input_tokens: int, output_tokens: int) -> float
    
    @staticmethod
    def get_pricing_info(model: str) -> Dict
    
    @staticmethod
    def update_pricing(model: str, input_price: float, output_price: float)
```

#### 2. Unified Token Tracker (`unified_token_tracker.py`)
```python
@dataclass
class AgentExecutionToken:
    agent_name: str
    model_name: str
    input_tokens: int
    output_tokens: int
    cost: float
    tool_calls: List[str]
    duration_ms: float
    timestamp: datetime

@dataclass
class ConversationToken:
    conversation_id: str
    mode: ChatModeType
    model_name: str
    agents: List[AgentExecutionToken]
    total_input: int
    total_output: int
    total_cost: float
    start_time: datetime
    end_time: Optional[datetime]

class UnifiedTokenTracker:
    def __init__(self, db_manager)
    
    # Conversation lifecycle
    def start_conversation(mode: ChatModeType, model: str) -> str
    def track_agent(agent_name, model, input_tokens, output_tokens)
    def end_conversation() -> ConversationToken
    
    # Persistence
    def _save_to_db(conversation: ConversationToken)
    def _load_from_db(session_id: int)
    
    # Statistics
    def get_session_stats() -> Dict
    def get_mode_breakdown() -> Dict[ChatModeType, TokenUsage]
    def get_model_breakdown() -> Dict[str, TokenUsage]
    def get_agent_breakdown() -> Dict[str, TokenUsage]
    def get_historical_stats(days: int) -> Dict
    
    # Cost analysis
    def get_total_cost() -> float
    def get_cost_by_model() -> Dict[str, float]
    def get_most_expensive_model() -> Tuple[str, float]
```

#### 3. Token Storage (`token_storage.py`)
```python
class TokenStorage:
    def __init__(self, db_path: str)
    
    # Insert operations
    def insert_token_usage(session_id, mode, model, agent, tokens, cost)
    def update_session_summary(session_id, totals, breakdowns)
    def update_global_stats(date, totals, breakdowns)
    
    # Query operations
    def get_session_tokens(session_id) -> List[TokenUsage]
    def get_session_summary(session_id) -> Dict
    def get_global_stats(start_date, end_date) -> List[Dict]
    def get_model_usage_history(model, days) -> List[Dict]
    
    # Aggregation
    def aggregate_by_mode(session_id) -> Dict
    def aggregate_by_model(session_id) -> Dict
    def aggregate_by_agent(session_id) -> Dict
```

---

## ğŸ”„ Integration Points

### 1. Chat Processors
```python
# base_chat_processor.py
class BaseChatProcessor:
    def process_message(self, user_input, history):
        # Start tracking
        unified_tracker.start_conversation(
            mode=self.mode,
            model=self.model_strategy.model_name
        )
        
        # Process
        response = self._process(user_input, history)
        
        # End tracking
        unified_tracker.end_conversation()
        
        return response
```

### 2. Base Agent
```python
# base_agent.py
class BaseAgent:
    def execute(self, query, context):
        start_time = time.time()
        
        # Execute
        result = executor.invoke(inputs)
        
        # Extract tokens
        input_tokens, output_tokens = extract_tokens(result)
        
        # Track
        unified_tracker.track_agent(
            agent_name=self.get_name(),
            model=self.llm.model_name,
            input_tokens=input_tokens,
            output_tokens=output_tokens
        )
        
        return result
```

### 3. Multi-Agent Orchestrator
```python
# multi_agent_orchestrator.py
class MultiAgentOrchestrator:
    def execute_parallel_optimized(self, query, context):
        # Track orchestrator decision
        unified_tracker.track_agent(
            agent_name="Orchestrator",
            model=self.llm.model_name,
            input_tokens=decision_tokens.input,
            output_tokens=decision_tokens.output
        )
        
        # Execute agents (each tracks itself)
        results = parallel_execute(agents)
        
        return merge_results(results)
```

---

## ğŸ¨ UI Components

### Enhanced Token Display
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Token Usage Dashboard                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Current] [7 Days] [30 Days] [All Time]            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚ ğŸ“Š Overview                                         â”‚
â”‚  Total Tokens: 50,000                              â”‚
â”‚  Total Cost: $0.080                                â”‚
â”‚  Average per conversation: 500 tokens              â”‚
â”‚                                                     â”‚
â”‚ ğŸ“ˆ Mode Breakdown                                   â”‚
â”‚  â”œâ”€ SIMPLE: 10,000 tokens (20%) - $0.010          â”‚
â”‚  â”œâ”€ TOOL:   15,000 tokens (30%) - $0.020          â”‚
â”‚  â””â”€ RAG:    25,000 tokens (50%) - $0.050          â”‚
â”‚                                                     â”‚
â”‚ ğŸ’° Model Breakdown                                  â”‚
â”‚  â”œâ”€ gemini-2.0-flash: 30,000 tokens - $0.006      â”‚
â”‚  â”œâ”€ gpt-4:            10,000 tokens - $0.060       â”‚
â”‚  â””â”€ sonar-pro:        10,000 tokens - $0.014       â”‚
â”‚                                                     â”‚
â”‚ ğŸ¤– Agent Breakdown (RAG Mode)                      â”‚
â”‚  â”œâ”€ RAGAgent:         12,000 tokens - $0.024      â”‚
â”‚  â”œâ”€ MCPAgent:         10,000 tokens - $0.020      â”‚
â”‚  â”œâ”€ PythonREPLAgent:   5,000 tokens - $0.010      â”‚
â”‚  â”œâ”€ FileSystemAgent:   3,000 tokens - $0.006      â”‚
â”‚  â””â”€ Orchestrator:      3,000 tokens - $0.006      â”‚
â”‚                                                     â”‚
â”‚ ğŸ“‰ Cost Analysis                                    â”‚
â”‚  Most Expensive: gpt-4 ($0.060)                    â”‚
â”‚  Most Used: gemini-2.0-flash (30,000 tokens)      â”‚
â”‚  Cost per 1K tokens: $0.0016                       â”‚
â”‚                                                     â”‚
â”‚ [Export CSV] [Export JSON] [Clear History]         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Features
- Real-time updates via PyQt6 signals
- Interactive charts (bar, pie, line)
- Drill-down capability (click to see details)
- Export to CSV/JSON
- Date range filtering
- Model comparison view

---

## ğŸ“… Implementation Plan

### Phase 1: Database Schema (0.5 days) âœ… COMPLETED
**Files**: `core/token_tracking/migrations/001_add_token_tables.sql`

- [x] Create migration script
- [x] Add token_usage table
- [x] Add session_token_summary table
- [x] Add global_token_stats table
- [x] Create indexes
- [x] Test migration on existing DB

### Phase 2: Model Pricing System (0.5 days) âœ… COMPLETED
**Files**: `core/token_tracking/model_pricing.py`

- [x] Define MODEL_PRICING dictionary (33 models)
- [x] Implement ModelPricing class
- [x] Add get_cost() method
- [x] Add pricing update mechanism
- [x] Add comparison methods (cheapest/most expensive)
- [x] Write unit tests

### Phase 3: Token Storage Layer (1 day) âœ… COMPLETED
**Files**: `core/token_tracking/token_storage.py`

- [x] Implement TokenStorage class
- [x] Add insert methods (token_usage, summaries)
- [x] Add query methods (session, global stats)
- [x] Add aggregation methods (mode/model/agent)
- [x] Add error handling and logging
- [x] Write integration tests

### Phase 4: Unified Token Tracker (1.5 days) âœ… COMPLETED
**Files**: `core/token_tracking/unified_token_tracker.py`

- [x] Define data classes (AgentExecutionToken, ConversationToken)
- [x] Implement UnifiedTokenTracker class
- [x] Add conversation lifecycle methods (start/track/end)
- [x] Implement 4-dimensional tracking (Mode/Model/Agent/Time)
- [x] Add persistence logic (save/load)
- [x] Implement statistics methods
- [x] Add cost calculation integration
- [x] Add PyQt6 signals for UI updates
- [x] Write comprehensive tests

### Phase 5: Integration (1 day) âœ… COMPLETED
**Files**: Multiple processor and agent files

- [x] Update SimpleChatProcessor (unified tracker integration)
- [x] Update ToolChatProcessor (unified tracker integration)
- [x] Update RAGChatProcessor (unified tracker integration)
- [x] Update BaseAgent.execute() (automatic token tracking)
- [x] Add _track_execution() method to BaseAgent
- [x] Add _extract_token_counts() method
- [x] Add model name propagation via context
- [x] Create migration application script
- [ ] Test all chat modes (pending)
- [ ] Test multi-agent scenarios (pending)
- [ ] Test UI data compatibility (pending)

### Phase 6: UI Dashboard Enhancement (1.5 days)
**Files**: `ui/components/token_usage_display.py` (ê¸°ì¡´ íŒŒì¼ ìˆ˜ì • + í™•ì¥)

#### 6.1 ê¸°ì¡´ UI ë°ì´í„° í˜¸í™˜ì„± ìˆ˜ì • (0.5 days)

**ë¬¸ì œì  ë¶„ì„**:
```python
# í˜„ì¬ ì½”ë“œê°€ ì˜ì¡´í•˜ëŠ” ë°ì´í„° êµ¬ì¡°
token_tracker.get_conversation_stats()  # âŒ unified_trackerì™€ ë‹¤ë¦„
token_tracker.conversation_history      # âŒ êµ¬ì¡° ë³€ê²½ í•„ìš”
token_accumulator.get_session_total()   # âŒ í†µí•© í•„ìš”
```

**ìˆ˜ì • ì‘ì—…**:
- [ ] **ë°ì´í„° ì†ŒìŠ¤ ì „í™˜**:
  - [ ] `token_tracker` â†’ `unified_tracker` ì „í™˜
  - [ ] `token_accumulator` í†µí•© (ì¤‘ë³µ ì œê±°)
  - [ ] ë°ì´í„° êµ¬ì¡° ë§¤í•‘ ë ˆì´ì–´ ì¶”ê°€

- [ ] **Current íƒ­ ìˆ˜ì •**:
  - [ ] `conversation_id` â†’ `conversation_id` (ë™ì¼)
  - [ ] `model_name` â†’ `model_name` (ë™ì¼)
  - [ ] `steps_count` â†’ `len(agents)` (Agent ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½)
  - [ ] `total_actual_tokens` â†’ `total_input + total_output`
  - [ ] **ë¹„ìš© ì •ë³´ ì¶”ê°€**: `total_cost` í‘œì‹œ
  - [ ] **ëª¨ë“œ ì •ë³´ ì¶”ê°€**: `mode` (SIMPLE/TOOL/RAG) í‘œì‹œ

- [ ] **Steps íƒ­ ìˆ˜ì •**:
  - [ ] ê¸°ì¡´: ë‹¨ê³„ë³„ í† í° (StepType ê¸°ë°˜)
  - [ ] ì‹ ê·œ: Agentë³„ í† í° (AgentExecutionToken ê¸°ë°˜)
  - [ ] í…Œì´ë¸” ì»¬ëŸ¼ ì¶”ê°€: "Agent", "Cost"
  - [ ] í…Œì´ë¸” ì»¬ëŸ¼ ì œê±°: "Type" (ë¶ˆí•„ìš”)

- [ ] **Stats íƒ­ ìˆ˜ì •**:
  - [ ] ê¸°ì¡´: ëª¨ë¸ë³„ í†µê³„ë§Œ
  - [ ] ì‹ ê·œ: ëª¨ë“œë³„ + ëª¨ë¸ë³„ + Agentë³„ í†µê³„
  - [ ] `model_stats` â†’ `get_model_breakdown()` ì „í™˜
  - [ ] ì •í™•ë„ ê³„ì‚° ì œê±° (ì¶”ì • í† í° ì‚¬ìš© ì•ˆ í•¨)

- [ ] **Signal ì—°ê²° ìˆ˜ì •**:
  - [ ] `token_accumulator.token_updated` â†’ `unified_tracker.token_updated`
  - [ ] Signal ë°ì´í„° êµ¬ì¡° ë³€ê²½ ëŒ€ì‘

#### 6.2 ìƒˆ ê¸°ëŠ¥ ì¶”ê°€ (1 day)

**ì¶”ê°€ ê¸°ëŠ¥**:
- [ ] **Stats íƒ­ í™•ì¥**:
  - [ ] Mode Breakdown ì„¹ì…˜ (SIMPLE/TOOL/RAG)
  - [ ] Model Breakdown ì„¹ì…˜ (ë¹„ìš© í¬í•¨)
  - [ ] Agent Breakdown ì„¹ì…˜ (RAG ëª¨ë“œ)
  - [ ] Cost Analysis ì„¹ì…˜ (ì´ ë¹„ìš©, ê°€ì¥ ë¹„ì‹¼ ëª¨ë¸)

- [ ] **Time Range í•„í„°**:
  - [ ] ë“œë¡­ë‹¤ìš´ ì¶”ê°€: Current/7D/30D/All
  - [ ] í•„í„° ë³€ê²½ ì‹œ ë°ì´í„° ì¬ë¡œë“œ
  - [ ] DB ì¿¼ë¦¬ ì—°ë™

- [ ] **Cost ì •ë³´ í‘œì‹œ**:
  - [ ] Current íƒ­: í˜„ì¬ ëŒ€í™” ë¹„ìš©
  - [ ] Stats íƒ­: ì´ ë¹„ìš©, í‰ê·  ë¹„ìš©
  - [ ] ëª¨ë¸ë³„ ë¹„ìš© ì°¨íŠ¸

- [ ] **Export ê¸°ëŠ¥ í™•ì¥**:
  - [ ] CSV export ì¶”ê°€
  - [ ] í•„í„°ë§ëœ ë°ì´í„°ë§Œ export
  - [ ] ë¹„ìš© ì •ë³´ í¬í•¨

- [ ] **ì°¨íŠ¸ ì¶”ê°€** (ì„ íƒì ):
  - [ ] ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰ íŒŒì´ ì°¨íŠ¸
  - [ ] ì‹œê°„ë³„ í† í° ì‚¬ìš©ëŸ‰ ë¼ì¸ ì°¨íŠ¸
  - [ ] ë¹„ìš© ë¹„êµ ë°” ì°¨íŠ¸

### Phase 7: Testing & Optimization (0.5 days)

- [ ] End-to-end testing (all modes)
- [ ] Performance testing (DB queries)
- [ ] Memory leak testing
- [ ] UI responsiveness testing
- [ ] Export/import testing
- [ ] Migration testing (existing data)
- [ ] Documentation updates

---

## ğŸ“Š Success Metrics

### Functional Requirements
- âœ… Track tokens across all 3 chat modes
- âœ… Track tokens for all models
- âœ… Track tokens per agent (RAG mode)
- âœ… Calculate accurate costs
- âœ… Persist data across app restarts
- âœ… Display historical statistics

### Performance Requirements
- DB insert < 10ms (async)
- Statistics query < 100ms
- UI update < 50ms
- Memory usage < 50MB (cache)

### Data Integrity
- No token loss on app crash
- Accurate cost calculation (Â±1%)
- Consistent aggregation
- Safe concurrent access

---

## ğŸš€ Deployment

### Migration Steps
1. Backup existing database
2. Run migration script
3. Verify table creation
4. Test with sample data
5. Deploy new code
6. Monitor logs for errors

### Rollback Plan
1. Restore database backup
2. Revert code changes
3. Clear token cache
4. Restart application

---

## ğŸ“ Notes

### Design Decisions
- **Async DB writes**: Prevent UI blocking
- **Hybrid caching**: Fast access + persistence
- **JSON breakdowns**: Flexible schema
- **Separate tables**: Optimized queries
- **ê¸°ì¡´ UI í™•ì¥**: ìƒˆ ìœ„ì ¯ ìƒì„± ëŒ€ì‹  ê¸°ì¡´ token_usage_display.py í™•ì¥
- **ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜**: token_tracker â†’ unified_tracker ë‹¨ê³„ì  ì „í™˜
- **í•˜ìœ„ í˜¸í™˜ì„±**: ê¸°ì¡´ ë°ì´í„° êµ¬ì¡° ë§¤í•‘ ë ˆì´ì–´ë¡œ í˜¸í™˜ì„± ìœ ì§€
- **ë°ì´í„° ì¤‘ë³µ ì œê±°**: token_accumulator ê¸°ëŠ¥ì„ unified_trackerë¡œ í†µí•©

### Future Enhancements
- Cost alerts (budget limits)
- Token usage predictions
- Model recommendation (cost-effective)
- Batch export for accounting
- API for external analytics

---

## ğŸ”§ Data Structure Mapping

### ê¸°ì¡´ â†’ ì‹ ê·œ ë§¤í•‘

```python
# ê¸°ì¡´ token_tracker êµ¬ì¡°
class ConversationTokenUsage:
    conversation_id: str
    model_name: str
    steps: List[TokenUsageStep]  # StepType ê¸°ë°˜
    total_tokens: int
    total_estimated_tokens: int

# ì‹ ê·œ unified_tracker êµ¬ì¡°
class ConversationToken:
    conversation_id: str
    mode: ChatModeType           # âœ¨ ìƒˆë¡œ ì¶”ê°€
    model_name: str
    agents: List[AgentExecutionToken]  # âœ¨ Agent ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½
    total_input: int
    total_output: int
    total_cost: float            # âœ¨ ìƒˆë¡œ ì¶”ê°€

# ë§¤í•‘ ë ˆì´ì–´
class DataAdapter:
    @staticmethod
    def convert_to_legacy_format(new_data: ConversationToken) -> dict:
        """ì‹ ê·œ â†’ ê¸°ì¡´ í˜•ì‹ ë³€í™˜ (UI í˜¸í™˜ì„±)"""
        return {
            'conversation_id': new_data.conversation_id,
            'model_name': new_data.model_name,
            'steps_count': len(new_data.agents),
            'total_actual_tokens': new_data.total_input + new_data.total_output,
            'steps': [
                {
                    'step_name': agent.agent_name,
                    'actual_tokens': agent.input_tokens + agent.output_tokens,
                    'duration_ms': agent.duration_ms,
                    'tool_name': ', '.join(agent.tool_calls)
                }
                for agent in new_data.agents
            ]
        }
```

## ğŸ“š References

- LangChain token counting: https://python.langchain.com/docs/modules/model_io/llms/token_usage_tracking
- OpenAI pricing: https://openai.com/pricing
- Google Gemini pricing: https://ai.google.dev/pricing
- Perplexity pricing: https://docs.perplexity.ai/docs/pricing
- SQLite best practices: https://www.sqlite.org/bestpractice.html

---

**Total Estimated Time**: 6.5 days
**Priority**: High
**Status**: Planning Complete âœ…
