from PyQt6.QtCore import QObject, pyqtSignal
import threading
from ui.components.status_display import status_display
from core.token_logger import TokenLogger


class AIProcessor(QObject):
    """AI ìš”ì²­ ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ (SRP)"""
    
    finished = pyqtSignal(str, str, list)  # sender, text, used_tools
    error = pyqtSignal(str)
    streaming = pyqtSignal(str, str)  # sender, partial_text
    streaming_complete = pyqtSignal(str, str, list)  # sender, full_text, used_tools
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self._cancelled = False
        self._current_client = None
    
    def cancel(self):
        """ìš”ì²­ ì·¨ì†Œ"""
        self._cancelled = True
        status_display.finish_processing(False)
        if self._current_client:
            self._current_client.cancel_streaming()
    
    def process_request(self, api_key, model, messages, user_text=None, agent_mode=False, file_prompt=None):
        """AI ìš”ì²­ ì²˜ë¦¬ - ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨"""
        def _process():
            try:
                if self._cancelled:
                    return
                
                # ìƒíƒœ í‘œì‹œ ì‹œì‘
                mode = 'agent' if agent_mode else 'ask'
                status_display.start_processing(model, mode)
                
                from core.ai_client import AIClient
                client = AIClient(api_key, model)
                self._current_client = client
                self._current_model = model
                
                # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì„¤ì •
                if messages:
                    client.conversation_history = messages
                    if hasattr(client, '_conversation_manager'):
                        client._conversation_manager.conversation_history = messages
                
                response = None
                sender = 'AI'
                used_tools = []
                
                if file_prompt:
                    # íŒŒì¼ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
                    if agent_mode:
                        result = client.agent_chat(file_prompt)
                        if isinstance(result, tuple):
                            response, used_tools = result
                        else:
                            response = result
                            used_tools = []
                        sender = 'ì—ì´ì „íŠ¸'
                    else:
                        response = client.simple_chat(file_prompt)
                        sender = 'AI'
                        used_tools = []
                else:
                    # ì¼ë°˜ í…ìŠ¤íŠ¸ ì²˜ë¦¬
                    if agent_mode:
                        # ì—ì´ì „íŠ¸ ëª¨ë“œ: ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥
                        if messages:
                            # íˆìŠ¤í† ë¦¬ë¥¼ í¬í•¨í•œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„±
                            full_messages = messages + [{'role': 'user', 'content': user_text}]
                            # AIClient.chat() ë©”ì„œë“œë¥¼ í†µí•´ force_agent=True ì „ë‹¬
                            result = client.chat(full_messages, force_agent=True)
                            if isinstance(result, tuple):
                                response, used_tools = result
                            else:
                                response = result
                                used_tools = []
                        else:
                            result = client.agent_chat(user_text)
                            if isinstance(result, tuple):
                                response, used_tools = result
                            else:
                                response = result
                                used_tools = []
                        sender = 'ì—ì´ì „íŠ¸'
                    else:
                        # Ask ëª¨ë“œ: ë„êµ¬ ì‚¬ìš© ì—†ì´ ë‹¨ìˆœ ì±„íŒ…ë§Œ
                        if messages:
                            # Ask ëª¨ë“œ: force_agent=Falseë¡œ ëª…ì‹œì  ì „ë‹¬
                            full_messages = messages + [{'role': 'user', 'content': user_text}]
                            result = client.chat(full_messages, force_agent=False)
                            if isinstance(result, tuple):
                                response, used_tools = result
                            else:
                                response = result
                                used_tools = []
                        else:
                            response = client.simple_chat(user_text)
                            used_tools = []
                        sender = 'AI'
                
                if not self._cancelled and response:
                    # ì‚¬ìš©ëœ ë„êµ¬ ì—…ë°ì´íŠ¸
                    for tool in used_tools:
                        status_display.add_tool_used(str(tool))
                    
                    # ì…ë ¥ í…ìŠ¤íŠ¸ êµ¬ì„±
                    input_text = ""
                    if messages:
                        for msg in messages:
                            if isinstance(msg, dict) and msg.get('content'):
                                input_text += str(msg['content']) + "\n"
                    if user_text:
                        input_text += user_text
                    if file_prompt:
                        input_text += file_prompt
                    
                    # ì‹¤ì œ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ ì‹œë„
                    actual_input_tokens, actual_output_tokens = 0, 0
                    if hasattr(client, '_last_response'):
                        actual_input_tokens, actual_output_tokens = TokenLogger.extract_actual_tokens(client._last_response)
                    
                    # ì‹¤ì œ í† í°ì´ ì—†ìœ¼ë©´ ì¶”ì •ì¹˜ ì‚¬ìš©
                    if actual_input_tokens == 0 and actual_output_tokens == 0:
                        actual_input_tokens = TokenLogger.estimate_tokens(input_text, model)
                        actual_output_tokens = TokenLogger.estimate_tokens(response, model)
                    
                    # ìƒíƒœ í‘œì‹œì— ì‹¤ì œ í† í° ì •ë³´ ì—…ë°ì´íŠ¸
                    status_display.update_tokens(actual_input_tokens, actual_output_tokens)
                    
                    # ë¡œê·¸ì— ì‹¤ì œ í† í° ì‚¬ìš©ëŸ‰ ê¸°ë¡
                    if hasattr(client, '_last_response') and client._last_response:
                        TokenLogger.log_actual_token_usage(model, client._last_response, "agent_chat" if agent_mode else "simple_chat")
                    else:
                        TokenLogger.log_token_usage(model, input_text, response, "agent_chat" if agent_mode else "simple_chat")
                    
                    # ìƒíƒœ í‘œì‹œ ì™„ë£Œ
                    status_display.finish_processing(True)
                    
                    # senderì— ëª¨ë¸ ì •ë³´ì™€ í† í° ì •ë³´ í¬í•¨ - TokenLoggerì™€ ë™ì¼í•œ í˜•ì‹
                    total_tokens = actual_input_tokens + actual_output_tokens
                    token_info = f" | ğŸ“Š {total_tokens:,}í† í° (IN:{actual_input_tokens:,} OUT:{actual_output_tokens:,})"
                    model_sender = f"{sender}_{model}{token_info}"
                    self.finished.emit(model_sender, response, used_tools)
                elif not self._cancelled:
                    status_display.finish_processing(False)
                    self.error.emit("ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                if not self._cancelled:
                    status_display.finish_processing(False)
                    self.error.emit(f'ì˜¤ë¥˜ ë°œìƒ: {str(e)}')
        
        thread = threading.Thread(target=_process, daemon=True)
        thread.start()